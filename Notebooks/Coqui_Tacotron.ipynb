{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qCS2atfAJ1Sb",
        "outputId": "727ddd95-bbc2-4c7e-bc49-56be10499764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TTS\n",
            "  Downloading TTS-0.14.0-cp310-cp310-manylinux1_x86_64.whl (736 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m736.7/736.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cython==0.29.28 (from TTS)\n",
            "  Downloading Cython-0.29.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.1+cu118)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
            "Requirement already satisfied: librosa==0.10.0.* in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.0.post2)\n",
            "Collecting inflect==5.6.0 (from TTS)\n",
            "  Downloading inflect-5.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from TTS) (4.65.0)\n",
            "Collecting anyascii (from TTS)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0)\n",
            "Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.4.0)\n",
            "Collecting aiohttp (from TTS)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from TTS) (23.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.4)\n",
            "Collecting pysbd (from TTS)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn==0.5.1 (from TTS)\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
            "Collecting trainer==0.0.20 (from TTS)\n",
            "  Downloading trainer-0.0.20-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coqpit>=0.0.16 (from TTS)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
            "Collecting pypinyin (from TTS)\n",
            "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mecab-python3==1.0.5 (from TTS)\n",
            "  Downloading mecab_python3-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.1/581.1 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidic-lite==1.0.8 (from TTS)\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut[de,es,fr]==2.2.3 (from TTS)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Collecting bangla==0.0.2 (from TTS)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting bnnumerizer (from TTS)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer==0.1.1 (from TTS)\n",
            "  Downloading bnunicodenormalizer-0.1.1.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting k-diffusion (from TTS)\n",
            "  Downloading k_diffusion-0.0.14-py3-none-any.whl (25 kB)\n",
            "Collecting einops (from TTS)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from TTS)\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from TTS) (1.22.4)\n",
            "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.56.4)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.12.1)\n",
            "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num2words<1.0.0,>=0.5.10 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.2)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->TTS) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->TTS) (67.7.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer==0.0.20->TTS) (5.9.5)\n",
            "Collecting tensorboardX (from trainer==0.0.20->TTS)\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2 (from trainer==0.0.20->TTS)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynndescent>=0.5 (from umap-learn==0.5.1->TTS)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->TTS) (1.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (16.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->TTS)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->TTS)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->TTS)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->TTS)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->TTS)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (8.1.3)\n",
            "Collecting accelerate (from k-diffusion->TTS)\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clean-fid (from k-diffusion->TTS)\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->TTS)\n",
            "  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonmerge (from k-diffusion->TTS)\n",
            "  Downloading jsonmerge-1.9.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kornia (from k-diffusion->TTS)\n",
            "  Downloading kornia-0.6.12-py2.py3-none-any.whl (653 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.4/653.4 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (8.4.0)\n",
            "Collecting resize-right (from k-diffusion->TTS)\n",
            "  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.19.3)\n",
            "Collecting torchdiffeq (from k-diffusion->TTS)\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Collecting torchsde (from k-diffusion->TTS)\n",
            "  Downloading torchsde-0.2.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.15.1+cu118)\n",
            "Collecting wandb (from k-diffusion->TTS)\n",
            "  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (2.8.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->TTS) (2022.10.31)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TTS) (2022.7.1)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers->TTS)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->TTS) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->TTS)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (4.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->TTS) (2.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Collecting docopt>=0.6.2 (from num2words<1.0.0,>=0.5.10->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa==0.10.0.*->TTS) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.0.*->TTS) (3.1.0)\n",
            "Collecting ftfy (from clip-anytorch->k-diffusion->TTS)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->TTS) (4.3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (1.4.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->TTS) (1.3.0)\n",
            "Collecting boltons>=20.2.1 (from torchsde->k-diffusion->TTS)\n",
            "  Downloading boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trampoline>=0.1.2 (from torchsde->k-diffusion->TTS)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->k-diffusion->TTS)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->k-diffusion->TTS)\n",
            "  Downloading sentry_sdk-1.23.0-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->k-diffusion->TTS)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->k-diffusion->TTS)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->k-diffusion->TTS)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.19.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip-anytorch->k-diffusion->TTS) (0.2.6)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (0.1.0.post0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (2023.3)\n",
            "Building wheels for collected packages: bnunicodenormalizer, umap-learn, unidic-lite, bnnumerizer, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, pynndescent, gruut, jsonmerge, docopt, pathtools\n",
            "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.1-py3-none-any.whl size=21895 sha256=1a76ae1b7c7ef8db654690e790e10c6b2389c809ccb68a50f3fb71f99bea1938\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/f6/01/9e68ecec7c7ea85fc9431cfac42eba1c5a5f6debe5070de5c7\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76548 sha256=0e5ee0f624557f8a09f49d0c735af1298bf54eaa371dd1ffe0cfbf1c7fb48b17\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/21/8e/802cb9c4c606a67139f538cb17bf3bf1b98b739a7900469953\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=b0afb3ab444f92ec77719a7a8e9cb0bad2a1e66d1cb0d463df597bcd1be2af19\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5259 sha256=e05cfc0c1a86bc4063f48ba65fd0969e41deeb8307bda936ee3efa9ffff3efc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104870 sha256=8c0c6deaf1533be39f7694b347b1057f29c927021ab74bb09a96cde8664b5f66\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498182 sha256=b8483b88f8ac86c5f005e2233cb6a1a080465b2cce1369f070332a324215c977\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297178 sha256=53b2e7f26a0ee49ab4f2e326a6e0c66d4af828063ecd0c07da9f6747342bf3fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173796 sha256=82900b1c9f5787f1c71fe2cb19d4371a37a27a8295e75c65d642b91f75783381\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=102655581536578c7fc75650c3ae4010c93b249aa7b9f3d1e15b9303b90a2a3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=819e3639e3c609c3d676e99d9859ad856de904b043e8d39ccb9405e6ce990560\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75799 sha256=6fe2c7c324ab38acd9ae9da551e04a2fcba39d5b10d27973a9190d64a2ed5060\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "  Building wheel for jsonmerge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonmerge: filename=jsonmerge-1.9.0-py3-none-any.whl size=18608 sha256=4b2bc82030246f7441ae9a788c36eaea9c4d7ea60f5eb75eb22ef2f64cd75883\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/30/22/18d39219b08402f26539c3e72a132353a31f49204ff35c8d8e\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=c1a5358378c0a84c2021c6676c2af9794d6b4460fca156a5398b9df524b22abd\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=a6dcca71cbeff7f47429d09380cde5393e04c9714368d26fbab20de8b1bddf02\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built bnunicodenormalizer umap-learn unidic-lite bnnumerizer gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr pynndescent gruut jsonmerge docopt pathtools\n",
            "Installing collected packages: unidic-lite, trampoline, tokenizers, resize-right, python-crfsuite, pathtools, mecab-python3, jamo, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, boltons, bnunicodenormalizer, bnnumerizer, bangla, smmap, setproctitle, sentry-sdk, pysbd, pypinyin, protobuf, num2words, networkx, multidict, jsonlines, inflect, gruut-ipa, ftfy, frozenlist, einops, docker-pycreds, cython, coqpit, async-timeout, anyascii, yarl, tensorboardX, jsonmerge, huggingface-hub, gitdb, g2pkk, aiosignal, transformers, pynndescent, GitPython, dateparser, aiohttp, wandb, umap-learn, gruut, torchsde, torchdiffeq, kornia, clip-anytorch, clean-fid, accelerate, trainer, k-diffusion, TTS\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 6.0.4\n",
            "    Uninstalling inflect-6.0.4:\n",
            "      Successfully uninstalled inflect-6.0.4\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 0.29.34\n",
            "    Uninstalling Cython-0.29.34:\n",
            "      Successfully uninstalled Cython-0.29.34\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 TTS-0.14.0 accelerate-0.19.0 aiohttp-3.8.4 aiosignal-1.3.1 anyascii-0.3.2 async-timeout-4.0.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.1 boltons-23.0.0 clean-fid-0.1.35 clip-anytorch-2.5.2 coqpit-0.0.17 cython-0.29.28 dateparser-1.1.8 docker-pycreds-0.4.0 docopt-0.6.2 einops-0.6.1 frozenlist-1.3.3 ftfy-6.1.1 g2pkk-0.1.2 gitdb-4.0.10 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 huggingface-hub-0.14.1 inflect-5.6.0 jamo-0.4.1 jsonlines-1.2.0 jsonmerge-1.9.0 k-diffusion-0.0.14 kornia-0.6.12 mecab-python3-1.0.5 multidict-6.0.4 networkx-2.8.8 num2words-0.5.12 pathtools-0.1.2 protobuf-3.19.6 pynndescent-0.5.10 pypinyin-0.49.0 pysbd-0.3.4 python-crfsuite-0.9.9 resize-right-0.0.2 sentry-sdk-1.23.0 setproctitle-1.3.2 smmap-5.0.0 tensorboardX-2.6 tokenizers-0.13.3 torchdiffeq-0.2.3 torchsde-0.2.5 trainer-0.0.20 trampoline-0.1.2 transformers-4.29.1 umap-learn-0.5.1 unidic-lite-1.0.8 wandb-0.15.2 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install TTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "DUbgCLgWTFDl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig"
      ],
      "metadata": {
        "id": "QHL5iARoc9Nt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BaseDatasetConfig provides a configuration template for managing dataset-related settings in text-to-speech (TTS) applications"
      ],
      "metadata": {
        "id": "ZfOYff9dno_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"tts_train_dir\"\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)"
      ],
      "metadata": {
        "id": "dpKnfrz2ny7D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O tts_train_dir/LJSpeech-1.1.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcFYNNWnoqj9",
        "outputId": "2be4583d-5311-4061-92ae-aa8668c0c3f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-16 17:29:50--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "Resolving data.keithito.com (data.keithito.com)... 174.138.79.61\n",
            "Connecting to data.keithito.com (data.keithito.com)|174.138.79.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2748572632 (2.6G) [application/octet-stream]\n",
            "Saving to: ‘tts_train_dir/LJSpeech-1.1.tar.bz2’\n",
            "\n",
            "tts_train_dir/LJSpe 100%[===================>]   2.56G  95.8MB/s    in 30s     \n",
            "\n",
            "2023-05-16 17:30:20 (87.2 MB/s) - ‘tts_train_dir/LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf tts_train_dir/LJSpeech-1.1.tar.bz2"
      ],
      "metadata": {
        "id": "wsP_dRobqMwW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=\"/content/LJSpeech-1.1\")"
      ],
      "metadata": {
        "id": "ObxUcNy1qbs8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.configs.tacotron_config import TacotronConfig\n",
        "\n",
        "config = TacotronConfig(\n",
        "    batch_size=32,\n",
        "    eval_batch_size=16,\n",
        "    num_loader_workers=4,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,  #This value means that testing will be performed immediately without any delay after each epoch of training. The value -1 indicates that there is no specific number of epochs to wait before starting the testing phase.\n",
        "    epochs=100,\n",
        "    text_cleaner=\"phoneme_cleaners\", \n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=25,\n",
        "    print_eval=False,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    save_step=1000,\n",
        ")\n"
      ],
      "metadata": {
        "id": "Uv3DYidkrQ3-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: A text cleaner is responsible for performing various text normalization operations to convert the raw input text into a cleaner representation suitable for TTS processing. The \"phoneme_cleaners\" text cleaner is likely designed to convert the input text into phonemes, which are the smallest units of sound in a language.\n",
        "\n",
        "By using the \"phoneme_cleaners\" text cleaner, the TTS model will work with phoneme sequences instead of raw text, enabling it to generate speech that corresponds to the phonetic representation of the input text."
      ],
      "metadata": {
        "id": "qMUopQqDA0c7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will initialize the audio processor using AudioProcessor class, responsible for handling feature extraction from audio and performing audio I/O operations."
      ],
      "metadata": {
        "id": "5PeAMEDceyoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.utils.audio import AudioProcessor\n",
        "ap = AudioProcessor.init_from_config(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-4Fk3vt5IEN",
        "outputId": "c6d0c6e0-f7ad-40e2-baa4-54cfe84a3954"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will initialize the tokenizer which is used to convert text to sequences of token IDs. If characters are not defined in the config, default characters are passed to the config."
      ],
      "metadata": {
        "id": "583l9ghThdg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)"
      ],
      "metadata": {
        "id": "KAL4ctJzgEPI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will load data samples. Each sample is a list of [text, audio_file_path, speaker_name]."
      ],
      "metadata": {
        "id": "AJ2Cakybht0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.datasets import load_tts_samples\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size=config.eval_split_size,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C_l9xIlhhf5",
        "outputId": "e0246f0f-d066-49fc-b250-30a0ddbf5e73"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Found 13100 files in /content/LJSpeech-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.models.tacotron import Tacotron\n",
        "model = Tacotron(config, ap, tokenizer, speaker_manager=None)"
      ],
      "metadata": {
        "id": "0zT4eGj1hxl6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trainer import Trainer, TrainerArgs\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
        ")"
      ],
      "metadata": {
        "id": "7P_0CjpUh5lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86iYqxrriCul",
        "outputId": "301394b8-a247-4766-9d40-f5adc0f4ee9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
            " --> tts_train_dir/run-May-16-2023_05+34PM-0000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Pre-computing phonemes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 4/12969 [00:00<37:57,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ɪnstɛd əv weɪtɪŋ ðɛɹ, ɔzwɔld əpɛɹəntli wɛnt æz fɑɹ əweɪ æz hi kʊd ænd bɔɹdɪd ðə fɚst oʊk klɪf bʌs wɪt͡ʃ keɪm əlɔŋ\n",
            " [!] Character '͡' not found in the vocabulary. Discarding it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 2059/12969 [01:21<05:04, 35.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n",
            " [!] Character '“' not found in the vocabulary. Discarding it.\n",
            "ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n",
            " [!] Character '”' not found in the vocabulary. Discarding it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12969/12969 [05:02<00:00, 42.93it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-16 17:40:09) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "\u001b[1m   --> STEP: 0/406 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > decoder_loss: 3.96578  (3.96578)\n",
            "     | > postnet_loss: 2.70405  (2.70405)\n",
            "     | > stopnet_loss: 0.76831  (0.76831)\n",
            "     | > ga_loss: 0.02065  (0.02065)\n",
            "     | > decoder_diff_spec_loss: 0.20948  (0.20948)\n",
            "     | > postnet_diff_spec_loss: 0.45940  (0.45940)\n",
            "     | > decoder_ssim_loss: 0.89874  (0.89874)\n",
            "     | > postnet_ssim_loss: 0.87623  (0.87623)\n",
            "     | > loss: 3.14995  (3.14995)\n",
            "     | > align_error: 0.94115  (0.94115)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.60614  (1.60614)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 6.41410  (6.41414)\n",
            "     | > loader_time: 3.52430  (3.52430)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 25/406 -- GLOBAL_STEP: 25\u001b[0m\n",
            "     | > decoder_loss: 4.27260  (4.10153)\n",
            "     | > postnet_loss: 2.65782  (2.60968)\n",
            "     | > stopnet_loss: 0.78761  (0.78038)\n",
            "     | > ga_loss: 0.00844  (0.01072)\n",
            "     | > decoder_diff_spec_loss: 0.21689  (0.22054)\n",
            "     | > postnet_diff_spec_loss: 0.45849  (0.46759)\n",
            "     | > decoder_ssim_loss: 0.94964  (0.94831)\n",
            "     | > postnet_ssim_loss: 0.94392  (0.93759)\n",
            "     | > loss: 3.20466  (3.15528)\n",
            "     | > align_error: 0.97361  (0.96762)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.73147  (1.69428)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.21090  (1.24668)\n",
            "     | > loader_time: 0.01390  (0.01269)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 50/406 -- GLOBAL_STEP: 50\u001b[0m\n",
            "     | > decoder_loss: 4.26662  (4.12255)\n",
            "     | > postnet_loss: 2.62929  (2.59894)\n",
            "     | > stopnet_loss: 0.78487  (0.78301)\n",
            "     | > ga_loss: 0.00653  (0.00882)\n",
            "     | > decoder_diff_spec_loss: 0.21358  (0.22178)\n",
            "     | > postnet_diff_spec_loss: 0.45366  (0.46744)\n",
            "     | > decoder_ssim_loss: 0.95233  (0.95012)\n",
            "     | > postnet_ssim_loss: 0.94158  (0.94043)\n",
            "     | > loss: 3.18176  (3.15244)\n",
            "     | > align_error: 0.97904  (0.97293)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.73579  (1.70916)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.44400  (1.35192)\n",
            "     | > loader_time: 0.01340  (0.01480)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 75/406 -- GLOBAL_STEP: 75\u001b[0m\n",
            "     | > decoder_loss: 4.30257  (4.17464)\n",
            "     | > postnet_loss: 2.65591  (2.60429)\n",
            "     | > stopnet_loss: 0.79096  (0.78475)\n",
            "     | > ga_loss: 0.00540  (0.00777)\n",
            "     | > decoder_diff_spec_loss: 0.22164  (0.22247)\n",
            "     | > postnet_diff_spec_loss: 0.46481  (0.46701)\n",
            "     | > decoder_ssim_loss: 0.95176  (0.95064)\n",
            "     | > postnet_ssim_loss: 0.94342  (0.94147)\n",
            "     | > loss: 3.20301  (3.16375)\n",
            "     | > align_error: 0.98106  (0.97590)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.74528  (1.72066)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.47000  (1.48674)\n",
            "     | > loader_time: 0.01540  (0.01652)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 100/406 -- GLOBAL_STEP: 100\u001b[0m\n",
            "     | > decoder_loss: 4.18277  (4.20753)\n",
            "     | > postnet_loss: 2.60753  (2.60878)\n",
            "     | > stopnet_loss: 0.78910  (0.78610)\n",
            "     | > ga_loss: 0.00461  (0.00706)\n",
            "     | > decoder_diff_spec_loss: 0.22424  (0.22289)\n",
            "     | > postnet_diff_spec_loss: 0.46993  (0.46657)\n",
            "     | > decoder_ssim_loss: 0.95271  (0.95083)\n",
            "     | > postnet_ssim_loss: 0.92939  (0.93841)\n",
            "     | > loss: 3.15380  (3.17015)\n",
            "     | > align_error: 0.98539  (0.97802)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.74936  (1.72897)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.58680  (1.59587)\n",
            "     | > loader_time: 0.01800  (0.01809)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 125/406 -- GLOBAL_STEP: 125\u001b[0m\n",
            "     | > decoder_loss: 4.41435  (4.23668)\n",
            "     | > postnet_loss: 2.69196  (2.61163)\n",
            "     | > stopnet_loss: 0.79324  (0.78706)\n",
            "     | > ga_loss: 0.00429  (0.00653)\n",
            "     | > decoder_diff_spec_loss: 0.22062  (0.22315)\n",
            "     | > postnet_diff_spec_loss: 0.46281  (0.46642)\n",
            "     | > decoder_ssim_loss: 0.95139  (0.95098)\n",
            "     | > postnet_ssim_loss: 0.92668  (0.93616)\n",
            "     | > loss: 3.23164  (3.17597)\n",
            "     | > align_error: 0.98592  (0.97955)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76090  (1.73507)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.61620  (1.69056)\n",
            "     | > loader_time: 0.01780  (0.01966)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 150/406 -- GLOBAL_STEP: 150\u001b[0m\n",
            "     | > decoder_loss: 4.29571  (4.26379)\n",
            "     | > postnet_loss: 2.61259  (2.61427)\n",
            "     | > stopnet_loss: 0.79186  (0.78788)\n",
            "     | > ga_loss: 0.00388  (0.00613)\n",
            "     | > decoder_diff_spec_loss: 0.22936  (0.22338)\n",
            "     | > postnet_diff_spec_loss: 0.47186  (0.46619)\n",
            "     | > decoder_ssim_loss: 0.95037  (0.95100)\n",
            "     | > postnet_ssim_loss: 0.92754  (0.93466)\n",
            "     | > loss: 3.18313  (3.18183)\n",
            "     | > align_error: 0.98775  (0.98068)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76319  (1.74013)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.00870  (1.77730)\n",
            "     | > loader_time: 0.04540  (0.02078)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 175/406 -- GLOBAL_STEP: 175\u001b[0m\n",
            "     | > decoder_loss: 4.39275  (4.27760)\n",
            "     | > postnet_loss: 2.63311  (2.61621)\n",
            "     | > stopnet_loss: 0.78865  (0.78825)\n",
            "     | > ga_loss: 0.00365  (0.00579)\n",
            "     | > decoder_diff_spec_loss: 0.22130  (0.22343)\n",
            "     | > postnet_diff_spec_loss: 0.46145  (0.46595)\n",
            "     | > decoder_ssim_loss: 0.94982  (0.95095)\n",
            "     | > postnet_ssim_loss: 0.92518  (0.93356)\n",
            "     | > loss: 3.20283  (3.18414)\n",
            "     | > align_error: 0.98901  (0.98164)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76551  (1.74283)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.46380  (1.87296)\n",
            "     | > loader_time: 0.02230  (0.02232)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 200/406 -- GLOBAL_STEP: 200\u001b[0m\n",
            "     | > decoder_loss: 4.44062  (4.29429)\n",
            "     | > postnet_loss: 2.61786  (2.61913)\n",
            "     | > stopnet_loss: 0.79301  (0.78881)\n",
            "     | > ga_loss: 0.00340  (0.00551)\n",
            "     | > decoder_diff_spec_loss: 0.22544  (0.22336)\n",
            "     | > postnet_diff_spec_loss: 0.46411  (0.46552)\n",
            "     | > decoder_ssim_loss: 0.95038  (0.95086)\n",
            "     | > postnet_ssim_loss: 0.92673  (0.93265)\n",
            "     | > loss: 3.21631  (3.18784)\n",
            "     | > align_error: 0.98823  (0.98248)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.77238  (1.74585)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 3.90590  (1.95495)\n",
            "     | > loader_time: 0.02440  (0.02329)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 225/406 -- GLOBAL_STEP: 225\u001b[0m\n",
            "     | > decoder_loss: 4.49035  (4.31081)\n",
            "     | > postnet_loss: 2.59768  (2.62155)\n",
            "     | > stopnet_loss: 0.79156  (0.78921)\n",
            "     | > ga_loss: 0.00326  (0.00527)\n",
            "     | > decoder_diff_spec_loss: 0.22143  (0.22346)\n",
            "     | > postnet_diff_spec_loss: 0.46038  (0.46538)\n",
            "     | > decoder_ssim_loss: 0.94917  (0.95078)\n",
            "     | > postnet_ssim_loss: 0.92343  (0.93189)\n",
            "     | > loss: 3.21848  (3.19154)\n",
            "     | > align_error: 0.98855  (0.98319)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.77361  (1.74889)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 4.16940  (2.03882)\n",
            "     | > loader_time: 0.05640  (0.02476)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 250/406 -- GLOBAL_STEP: 250\u001b[0m\n",
            "     | > decoder_loss: 4.55871  (4.32372)\n",
            "     | > postnet_loss: 2.70685  (2.62478)\n",
            "     | > stopnet_loss: 0.79083  (0.78963)\n",
            "     | > ga_loss: 0.00322  (0.00506)\n",
            "     | > decoder_diff_spec_loss: 0.21863  (0.22345)\n",
            "     | > postnet_diff_spec_loss: 0.45639  (0.46516)\n",
            "     | > decoder_ssim_loss: 0.95168  (0.95070)\n",
            "     | > postnet_ssim_loss: 0.92551  (0.93132)\n",
            "     | > loss: 3.26135  (3.19473)\n",
            "     | > align_error: 0.98898  (0.98383)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76933  (1.75116)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.58820  (2.11932)\n",
            "     | > loader_time: 0.03760  (0.02578)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 275/406 -- GLOBAL_STEP: 275\u001b[0m\n",
            "     | > decoder_loss: 4.43447  (4.33360)\n",
            "     | > postnet_loss: 2.65313  (2.62657)\n",
            "     | > stopnet_loss: 0.79304  (0.78995)\n",
            "     | > ga_loss: 0.00294  (0.00488)\n",
            "     | > decoder_diff_spec_loss: 0.22323  (0.22342)\n",
            "     | > postnet_diff_spec_loss: 0.46387  (0.46496)\n",
            "     | > decoder_ssim_loss: 0.94941  (0.95060)\n",
            "     | > postnet_ssim_loss: 0.92512  (0.93083)\n",
            "     | > loss: 3.22004  (3.19683)\n",
            "     | > align_error: 0.99040  (0.98439)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.77089  (1.75309)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.48430  (2.19225)\n",
            "     | > loader_time: 0.05240  (0.02666)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 300/406 -- GLOBAL_STEP: 300\u001b[0m\n",
            "     | > decoder_loss: 4.30243  (4.34293)\n",
            "     | > postnet_loss: 2.60867  (2.62855)\n",
            "     | > stopnet_loss: 0.79272  (0.79028)\n",
            "     | > ga_loss: 0.00280  (0.00471)\n",
            "     | > decoder_diff_spec_loss: 0.22235  (0.22341)\n",
            "     | > postnet_diff_spec_loss: 0.46190  (0.46479)\n",
            "     | > decoder_ssim_loss: 0.95022  (0.95054)\n",
            "     | > postnet_ssim_loss: 0.92647  (0.93042)\n",
            "     | > loss: 3.17475  (3.19899)\n",
            "     | > align_error: 0.99046  (0.98490)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75666  (1.75475)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 3.05610  (2.27031)\n",
            "     | > loader_time: 0.05880  (0.02780)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 325/406 -- GLOBAL_STEP: 325\u001b[0m\n",
            "     | > decoder_loss: 4.43274  (4.35049)\n",
            "     | > postnet_loss: 2.64432  (2.62987)\n",
            "     | > stopnet_loss: 0.79227  (0.79060)\n",
            "     | > ga_loss: 0.00266  (0.00456)\n",
            "     | > decoder_diff_spec_loss: 0.22248  (0.22345)\n",
            "     | > postnet_diff_spec_loss: 0.46116  (0.46470)\n",
            "     | > decoder_ssim_loss: 0.94699  (0.95043)\n",
            "     | > postnet_ssim_loss: 0.92478  (0.93004)\n",
            "     | > loss: 3.21368  (3.20063)\n",
            "     | > align_error: 0.99090  (0.98535)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76529  (1.75634)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 4.71900  (2.34145)\n",
            "     | > loader_time: 0.02980  (0.02880)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 350/406 -- GLOBAL_STEP: 350\u001b[0m\n",
            "     | > decoder_loss: 4.57296  (4.36029)\n",
            "     | > postnet_loss: 2.65743  (2.63178)\n",
            "     | > stopnet_loss: 0.79474  (0.79084)\n",
            "     | > ga_loss: 0.00253  (0.00442)\n",
            "     | > decoder_diff_spec_loss: 0.22402  (0.22339)\n",
            "     | > postnet_diff_spec_loss: 0.46269  (0.46449)\n",
            "     | > decoder_ssim_loss: 0.95066  (0.95035)\n",
            "     | > postnet_ssim_loss: 0.92521  (0.92968)\n",
            "     | > loss: 3.25565  (3.20294)\n",
            "     | > align_error: 0.99173  (0.98577)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.79634  (1.75807)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 4.36330  (2.41237)\n",
            "     | > loader_time: 0.03120  (0.02959)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 375/406 -- GLOBAL_STEP: 375\u001b[0m\n",
            "     | > decoder_loss: 4.56143  (4.36874)\n",
            "     | > postnet_loss: 2.63890  (2.63333)\n",
            "     | > stopnet_loss: 0.79721  (0.79110)\n",
            "     | > ga_loss: 0.00251  (0.00429)\n",
            "     | > decoder_diff_spec_loss: 0.22035  (0.22334)\n",
            "     | > postnet_diff_spec_loss: 0.46003  (0.46431)\n",
            "     | > decoder_ssim_loss: 0.94906  (0.95028)\n",
            "     | > postnet_ssim_loss: 0.92374  (0.92937)\n",
            "     | > loss: 3.24814  (3.20491)\n",
            "     | > align_error: 0.99145  (0.98615)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.78574  (1.75987)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 4.77100  (2.49173)\n",
            "     | > loader_time: 0.06930  (0.03046)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 400/406 -- GLOBAL_STEP: 400\u001b[0m\n",
            "     | > decoder_loss: 4.63597  (4.37729)\n",
            "     | > postnet_loss: 2.66632  (2.63471)\n",
            "     | > stopnet_loss: 0.79627  (0.79131)\n",
            "     | > ga_loss: 0.00236  (0.00417)\n",
            "     | > decoder_diff_spec_loss: 0.22225  (0.22332)\n",
            "     | > postnet_diff_spec_loss: 0.46011  (0.46418)\n",
            "     | > decoder_ssim_loss: 0.94981  (0.95023)\n",
            "     | > postnet_ssim_loss: 0.92387  (0.92910)\n",
            "     | > loss: 3.27267  (3.20689)\n",
            "     | > align_error: 0.99227  (0.98652)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.79022  (1.76104)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.97070  (2.55296)\n",
            "     | > loader_time: 0.02910  (0.03108)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.01750 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_loss: 4.37734 \u001b[0m(+0.00000)\n",
            "     | > avg_postnet_loss: 2.61879 \u001b[0m(+0.00000)\n",
            "     | > avg_stopnet_loss: 0.84825 \u001b[0m(+0.00000)\n",
            "     | > avg_ga_loss: 0.00340 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_diff_spec_loss: 0.21481 \u001b[0m(+0.00000)\n",
            "     | > avg_postnet_diff_spec_loss: 0.46460 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_ssim_loss: 0.90404 \u001b[0m(+0.00000)\n",
            "     | > avg_postnet_ssim_loss: 0.88467 \u001b[0m(+0.00000)\n",
            "     | > avg_loss: 3.23131 \u001b[0m(+0.00000)\n",
            "     | > avg_align_error: 0.98966 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-16-2023_05+34PM-0000000/best_model_406.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/100\u001b[0m\n",
            " --> tts_train_dir/run-May-16-2023_05+34PM-0000000\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-16 18:09:22) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 19/406 -- GLOBAL_STEP: 425\u001b[0m\n",
            "     | > decoder_loss: 4.05089  (4.08964)\n",
            "     | > postnet_loss: 2.57635  (2.60934)\n",
            "     | > stopnet_loss: 0.78223  (0.77782)\n",
            "     | > ga_loss: 0.00858  (0.01151)\n",
            "     | > decoder_diff_spec_loss: 0.22725  (0.21952)\n",
            "     | > postnet_diff_spec_loss: 0.47503  (0.46762)\n",
            "     | > decoder_ssim_loss: 0.95224  (0.94702)\n",
            "     | > postnet_ssim_loss: 0.93842  (0.93564)\n",
            "     | > loss: 3.13020  (3.15257)\n",
            "     | > align_error: 0.97351  (0.96531)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.70772  (1.68014)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.93740  (1.02045)\n",
            "     | > loader_time: 0.02460  (0.02120)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 44/406 -- GLOBAL_STEP: 450\u001b[0m\n",
            "     | > decoder_loss: 4.16215  (4.10431)\n",
            "     | > postnet_loss: 2.61785  (2.59956)\n",
            "     | > stopnet_loss: 0.78413  (0.78220)\n",
            "     | > ga_loss: 0.00636  (0.00914)\n",
            "     | > decoder_diff_spec_loss: 0.22544  (0.22160)\n",
            "     | > postnet_diff_spec_loss: 0.46765  (0.46777)\n",
            "     | > decoder_ssim_loss: 0.94948  (0.94946)\n",
            "     | > postnet_ssim_loss: 0.94017  (0.93981)\n",
            "     | > loss: 3.15662  (3.14855)\n",
            "     | > align_error: 0.98097  (0.97208)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.72203  (1.70076)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.13780  (1.19554)\n",
            "     | > loader_time: 0.01700  (0.02308)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 69/406 -- GLOBAL_STEP: 475\u001b[0m\n",
            "     | > decoder_loss: 4.35028  (4.15931)\n",
            "     | > postnet_loss: 2.64453  (2.60218)\n",
            "     | > stopnet_loss: 0.78629  (0.78399)\n",
            "     | > ga_loss: 0.00554  (0.00798)\n",
            "     | > decoder_diff_spec_loss: 0.22922  (0.22213)\n",
            "     | > postnet_diff_spec_loss: 0.46908  (0.46712)\n",
            "     | > decoder_ssim_loss: 0.95183  (0.95006)\n",
            "     | > postnet_ssim_loss: 0.94348  (0.94100)\n",
            "     | > loss: 3.21110  (3.15934)\n",
            "     | > align_error: 0.98170  (0.97534)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.74310  (1.71317)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.70100  (1.35578)\n",
            "     | > loader_time: 0.05010  (0.02388)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 94/406 -- GLOBAL_STEP: 500\u001b[0m\n",
            "     | > decoder_loss: 4.32802  (4.20023)\n",
            "     | > postnet_loss: 2.61756  (2.60838)\n",
            "     | > stopnet_loss: 0.79357  (0.78541)\n",
            "     | > ga_loss: 0.00475  (0.00721)\n",
            "     | > decoder_diff_spec_loss: 0.22242  (0.22254)\n",
            "     | > postnet_diff_spec_loss: 0.46133  (0.46659)\n",
            "     | > decoder_ssim_loss: 0.95190  (0.95035)\n",
            "     | > postnet_ssim_loss: 0.92698  (0.93878)\n",
            "     | > loss: 3.19439  (3.16817)\n",
            "     | > align_error: 0.98446  (0.97757)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76122  (1.72214)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.56610  (1.46633)\n",
            "     | > loader_time: 0.01820  (0.02526)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 119/406 -- GLOBAL_STEP: 525\u001b[0m\n",
            "     | > decoder_loss: 4.43952  (4.22670)\n",
            "     | > postnet_loss: 2.66065  (2.61121)\n",
            "     | > stopnet_loss: 0.79056  (0.78632)\n",
            "     | > ga_loss: 0.00438  (0.00664)\n",
            "     | > decoder_diff_spec_loss: 0.22354  (0.22286)\n",
            "     | > postnet_diff_spec_loss: 0.46320  (0.46643)\n",
            "     | > decoder_ssim_loss: 0.95377  (0.95051)\n",
            "     | > postnet_ssim_loss: 0.92615  (0.93626)\n",
            "     | > loss: 3.22915  (3.17303)\n",
            "     | > align_error: 0.98616  (0.97922)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76671  (1.72817)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.71120  (1.57741)\n",
            "     | > loader_time: 0.01870  (0.02663)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 144/406 -- GLOBAL_STEP: 550\u001b[0m\n",
            "     | > decoder_loss: 4.36306  (4.25661)\n",
            "     | > postnet_loss: 2.62973  (2.61395)\n",
            "     | > stopnet_loss: 0.79306  (0.78724)\n",
            "     | > ga_loss: 0.00400  (0.00621)\n",
            "     | > decoder_diff_spec_loss: 0.22816  (0.22302)\n",
            "     | > postnet_diff_spec_loss: 0.46582  (0.46615)\n",
            "     | > decoder_ssim_loss: 0.95007  (0.95052)\n",
            "     | > postnet_ssim_loss: 0.92657  (0.93455)\n",
            "     | > loss: 3.20393  (3.17952)\n",
            "     | > align_error: 0.98671  (0.98043)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75764  (1.73378)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.67720  (1.67152)\n",
            "     | > loader_time: 0.02180  (0.02780)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 169/406 -- GLOBAL_STEP: 575\u001b[0m\n",
            "     | > decoder_loss: 4.30797  (4.27156)\n",
            "     | > postnet_loss: 2.66485  (2.61559)\n",
            "     | > stopnet_loss: 0.79007  (0.78781)\n",
            "     | > ga_loss: 0.00379  (0.00587)\n",
            "     | > decoder_diff_spec_loss: 0.22609  (0.22318)\n",
            "     | > postnet_diff_spec_loss: 0.46602  (0.46599)\n",
            "     | > decoder_ssim_loss: 0.95043  (0.95053)\n",
            "     | > postnet_ssim_loss: 0.92649  (0.93333)\n",
            "     | > loss: 3.19448  (3.18218)\n",
            "     | > align_error: 0.98761  (0.98143)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.74881  (1.73732)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 3.60870  (1.77700)\n",
            "     | > loader_time: 0.02800  (0.02885)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 194/406 -- GLOBAL_STEP: 600\u001b[0m\n",
            "     | > decoder_loss: 4.37826  (4.28780)\n",
            "     | > postnet_loss: 2.64881  (2.61846)\n",
            "     | > stopnet_loss: 0.79076  (0.78823)\n",
            "     | > ga_loss: 0.00357  (0.00558)\n",
            "     | > decoder_diff_spec_loss: 0.22191  (0.22313)\n",
            "     | > postnet_diff_spec_loss: 0.46247  (0.46560)\n",
            "     | > decoder_ssim_loss: 0.94924  (0.95043)\n",
            "     | > postnet_ssim_loss: 0.92673  (0.93236)\n",
            "     | > loss: 3.20545  (3.18555)\n",
            "     | > align_error: 0.98927  (0.98229)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75308  (1.74005)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.99950  (1.85338)\n",
            "     | > loader_time: 0.02570  (0.02942)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 219/406 -- GLOBAL_STEP: 625\u001b[0m\n",
            "     | > decoder_loss: 4.37525  (4.30380)\n",
            "     | > postnet_loss: 2.64322  (2.62085)\n",
            "     | > stopnet_loss: 0.79418  (0.78866)\n",
            "     | > ga_loss: 0.00322  (0.00533)\n",
            "     | > decoder_diff_spec_loss: 0.22463  (0.22320)\n",
            "     | > postnet_diff_spec_loss: 0.46733  (0.46539)\n",
            "     | > decoder_ssim_loss: 0.94958  (0.95041)\n",
            "     | > postnet_ssim_loss: 0.92575  (0.93158)\n",
            "     | > loss: 3.20674  (3.18910)\n",
            "     | > align_error: 0.98971  (0.98304)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76009  (1.74320)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.11000  (1.94124)\n",
            "     | > loader_time: 0.02830  (0.03006)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 244/406 -- GLOBAL_STEP: 650\u001b[0m\n",
            "     | > decoder_loss: 4.37309  (4.31903)\n",
            "     | > postnet_loss: 2.60907  (2.62422)\n",
            "     | > stopnet_loss: 0.79044  (0.78901)\n",
            "     | > ga_loss: 0.00312  (0.00511)\n",
            "     | > decoder_diff_spec_loss: 0.22620  (0.22321)\n",
            "     | > postnet_diff_spec_loss: 0.46964  (0.46519)\n",
            "     | > decoder_ssim_loss: 0.94886  (0.95032)\n",
            "     | > postnet_ssim_loss: 0.92651  (0.93096)\n",
            "     | > loss: 3.19440  (3.19280)\n",
            "     | > align_error: 0.98952  (0.98369)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76422  (1.74545)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.31970  (2.02004)\n",
            "     | > loader_time: 0.05940  (0.03126)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 269/406 -- GLOBAL_STEP: 675\u001b[0m\n",
            "     | > decoder_loss: 4.47448  (4.32749)\n",
            "     | > postnet_loss: 2.66916  (2.62567)\n",
            "     | > stopnet_loss: 0.79343  (0.78931)\n",
            "     | > ga_loss: 0.00296  (0.00492)\n",
            "     | > decoder_diff_spec_loss: 0.22230  (0.22319)\n",
            "     | > postnet_diff_spec_loss: 0.46138  (0.46501)\n",
            "     | > decoder_ssim_loss: 0.94854  (0.95020)\n",
            "     | > postnet_ssim_loss: 0.92644  (0.93044)\n",
            "     | > loss: 3.23379  (3.19440)\n",
            "     | > align_error: 0.99030  (0.98427)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76557  (1.74734)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.29950  (2.09454)\n",
            "     | > loader_time: 0.06220  (0.03249)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 294/406 -- GLOBAL_STEP: 700\u001b[0m\n",
            "     | > decoder_loss: 4.49786  (4.33727)\n",
            "     | > postnet_loss: 2.67668  (2.62791)\n",
            "     | > stopnet_loss: 0.79551  (0.78959)\n",
            "     | > ga_loss: 0.00284  (0.00475)\n",
            "     | > decoder_diff_spec_loss: 0.21963  (0.22319)\n",
            "     | > postnet_diff_spec_loss: 0.45932  (0.46485)\n",
            "     | > decoder_ssim_loss: 0.94697  (0.95011)\n",
            "     | > postnet_ssim_loss: 0.92443  (0.92998)\n",
            "     | > loss: 3.24092  (3.19665)\n",
            "     | > align_error: 0.99070  (0.98479)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.77264  (1.74910)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 4.28610  (2.17478)\n",
            "     | > loader_time: 0.05950  (0.03347)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 319/406 -- GLOBAL_STEP: 725\u001b[0m\n",
            "     | > decoder_loss: 4.52959  (4.34555)\n",
            "     | > postnet_loss: 2.64440  (2.62938)\n",
            "     | > stopnet_loss: 0.79350  (0.78989)\n",
            "     | > ga_loss: 0.00269  (0.00459)\n",
            "     | > decoder_diff_spec_loss: 0.22257  (0.22319)\n",
            "     | > postnet_diff_spec_loss: 0.46047  (0.46472)\n",
            "     | > decoder_ssim_loss: 0.94857  (0.95002)\n",
            "     | > postnet_ssim_loss: 0.92332  (0.92959)\n",
            "     | > loss: 3.23918  (3.19847)\n",
            "     | > align_error: 0.99100  (0.98526)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.78268  (1.75069)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.64600  (2.24255)\n",
            "     | > loader_time: 0.07740  (0.03422)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 344/406 -- GLOBAL_STEP: 750\u001b[0m\n",
            "     | > decoder_loss: 4.40738  (4.35392)\n",
            "     | > postnet_loss: 2.62124  (2.63119)\n",
            "     | > stopnet_loss: 0.79291  (0.79006)\n",
            "     | > ga_loss: 0.00258  (0.00445)\n",
            "     | > decoder_diff_spec_loss: 0.21974  (0.22319)\n",
            "     | > postnet_diff_spec_loss: 0.46016  (0.46456)\n",
            "     | > decoder_ssim_loss: 0.94940  (0.94991)\n",
            "     | > postnet_ssim_loss: 0.92433  (0.92922)\n",
            "     | > loss: 3.20140  (3.20032)\n",
            "     | > align_error: 0.99156  (0.98568)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76859  (1.75225)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.69720  (2.31555)\n",
            "     | > loader_time: 0.03070  (0.03515)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 369/406 -- GLOBAL_STEP: 775\u001b[0m\n",
            "     | > decoder_loss: 4.40071  (4.36308)\n",
            "     | > postnet_loss: 2.60817  (2.63271)\n",
            "     | > stopnet_loss: 0.79015  (0.79031)\n",
            "     | > ga_loss: 0.00242  (0.00432)\n",
            "     | > decoder_diff_spec_loss: 0.22179  (0.22313)\n",
            "     | > postnet_diff_spec_loss: 0.46309  (0.46437)\n",
            "     | > decoder_ssim_loss: 0.94900  (0.94984)\n",
            "     | > postnet_ssim_loss: 0.92397  (0.92890)\n",
            "     | > loss: 3.19395  (3.20243)\n",
            "     | > align_error: 0.99286  (0.98607)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.77141  (1.75411)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.64160  (2.38741)\n",
            "     | > loader_time: 0.03220  (0.03598)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 394/406 -- GLOBAL_STEP: 800\u001b[0m\n",
            "     | > decoder_loss: 4.50269  (4.37079)\n",
            "     | > postnet_loss: 2.64972  (2.63391)\n",
            "     | > stopnet_loss: 0.79707  (0.79053)\n",
            "     | > ga_loss: 0.00237  (0.00420)\n",
            "     | > decoder_diff_spec_loss: 0.22474  (0.22309)\n",
            "     | > postnet_diff_spec_loss: 0.46553  (0.46422)\n",
            "     | > decoder_ssim_loss: 0.94990  (0.94979)\n",
            "     | > postnet_ssim_loss: 0.92389  (0.92863)\n",
            "     | > loss: 3.23805  (3.20414)\n",
            "     | > align_error: 0.99190  (0.98644)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.77991  (1.75532)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 3.01560  (2.46058)\n",
            "     | > loader_time: 0.08280  (0.03675)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.02225 \u001b[0m(+0.00474)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.37447 \u001b[0m(-0.00288)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.61854 \u001b[0m(-0.00026)\n",
            "     | > avg_stopnet_loss:\u001b[91m 0.85078 \u001b[0m(+0.00253)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00340 \u001b[0m(-0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.21468 \u001b[0m(-0.00013)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[91m 0.46461 \u001b[0m(+0.00001)\n",
            "     | > avg_decoder_ssim_loss:\u001b[91m 0.90414 \u001b[0m(+0.00010)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.88366 \u001b[0m(-0.00101)\n",
            "     | > avg_loss:\u001b[91m 3.23280 \u001b[0m(+0.00148)\n",
            "     | > avg_align_error:\u001b[91m 0.98967 \u001b[0m(+0.00001)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/100\u001b[0m\n",
            " --> tts_train_dir/run-May-16-2023_05+34PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-16 18:37:47) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 13/406 -- GLOBAL_STEP: 825\u001b[0m\n",
            "     | > decoder_loss: 4.11257  (4.07533)\n",
            "     | > postnet_loss: 2.61601  (2.61215)\n",
            "     | > stopnet_loss: 0.78558  (0.77654)\n",
            "     | > ga_loss: 0.00968  (0.01258)\n",
            "     | > decoder_diff_spec_loss: 0.21825  (0.21751)\n",
            "     | > postnet_diff_spec_loss: 0.46324  (0.46630)\n",
            "     | > decoder_ssim_loss: 0.95060  (0.94448)\n",
            "     | > postnet_ssim_loss: 0.94050  (0.93265)\n",
            "     | > loss: 3.15928  (3.15153)\n",
            "     | > align_error: 0.96955  (0.96235)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.70376  (1.66905)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.47900  (1.06405)\n",
            "     | > loader_time: 0.01100  (0.02020)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 38/406 -- GLOBAL_STEP: 850\u001b[0m\n",
            "     | > decoder_loss: 4.16503  (4.10439)\n",
            "     | > postnet_loss: 2.58850  (2.60210)\n",
            "     | > stopnet_loss: 0.78525  (0.78110)\n",
            "     | > ga_loss: 0.00698  (0.00955)\n",
            "     | > decoder_diff_spec_loss: 0.22204  (0.22100)\n",
            "     | > postnet_diff_spec_loss: 0.46888  (0.46787)\n",
            "     | > decoder_ssim_loss: 0.95070  (0.94877)\n",
            "     | > postnet_ssim_loss: 0.94241  (0.93903)\n",
            "     | > loss: 3.15454  (3.14964)\n",
            "     | > align_error: 0.97742  (0.97097)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.70529  (1.69391)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91050  (1.15372)\n",
            "     | > loader_time: 0.01230  (0.01970)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 63/406 -- GLOBAL_STEP: 875\u001b[0m\n",
            "     | > decoder_loss: 4.33091  (4.14267)\n",
            "     | > postnet_loss: 2.60241  (2.59962)\n",
            "     | > stopnet_loss: 0.78697  (0.78260)\n",
            "     | > ga_loss: 0.00568  (0.00821)\n",
            "     | > decoder_diff_spec_loss: 0.21937  (0.22167)\n",
            "     | > postnet_diff_spec_loss: 0.46029  (0.46727)\n",
            "     | > decoder_ssim_loss: 0.95274  (0.94950)\n",
            "     | > postnet_ssim_loss: 0.94175  (0.94032)\n",
            "     | > loss: 3.19221  (3.15392)\n",
            "     | > align_error: 0.98131  (0.97470)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.73537  (1.70538)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.30340  (1.31691)\n",
            "     | > loader_time: 0.01410  (0.02034)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 88/406 -- GLOBAL_STEP: 900\u001b[0m\n",
            "     | > decoder_loss: 4.21060  (4.18566)\n",
            "     | > postnet_loss: 2.60271  (2.60590)\n",
            "     | > stopnet_loss: 0.78636  (0.78412)\n",
            "     | > ga_loss: 0.00481  (0.00737)\n",
            "     | > decoder_diff_spec_loss: 0.22472  (0.22218)\n",
            "     | > postnet_diff_spec_loss: 0.46622  (0.46678)\n",
            "     | > decoder_ssim_loss: 0.95026  (0.94970)\n",
            "     | > postnet_ssim_loss: 0.92768  (0.93900)\n",
            "     | > loss: 3.15595  (3.16326)\n",
            "     | > align_error: 0.98454  (0.97710)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.72792  (1.71471)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.40830  (1.40897)\n",
            "     | > loader_time: 0.01570  (0.02145)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 113/406 -- GLOBAL_STEP: 925\u001b[0m\n",
            "     | > decoder_loss: 4.43220  (4.21515)\n",
            "     | > postnet_loss: 2.65179  (2.60983)\n",
            "     | > stopnet_loss: 0.78825  (0.78493)\n",
            "     | > ga_loss: 0.00450  (0.00676)\n",
            "     | > decoder_diff_spec_loss: 0.22040  (0.22251)\n",
            "     | > postnet_diff_spec_loss: 0.46170  (0.46656)\n",
            "     | > decoder_ssim_loss: 0.95089  (0.94982)\n",
            "     | > postnet_ssim_loss: 0.92556  (0.93620)\n",
            "     | > loss: 3.22140  (3.16874)\n",
            "     | > align_error: 0.98511  (0.97888)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75178  (1.72047)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.58370  (1.52848)\n",
            "     | > loader_time: 0.01810  (0.02268)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 138/406 -- GLOBAL_STEP: 950\u001b[0m\n",
            "     | > decoder_loss: 4.50379  (4.24589)\n",
            "     | > postnet_loss: 2.64452  (2.61319)\n",
            "     | > stopnet_loss: 0.78998  (0.78584)\n",
            "     | > ga_loss: 0.00420  (0.00630)\n",
            "     | > decoder_diff_spec_loss: 0.22392  (0.22259)\n",
            "     | > postnet_diff_spec_loss: 0.46372  (0.46614)\n",
            "     | > decoder_ssim_loss: 0.94938  (0.94991)\n",
            "     | > postnet_ssim_loss: 0.92604  (0.93425)\n",
            "     | > loss: 3.23885  (3.17535)\n",
            "     | > align_error: 0.98588  (0.98018)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75794  (1.72619)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91050  (1.62647)\n",
            "     | > loader_time: 0.02380  (0.02465)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 163/406 -- GLOBAL_STEP: 975\u001b[0m\n",
            "     | > decoder_loss: 4.43547  (4.26295)\n",
            "     | > postnet_loss: 2.68857  (2.61443)\n",
            "     | > stopnet_loss: 0.78978  (0.78642)\n",
            "     | > ga_loss: 0.00379  (0.00594)\n",
            "     | > decoder_diff_spec_loss: 0.22015  (0.22281)\n",
            "     | > postnet_diff_spec_loss: 0.46035  (0.46606)\n",
            "     | > decoder_ssim_loss: 0.94976  (0.94984)\n",
            "     | > postnet_ssim_loss: 0.92459  (0.93292)\n",
            "     | > loss: 3.22845  (3.17837)\n",
            "     | > align_error: 0.98673  (0.98121)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75053  (1.72959)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 3.43710  (1.72677)\n",
            "     | > loader_time: 0.04290  (0.02583)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 188/406 -- GLOBAL_STEP: 1000\u001b[0m\n",
            "     | > decoder_loss: 4.56265  (4.27879)\n",
            "     | > postnet_loss: 2.71888  (2.61744)\n",
            "     | > stopnet_loss: 0.78932  (0.78694)\n",
            "     | > ga_loss: 0.00381  (0.00564)\n",
            "     | > decoder_diff_spec_loss: 0.21782  (0.22278)\n",
            "     | > postnet_diff_spec_loss: 0.45561  (0.46571)\n",
            "     | > decoder_ssim_loss: 0.94914  (0.94975)\n",
            "     | > postnet_ssim_loss: 0.92263  (0.93188)\n",
            "     | > loss: 3.26506  (3.18171)\n",
            "     | > align_error: 0.98728  (0.98211)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75478  (1.73241)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.99560  (1.80901)\n",
            "     | > loader_time: 0.05510  (0.02714)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-16-2023_05+34PM-0000000/checkpoint_1000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 213/406 -- GLOBAL_STEP: 1025\u001b[0m\n",
            "     | > decoder_loss: 4.44869  (4.29446)\n",
            "     | > postnet_loss: 2.66137  (2.61981)\n",
            "     | > stopnet_loss: 0.78714  (0.78725)\n",
            "     | > ga_loss: 0.00329  (0.00538)\n",
            "     | > decoder_diff_spec_loss: 0.22460  (0.22283)\n",
            "     | > postnet_diff_spec_loss: 0.46235  (0.46542)\n",
            "     | > decoder_ssim_loss: 0.94882  (0.94966)\n",
            "     | > postnet_ssim_loss: 0.92313  (0.93099)\n",
            "     | > loss: 3.22084  (3.18493)\n",
            "     | > align_error: 0.98869  (0.98288)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75522  (1.73544)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.99550  (1.89002)\n",
            "     | > loader_time: 0.02550  (0.02806)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 238/406 -- GLOBAL_STEP: 1050\u001b[0m\n",
            "     | > decoder_loss: 4.55072  (4.30919)\n",
            "     | > postnet_loss: 2.67194  (2.62284)\n",
            "     | > stopnet_loss: 0.79138  (0.78753)\n",
            "     | > ga_loss: 0.00321  (0.00516)\n",
            "     | > decoder_diff_spec_loss: 0.22140  (0.22283)\n",
            "     | > postnet_diff_spec_loss: 0.46073  (0.46524)\n",
            "     | > decoder_ssim_loss: 0.95006  (0.94954)\n",
            "     | > postnet_ssim_loss: 0.92476  (0.93029)\n",
            "     | > loss: 3.25232  (3.18829)\n",
            "     | > align_error: 0.98912  (0.98356)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.76303  (1.73745)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.16260  (1.97156)\n",
            "     | > loader_time: 0.02970  (0.02886)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 263/406 -- GLOBAL_STEP: 1075\u001b[0m\n",
            "     | > decoder_loss: 4.40202  (4.31902)\n",
            "     | > postnet_loss: 2.65797  (2.62484)\n",
            "     | > stopnet_loss: 0.79150  (0.78779)\n",
            "     | > ga_loss: 0.00298  (0.00496)\n",
            "     | > decoder_diff_spec_loss: 0.22516  (0.22281)\n",
            "     | > postnet_diff_spec_loss: 0.46547  (0.46505)\n",
            "     | > decoder_ssim_loss: 0.94775  (0.94940)\n",
            "     | > postnet_ssim_loss: 0.92351  (0.92970)\n",
            "     | > loss: 3.21186  (3.19029)\n",
            "     | > align_error: 0.99015  (0.98415)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75835  (1.73922)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 3.27860  (2.05117)\n",
            "     | > loader_time: 0.02570  (0.02975)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 288/406 -- GLOBAL_STEP: 1100\u001b[0m\n",
            "     | > decoder_loss: 4.36887  (4.32836)\n",
            "     | > postnet_loss: 2.63211  (2.62683)\n",
            "     | > stopnet_loss: 0.78916  (0.78803)\n",
            "     | > ga_loss: 0.00280  (0.00478)\n",
            "     | > decoder_diff_spec_loss: 0.22052  (0.22279)\n",
            "     | > postnet_diff_spec_loss: 0.46384  (0.46490)\n",
            "     | > decoder_ssim_loss: 0.94832  (0.94930)\n",
            "     | > postnet_ssim_loss: 0.92476  (0.92919)\n",
            "     | > loss: 3.19277  (3.19229)\n",
            "     | > align_error: 0.99148  (0.98468)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.75142  (1.74073)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.93070  (2.13023)\n",
            "     | > loader_time: 0.06210  (0.03123)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n",
        "!tensorboard --logdir=tts_train_dir"
      ],
      "metadata": {
        "id": "zO5SHGMdiEJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "output_path = \"tts_train_dir\"\n",
        "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
        "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"
      ],
      "metadata": {
        "id": "tkT-9AGYiMF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tts --text \"Text for TTS\" \\\n",
        "      --model_path $test_ckpt \\\n",
        "      --config_path $test_config \\\n",
        "      --out_path out.wav"
      ],
      "metadata": {
        "id": "gIvjA16NiPJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"out.wav\")"
      ],
      "metadata": {
        "id": "BA8OhCk4iSBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cuYMUd3uifj0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}