{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qCS2atfAJ1Sb",
        "outputId": "fedd5b65-933d-4a1e-bf75-a1e068f048e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TTS\n",
            "  Downloading TTS-0.14.0-cp310-cp310-manylinux1_x86_64.whl (736 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m736.7/736.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cython==0.29.28 (from TTS)\n",
            "  Downloading Cython-0.29.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.1+cu118)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
            "Requirement already satisfied: librosa==0.10.0.* in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.0.post2)\n",
            "Collecting inflect==5.6.0 (from TTS)\n",
            "  Downloading inflect-5.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from TTS) (4.65.0)\n",
            "Collecting anyascii (from TTS)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0)\n",
            "Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.4.0)\n",
            "Collecting aiohttp (from TTS)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from TTS) (23.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.4)\n",
            "Collecting pysbd (from TTS)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn==0.5.1 (from TTS)\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
            "Collecting trainer==0.0.20 (from TTS)\n",
            "  Downloading trainer-0.0.20-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coqpit>=0.0.16 (from TTS)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
            "Collecting pypinyin (from TTS)\n",
            "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mecab-python3==1.0.5 (from TTS)\n",
            "  Downloading mecab_python3-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.1/581.1 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidic-lite==1.0.8 (from TTS)\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut[de,es,fr]==2.2.3 (from TTS)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Collecting bangla==0.0.2 (from TTS)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting bnnumerizer (from TTS)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer==0.1.1 (from TTS)\n",
            "  Downloading bnunicodenormalizer-0.1.1.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting k-diffusion (from TTS)\n",
            "  Downloading k_diffusion-0.0.14-py3-none-any.whl (25 kB)\n",
            "Collecting einops (from TTS)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from TTS)\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from TTS) (1.22.4)\n",
            "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.56.4)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.12.1)\n",
            "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num2words<1.0.0,>=0.5.10 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.2)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->TTS) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->TTS) (67.7.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer==0.0.20->TTS) (5.9.5)\n",
            "Collecting tensorboardX (from trainer==0.0.20->TTS)\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2 (from trainer==0.0.20->TTS)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynndescent>=0.5 (from umap-learn==0.5.1->TTS)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->TTS) (1.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (16.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->TTS)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->TTS)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->TTS)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->TTS)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->TTS)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (8.1.3)\n",
            "Collecting accelerate (from k-diffusion->TTS)\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clean-fid (from k-diffusion->TTS)\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->TTS)\n",
            "  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonmerge (from k-diffusion->TTS)\n",
            "  Downloading jsonmerge-1.9.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kornia (from k-diffusion->TTS)\n",
            "  Downloading kornia-0.6.12-py2.py3-none-any.whl (653 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.4/653.4 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (8.4.0)\n",
            "Collecting resize-right (from k-diffusion->TTS)\n",
            "  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.19.3)\n",
            "Collecting torchdiffeq (from k-diffusion->TTS)\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Collecting torchsde (from k-diffusion->TTS)\n",
            "  Downloading torchsde-0.2.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.15.1+cu118)\n",
            "Collecting wandb (from k-diffusion->TTS)\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (2.8.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->TTS) (2022.10.31)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TTS) (2022.7.1)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers->TTS)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->TTS) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->TTS)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m139.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (4.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->TTS) (2.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Collecting docopt>=0.6.2 (from num2words<1.0.0,>=0.5.10->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa==0.10.0.*->TTS) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.0.*->TTS) (3.1.0)\n",
            "Collecting ftfy (from clip-anytorch->k-diffusion->TTS)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->TTS) (4.3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (1.4.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->TTS) (1.3.0)\n",
            "Collecting boltons>=20.2.1 (from torchsde->k-diffusion->TTS)\n",
            "  Downloading boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trampoline>=0.1.2 (from torchsde->k-diffusion->TTS)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->k-diffusion->TTS)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->k-diffusion->TTS)\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->k-diffusion->TTS)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->k-diffusion->TTS)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->k-diffusion->TTS)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.19.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip-anytorch->k-diffusion->TTS) (0.2.6)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (0.1.0.post0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (2023.3)\n",
            "Building wheels for collected packages: bnunicodenormalizer, umap-learn, unidic-lite, bnnumerizer, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, pynndescent, gruut, jsonmerge, docopt, pathtools\n",
            "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.1-py3-none-any.whl size=21895 sha256=ee34e81ba68af73e5d98e47e368e2d345dcb63650c6eee206c9816ba3951ad8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/f6/01/9e68ecec7c7ea85fc9431cfac42eba1c5a5f6debe5070de5c7\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76548 sha256=e94e8783eddb4fffe129e546948fef5e3bbe037753a2d3fcd9cf986bab2005f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/21/8e/802cb9c4c606a67139f538cb17bf3bf1b98b739a7900469953\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=88e2ed16fb0806da9594e2bab203ec1a0728526594dd2018c4487edaae9051ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5259 sha256=9f83d3472370888010226367e73ddd58c1497db14435daba6d8c746d6538ffc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104870 sha256=3aafeeee4a85345265ddd2d965bbee0531476a613dc70644f2fc9752e77fe5cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498182 sha256=0563cf7e86a8d5c81664764bffab8e5ce2f90b633f83cb568412c6d8b639ffd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297178 sha256=b5243dc1720c7d20abf7a620d04f7944a03222838dfe2dbf47117e7f3decbe63\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173796 sha256=e66a701ed25ea56fd481fef7b5296893555d3e1958de8b966ab3f5d899ad288c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=faa44d0e63ba1fa42aa48bc408c3330c8346d7ff8ac5c2b81762cadbd7b43d67\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=49cae9a38715213756d4484c700adc1db8569dc6e2f0a414c5c45684b48bf096\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75799 sha256=decfb9c93ac31ec9210e2c9a01b7afb2f52b1bf29c0d113b760843f72df14a88\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "  Building wheel for jsonmerge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonmerge: filename=jsonmerge-1.9.0-py3-none-any.whl size=18608 sha256=cccf131a72f1b8257fc76f6770dc071c5ab817182d35900600fb38ef9ae97ad8\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/30/22/18d39219b08402f26539c3e72a132353a31f49204ff35c8d8e\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=9b648813555c20618379b284bcbf4af4a58270ba5d1dffba3a89a7e7ed08c8d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=20db8b3d536fe2f0e54b8a09c74a27cc79db897c50c79b702d0c8efc41c514a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built bnunicodenormalizer umap-learn unidic-lite bnnumerizer gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr pynndescent gruut jsonmerge docopt pathtools\n",
            "Installing collected packages: unidic-lite, trampoline, tokenizers, resize-right, python-crfsuite, pathtools, mecab-python3, jamo, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, boltons, bnunicodenormalizer, bnnumerizer, bangla, smmap, setproctitle, sentry-sdk, pysbd, pypinyin, protobuf, num2words, networkx, multidict, jsonlines, inflect, gruut-ipa, ftfy, frozenlist, einops, docker-pycreds, cython, coqpit, async-timeout, anyascii, yarl, tensorboardX, jsonmerge, huggingface-hub, gitdb, g2pkk, aiosignal, transformers, pynndescent, GitPython, dateparser, aiohttp, wandb, umap-learn, gruut, torchsde, torchdiffeq, kornia, clip-anytorch, clean-fid, accelerate, trainer, k-diffusion, TTS\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 6.0.4\n",
            "    Uninstalling inflect-6.0.4:\n",
            "      Successfully uninstalled inflect-6.0.4\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 0.29.34\n",
            "    Uninstalling Cython-0.29.34:\n",
            "      Successfully uninstalled Cython-0.29.34\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 TTS-0.14.0 accelerate-0.19.0 aiohttp-3.8.4 aiosignal-1.3.1 anyascii-0.3.2 async-timeout-4.0.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.1 boltons-23.0.0 clean-fid-0.1.35 clip-anytorch-2.5.2 coqpit-0.0.17 cython-0.29.28 dateparser-1.1.8 docker-pycreds-0.4.0 docopt-0.6.2 einops-0.6.1 frozenlist-1.3.3 ftfy-6.1.1 g2pkk-0.1.2 gitdb-4.0.10 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 huggingface-hub-0.14.1 inflect-5.6.0 jamo-0.4.1 jsonlines-1.2.0 jsonmerge-1.9.0 k-diffusion-0.0.14 kornia-0.6.12 mecab-python3-1.0.5 multidict-6.0.4 networkx-2.8.8 num2words-0.5.12 pathtools-0.1.2 protobuf-3.19.6 pynndescent-0.5.10 pypinyin-0.49.0 pysbd-0.3.4 python-crfsuite-0.9.9 resize-right-0.0.2 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 tensorboardX-2.6 tokenizers-0.13.3 torchdiffeq-0.2.3 torchsde-0.2.5 trainer-0.0.20 trampoline-0.1.2 transformers-4.29.2 umap-learn-0.5.1 unidic-lite-1.0.8 wandb-0.15.3 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install TTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "DUbgCLgWTFDl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig"
      ],
      "metadata": {
        "id": "QHL5iARoc9Nt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BaseDatasetConfig provides a configuration template for managing dataset-related settings in text-to-speech (TTS) applications"
      ],
      "metadata": {
        "id": "ZfOYff9dno_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"tts_train_dir\"\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)"
      ],
      "metadata": {
        "id": "dpKnfrz2ny7D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O tts_train_dir/LJSpeech-1.1.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcFYNNWnoqj9",
        "outputId": "d3f96344-58e8-4d70-9f1f-329801bb41c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-18 04:59:30--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "Resolving data.keithito.com (data.keithito.com)... 174.138.79.61\n",
            "Connecting to data.keithito.com (data.keithito.com)|174.138.79.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2748572632 (2.6G) [application/octet-stream]\n",
            "Saving to: ‘tts_train_dir/LJSpeech-1.1.tar.bz2’\n",
            "\n",
            "tts_train_dir/LJSpe 100%[===================>]   2.56G  13.5MB/s    in 3m 17s  \n",
            "\n",
            "2023-05-18 05:02:47 (13.3 MB/s) - ‘tts_train_dir/LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf tts_train_dir/LJSpeech-1.1.tar.bz2"
      ],
      "metadata": {
        "id": "wsP_dRobqMwW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=\"/content/LJSpeech-1.1\")"
      ],
      "metadata": {
        "id": "ObxUcNy1qbs8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.configs.tacotron_config import TacotronConfig\n",
        "\n",
        "config = TacotronConfig(\n",
        "    batch_size=32,\n",
        "    eval_batch_size=16,\n",
        "    num_loader_workers=4,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,  #This value means that testing will be performed immediately without any delay after each epoch of training. The value -1 indicates that there is no specific number of epochs to wait before starting the testing phase.\n",
        "    epochs=30,\n",
        "    text_cleaner=\"phoneme_cleaners\", \n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=25,\n",
        "    print_eval=False,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    save_step=1000,\n",
        ")\n"
      ],
      "metadata": {
        "id": "Uv3DYidkrQ3-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: A text cleaner is responsible for performing various text normalization operations to convert the raw input text into a cleaner representation suitable for TTS processing. The \"phoneme_cleaners\" text cleaner is likely designed to convert the input text into phonemes, which are the smallest units of sound in a language.\n",
        "\n",
        "By using the \"phoneme_cleaners\" text cleaner, the TTS model will work with phoneme sequences instead of raw text, enabling it to generate speech that corresponds to the phonetic representation of the input text."
      ],
      "metadata": {
        "id": "qMUopQqDA0c7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will initialize the audio processor using AudioProcessor class, responsible for handling feature extraction from audio and performing audio I/O operations."
      ],
      "metadata": {
        "id": "5PeAMEDceyoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.utils.audio import AudioProcessor\n",
        "ap = AudioProcessor.init_from_config(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-4Fk3vt5IEN",
        "outputId": "ebd546ed-7fbd-42dd-8ef0-1eb0e84db372"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will initialize the tokenizer which is used to convert text to sequences of token IDs. If characters are not defined in the config, default characters are passed to the config."
      ],
      "metadata": {
        "id": "583l9ghThdg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)"
      ],
      "metadata": {
        "id": "KAL4ctJzgEPI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will load data samples. Each sample is a list of [text, audio_file_path, speaker_name]."
      ],
      "metadata": {
        "id": "AJ2Cakybht0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.datasets import load_tts_samples\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size=config.eval_split_size,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C_l9xIlhhf5",
        "outputId": "929b0243-969b-455a-af7d-db4585f06596"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Found 13100 files in /content/LJSpeech-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.models.tacotron import Tacotron\n",
        "model = Tacotron(config, ap, tokenizer, speaker_manager=None)"
      ],
      "metadata": {
        "id": "0zT4eGj1hxl6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trainer import Trainer, TrainerArgs\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
        ")"
      ],
      "metadata": {
        "id": "7P_0CjpUh5lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bbf510e-2116-4f47-a2b6-10896a8af3b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " > Training Environment:\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 12\n",
            " | > Num. of Torch Threads: 6\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " > Start Tensorboard: tensorboard --logdir=tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            " > Model has 6803235 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86iYqxrriCul",
        "outputId": "5117543c-a6e1-489d-9c49-2ac986785737"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*] Pre-computing phonemes...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 4/12969 [00:00<31:21,  6.89it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ɪnstɛd əv weɪtɪŋ ðɛɹ, ɔzwɔld əpɛɹəntli wɛnt æz fɑɹ əweɪ æz hi kʊd ænd bɔɹdɪd ðə fɚst oʊk klɪf bʌs wɪt͡ʃ keɪm əlɔŋ\n",
            " [!] Character '͡' not found in the vocabulary. Discarding it.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 2059/12969 [01:13<05:24, 33.64it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n",
            " [!] Character '“' not found in the vocabulary. Discarding it.\n",
            "ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n",
            " [!] Character '”' not found in the vocabulary. Discarding it.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12969/12969 [04:33<00:00, 47.42it/s]\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 05:12:23) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "\u001b[1m   --> STEP: 0/406 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > decoder_loss: 3.97882  (3.97882)\n",
            "     | > postnet_loss: 2.70898  (2.70898)\n",
            "     | > stopnet_loss: 0.61887  (0.61887)\n",
            "     | > ga_loss: 0.02331  (0.02331)\n",
            "     | > decoder_diff_spec_loss: 0.20733  (0.20733)\n",
            "     | > postnet_diff_spec_loss: 0.45953  (0.45953)\n",
            "     | > decoder_ssim_loss: 0.91883  (0.91883)\n",
            "     | > postnet_ssim_loss: 0.88059  (0.88059)\n",
            "     | > loss: 3.02396  (3.02396)\n",
            "     | > align_error: 0.93653  (0.93653)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.28477  (1.28477)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 5.75590  (5.75590)\n",
            "     | > loader_time: 1.94010  (1.94012)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 25/406 -- GLOBAL_STEP: 25\u001b[0m\n",
            "     | > decoder_loss: 4.28448  (4.11276)\n",
            "     | > postnet_loss: 2.66348  (2.61520)\n",
            "     | > stopnet_loss: 0.62681  (0.62392)\n",
            "     | > ga_loss: 0.00851  (0.01111)\n",
            "     | > decoder_diff_spec_loss: 0.21323  (0.21740)\n",
            "     | > postnet_diff_spec_loss: 0.45860  (0.46768)\n",
            "     | > decoder_ssim_loss: 0.97031  (0.96730)\n",
            "     | > postnet_ssim_loss: 0.94600  (0.94089)\n",
            "     | > loss: 3.05336  (3.00976)\n",
            "     | > align_error: 0.97317  (0.96649)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38811  (1.35729)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.95940  (0.77287)\n",
            "     | > loader_time: 0.00900  (0.00755)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 50/406 -- GLOBAL_STEP: 50\u001b[0m\n",
            "     | > decoder_loss: 4.27697  (4.13352)\n",
            "     | > postnet_loss: 2.63491  (2.60442)\n",
            "     | > stopnet_loss: 0.62226  (0.62434)\n",
            "     | > ga_loss: 0.00650  (0.00901)\n",
            "     | > decoder_diff_spec_loss: 0.20999  (0.21847)\n",
            "     | > postnet_diff_spec_loss: 0.45373  (0.46753)\n",
            "     | > decoder_ssim_loss: 0.96668  (0.96806)\n",
            "     | > postnet_ssim_loss: 0.94424  (0.94361)\n",
            "     | > loss: 3.02638  (3.00331)\n",
            "     | > align_error: 0.97906  (0.97228)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.37418  (1.36738)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.93900  (0.85754)\n",
            "     | > loader_time: 0.01120  (0.00916)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 75/406 -- GLOBAL_STEP: 75\u001b[0m\n",
            "     | > decoder_loss: 4.31490  (4.18555)\n",
            "     | > postnet_loss: 2.66138  (2.60987)\n",
            "     | > stopnet_loss: 0.62361  (0.62454)\n",
            "     | > ga_loss: 0.00536  (0.00789)\n",
            "     | > decoder_diff_spec_loss: 0.21825  (0.21908)\n",
            "     | > postnet_diff_spec_loss: 0.46486  (0.46711)\n",
            "     | > decoder_ssim_loss: 0.96945  (0.96842)\n",
            "     | > postnet_ssim_loss: 0.94581  (0.94455)\n",
            "     | > loss: 3.04408  (3.01265)\n",
            "     | > align_error: 0.98114  (0.97546)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38484  (1.37570)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.13320  (0.93789)\n",
            "     | > loader_time: 0.01360  (0.01030)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 100/406 -- GLOBAL_STEP: 100\u001b[0m\n",
            "     | > decoder_loss: 4.19328  (4.21836)\n",
            "     | > postnet_loss: 2.61339  (2.61446)\n",
            "     | > stopnet_loss: 0.62692  (0.62498)\n",
            "     | > ga_loss: 0.00457  (0.00714)\n",
            "     | > decoder_diff_spec_loss: 0.22063  (0.21945)\n",
            "     | > postnet_diff_spec_loss: 0.47001  (0.46666)\n",
            "     | > decoder_ssim_loss: 0.97002  (0.96848)\n",
            "     | > postnet_ssim_loss: 0.93304  (0.94187)\n",
            "     | > loss: 2.99988  (3.01801)\n",
            "     | > align_error: 0.98539  (0.97769)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.39415  (1.38179)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.20580  (1.00447)\n",
            "     | > loader_time: 0.01420  (0.01123)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 125/406 -- GLOBAL_STEP: 125\u001b[0m\n",
            "     | > decoder_loss: 4.42558  (4.24752)\n",
            "     | > postnet_loss: 2.69820  (2.61737)\n",
            "     | > stopnet_loss: 0.62553  (0.62506)\n",
            "     | > ga_loss: 0.00426  (0.00659)\n",
            "     | > decoder_diff_spec_loss: 0.21695  (0.21967)\n",
            "     | > postnet_diff_spec_loss: 0.46288  (0.46651)\n",
            "     | > decoder_ssim_loss: 0.96665  (0.96851)\n",
            "     | > postnet_ssim_loss: 0.93257  (0.94000)\n",
            "     | > loss: 3.07253  (3.02291)\n",
            "     | > align_error: 0.98600  (0.97930)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.40053  (1.38610)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.22750  (1.05816)\n",
            "     | > loader_time: 0.01560  (0.01212)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 150/406 -- GLOBAL_STEP: 150\u001b[0m\n",
            "     | > decoder_loss: 4.30783  (4.27464)\n",
            "     | > postnet_loss: 2.61893  (2.62007)\n",
            "     | > stopnet_loss: 0.62732  (0.62514)\n",
            "     | > ga_loss: 0.00386  (0.00617)\n",
            "     | > decoder_diff_spec_loss: 0.22562  (0.21985)\n",
            "     | > postnet_diff_spec_loss: 0.47197  (0.46628)\n",
            "     | > decoder_ssim_loss: 0.96949  (0.96840)\n",
            "     | > postnet_ssim_loss: 0.93329  (0.93867)\n",
            "     | > loss: 3.02838  (3.02797)\n",
            "     | > align_error: 0.98783  (0.98049)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41125  (1.39003)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.46560  (1.10864)\n",
            "     | > loader_time: 0.01710  (0.01301)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 175/406 -- GLOBAL_STEP: 175\u001b[0m\n",
            "     | > decoder_loss: 4.40211  (4.28847)\n",
            "     | > postnet_loss: 2.63913  (2.62204)\n",
            "     | > stopnet_loss: 0.62803  (0.62511)\n",
            "     | > ga_loss: 0.00363  (0.00583)\n",
            "     | > decoder_diff_spec_loss: 0.21805  (0.21989)\n",
            "     | > postnet_diff_spec_loss: 0.46156  (0.46604)\n",
            "     | > decoder_ssim_loss: 0.96639  (0.96835)\n",
            "     | > postnet_ssim_loss: 0.93002  (0.93764)\n",
            "     | > loss: 3.05050  (3.02985)\n",
            "     | > align_error: 0.98909  (0.98149)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41521  (1.39182)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.59400  (1.15912)\n",
            "     | > loader_time: 0.01800  (0.01365)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 200/406 -- GLOBAL_STEP: 200\u001b[0m\n",
            "     | > decoder_loss: 4.45253  (4.30518)\n",
            "     | > postnet_loss: 2.62425  (2.62500)\n",
            "     | > stopnet_loss: 0.62364  (0.62516)\n",
            "     | > ga_loss: 0.00337  (0.00554)\n",
            "     | > decoder_diff_spec_loss: 0.22164  (0.21981)\n",
            "     | > postnet_diff_spec_loss: 0.46422  (0.46561)\n",
            "     | > decoder_ssim_loss: 0.96926  (0.96825)\n",
            "     | > postnet_ssim_loss: 0.93035  (0.93687)\n",
            "     | > loss: 3.05604  (3.03305)\n",
            "     | > align_error: 0.98832  (0.98236)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.40833  (1.39426)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.71260  (1.20898)\n",
            "     | > loader_time: 0.02000  (0.01433)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 225/406 -- GLOBAL_STEP: 225\u001b[0m\n",
            "     | > decoder_loss: 4.50114  (4.32170)\n",
            "     | > postnet_loss: 2.60387  (2.62745)\n",
            "     | > stopnet_loss: 0.62584  (0.62522)\n",
            "     | > ga_loss: 0.00324  (0.00529)\n",
            "     | > decoder_diff_spec_loss: 0.21770  (0.21989)\n",
            "     | > postnet_diff_spec_loss: 0.46048  (0.46547)\n",
            "     | > decoder_ssim_loss: 0.96535  (0.96816)\n",
            "     | > postnet_ssim_loss: 0.92921  (0.93620)\n",
            "     | > loss: 3.06147  (3.03641)\n",
            "     | > align_error: 0.98864  (0.98309)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41641  (1.39625)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.63300  (1.25718)\n",
            "     | > loader_time: 0.01990  (0.01499)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 250/406 -- GLOBAL_STEP: 250\u001b[0m\n",
            "     | > decoder_loss: 4.57055  (4.33459)\n",
            "     | > postnet_loss: 2.71286  (2.63071)\n",
            "     | > stopnet_loss: 0.62525  (0.62527)\n",
            "     | > ga_loss: 0.00319  (0.00508)\n",
            "     | > decoder_diff_spec_loss: 0.21482  (0.21986)\n",
            "     | > postnet_diff_spec_loss: 0.45650  (0.46525)\n",
            "     | > decoder_ssim_loss: 0.96743  (0.96806)\n",
            "     | > postnet_ssim_loss: 0.92929  (0.93565)\n",
            "     | > loss: 3.10404  (3.03920)\n",
            "     | > align_error: 0.98907  (0.98375)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41838  (1.39790)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.76980  (1.30554)\n",
            "     | > loader_time: 0.02090  (0.01561)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 275/406 -- GLOBAL_STEP: 275\u001b[0m\n",
            "     | > decoder_loss: 4.44708  (4.34454)\n",
            "     | > postnet_loss: 2.65935  (2.63252)\n",
            "     | > stopnet_loss: 0.62279  (0.62523)\n",
            "     | > ga_loss: 0.00292  (0.00489)\n",
            "     | > decoder_diff_spec_loss: 0.21963  (0.21983)\n",
            "     | > postnet_diff_spec_loss: 0.46397  (0.46505)\n",
            "     | > decoder_ssim_loss: 0.96941  (0.96799)\n",
            "     | > postnet_ssim_loss: 0.93133  (0.93519)\n",
            "     | > loss: 3.06006  (3.04095)\n",
            "     | > align_error: 0.99054  (0.98433)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41324  (1.39945)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.95040  (1.35196)\n",
            "     | > loader_time: 0.02210  (0.01621)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 300/406 -- GLOBAL_STEP: 300\u001b[0m\n",
            "     | > decoder_loss: 4.31377  (4.35387)\n",
            "     | > postnet_loss: 2.61456  (2.63452)\n",
            "     | > stopnet_loss: 0.62915  (0.62525)\n",
            "     | > ga_loss: 0.00279  (0.00472)\n",
            "     | > decoder_diff_spec_loss: 0.21890  (0.21981)\n",
            "     | > postnet_diff_spec_loss: 0.46196  (0.46488)\n",
            "     | > decoder_ssim_loss: 0.96687  (0.96790)\n",
            "     | > postnet_ssim_loss: 0.93116  (0.93481)\n",
            "     | > loss: 3.01989  (3.04280)\n",
            "     | > align_error: 0.99055  (0.98484)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.40760  (1.40062)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.76900  (1.39762)\n",
            "     | > loader_time: 0.02290  (0.01682)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 325/406 -- GLOBAL_STEP: 325\u001b[0m\n",
            "     | > decoder_loss: 4.44400  (4.36143)\n",
            "     | > postnet_loss: 2.65036  (2.63586)\n",
            "     | > stopnet_loss: 0.62756  (0.62531)\n",
            "     | > ga_loss: 0.00264  (0.00457)\n",
            "     | > decoder_diff_spec_loss: 0.21912  (0.21984)\n",
            "     | > postnet_diff_spec_loss: 0.46124  (0.46479)\n",
            "     | > decoder_ssim_loss: 0.96542  (0.96780)\n",
            "     | > postnet_ssim_loss: 0.92764  (0.93444)\n",
            "     | > loss: 3.05769  (3.04417)\n",
            "     | > align_error: 0.99097  (0.98531)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41153  (1.40150)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.98580  (1.44151)\n",
            "     | > loader_time: 0.03100  (0.01743)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 350/406 -- GLOBAL_STEP: 350\u001b[0m\n",
            "     | > decoder_loss: 4.58293  (4.37124)\n",
            "     | > postnet_loss: 2.66410  (2.63779)\n",
            "     | > stopnet_loss: 0.62868  (0.62537)\n",
            "     | > ga_loss: 0.00252  (0.00443)\n",
            "     | > decoder_diff_spec_loss: 0.22005  (0.21978)\n",
            "     | > postnet_diff_spec_loss: 0.46281  (0.46458)\n",
            "     | > decoder_ssim_loss: 0.96596  (0.96770)\n",
            "     | > postnet_ssim_loss: 0.92982  (0.93411)\n",
            "     | > loss: 3.09772  (3.04631)\n",
            "     | > align_error: 0.99178  (0.98574)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.43440  (1.40280)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.28320  (1.48586)\n",
            "     | > loader_time: 0.02540  (0.01804)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 375/406 -- GLOBAL_STEP: 375\u001b[0m\n",
            "     | > decoder_loss: 4.57408  (4.37971)\n",
            "     | > postnet_loss: 2.64515  (2.63936)\n",
            "     | > stopnet_loss: 0.62447  (0.62540)\n",
            "     | > ga_loss: 0.00249  (0.00430)\n",
            "     | > decoder_diff_spec_loss: 0.21677  (0.21971)\n",
            "     | > postnet_diff_spec_loss: 0.46011  (0.46440)\n",
            "     | > decoder_ssim_loss: 0.96522  (0.96764)\n",
            "     | > postnet_ssim_loss: 0.92760  (0.93382)\n",
            "     | > loss: 3.08415  (3.04805)\n",
            "     | > align_error: 0.99153  (0.98613)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.42638  (1.40403)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.16470  (1.52976)\n",
            "     | > loader_time: 0.02620  (0.01858)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 400/406 -- GLOBAL_STEP: 400\u001b[0m\n",
            "     | > decoder_loss: 4.64863  (4.38824)\n",
            "     | > postnet_loss: 2.67282  (2.64076)\n",
            "     | > stopnet_loss: 0.62574  (0.62541)\n",
            "     | > ga_loss: 0.00235  (0.00418)\n",
            "     | > decoder_diff_spec_loss: 0.21865  (0.21969)\n",
            "     | > postnet_diff_spec_loss: 0.46018  (0.46427)\n",
            "     | > decoder_ssim_loss: 0.96778  (0.96757)\n",
            "     | > postnet_ssim_loss: 0.92992  (0.93358)\n",
            "     | > loss: 3.11197  (3.04982)\n",
            "     | > align_error: 0.99234  (0.98650)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.42640  (1.40502)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.06970  (1.57225)\n",
            "     | > loader_time: 0.02800  (0.01918)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.01008 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_loss: 4.37915 \u001b[0m(+0.00000)\n",
            "     | > avg_postnet_loss: 2.62511 \u001b[0m(+0.00000)\n",
            "     | > avg_stopnet_loss: 0.59750 \u001b[0m(+0.00000)\n",
            "     | > avg_ga_loss: 0.00336 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_diff_spec_loss: 0.21606 \u001b[0m(+0.00000)\n",
            "     | > avg_postnet_diff_spec_loss: 0.46486 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_ssim_loss: 0.92656 \u001b[0m(+0.00000)\n",
            "     | > avg_postnet_ssim_loss: 0.89406 \u001b[0m(+0.00000)\n",
            "     | > avg_loss: 2.99075 \u001b[0m(+0.00000)\n",
            "     | > avg_align_error: 0.98973 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_406.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 05:34:07) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 19/406 -- GLOBAL_STEP: 425\u001b[0m\n",
            "     | > decoder_loss: 4.05945  (4.10091)\n",
            "     | > postnet_loss: 2.58180  (2.61486)\n",
            "     | > stopnet_loss: 0.61976  (0.62318)\n",
            "     | > ga_loss: 0.00869  (0.01201)\n",
            "     | > decoder_diff_spec_loss: 0.22404  (0.21650)\n",
            "     | > postnet_diff_spec_loss: 0.47513  (0.46770)\n",
            "     | > decoder_ssim_loss: 0.96654  (0.96647)\n",
            "     | > postnet_ssim_loss: 0.94286  (0.93912)\n",
            "     | > loss: 2.97566  (3.00961)\n",
            "     | > align_error: 0.97285  (0.96397)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.35533  (1.35080)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.69620  (0.60074)\n",
            "     | > loader_time: 0.00890  (0.00780)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 44/406 -- GLOBAL_STEP: 450\u001b[0m\n",
            "     | > decoder_loss: 4.17278  (4.11530)\n",
            "     | > postnet_loss: 2.62360  (2.60502)\n",
            "     | > stopnet_loss: 0.62793  (0.62368)\n",
            "     | > ga_loss: 0.00633  (0.00937)\n",
            "     | > decoder_diff_spec_loss: 0.22213  (0.21844)\n",
            "     | > postnet_diff_spec_loss: 0.46775  (0.46785)\n",
            "     | > decoder_ssim_loss: 0.96656  (0.96758)\n",
            "     | > postnet_ssim_loss: 0.94341  (0.94301)\n",
            "     | > loss: 3.00864  (2.99981)\n",
            "     | > align_error: 0.98084  (0.97135)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38409  (1.36250)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.88060  (0.71473)\n",
            "     | > loader_time: 0.01410  (0.00933)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 69/406 -- GLOBAL_STEP: 475\u001b[0m\n",
            "     | > decoder_loss: 4.36061  (4.17034)\n",
            "     | > postnet_loss: 2.65107  (2.60773)\n",
            "     | > stopnet_loss: 0.62428  (0.62377)\n",
            "     | > ga_loss: 0.00550  (0.00812)\n",
            "     | > decoder_diff_spec_loss: 0.22560  (0.21891)\n",
            "     | > postnet_diff_spec_loss: 0.46917  (0.46720)\n",
            "     | > decoder_ssim_loss: 0.96808  (0.96806)\n",
            "     | > postnet_ssim_loss: 0.94682  (0.94408)\n",
            "     | > loss: 3.05711  (3.00843)\n",
            "     | > align_error: 0.98166  (0.97485)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38569  (1.37121)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.98150  (0.80374)\n",
            "     | > loader_time: 0.01290  (0.01045)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 94/406 -- GLOBAL_STEP: 500\u001b[0m\n",
            "     | > decoder_loss: 4.33770  (4.21110)\n",
            "     | > postnet_loss: 2.62315  (2.61405)\n",
            "     | > stopnet_loss: 0.62156  (0.62396)\n",
            "     | > ga_loss: 0.00473  (0.00730)\n",
            "     | > decoder_diff_spec_loss: 0.21889  (0.21926)\n",
            "     | > postnet_diff_spec_loss: 0.46144  (0.46667)\n",
            "     | > decoder_ssim_loss: 0.96996  (0.96829)\n",
            "     | > postnet_ssim_loss: 0.93292  (0.94209)\n",
            "     | > loss: 3.03124  (3.01582)\n",
            "     | > align_error: 0.98447  (0.97722)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38998  (1.37728)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.12010  (0.87523)\n",
            "     | > loader_time: 0.01430  (0.01142)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 119/406 -- GLOBAL_STEP: 525\u001b[0m\n",
            "     | > decoder_loss: 4.44669  (4.23763)\n",
            "     | > postnet_loss: 2.66706  (2.61696)\n",
            "     | > stopnet_loss: 0.62319  (0.62397)\n",
            "     | > ga_loss: 0.00435  (0.00671)\n",
            "     | > decoder_diff_spec_loss: 0.21996  (0.21955)\n",
            "     | > postnet_diff_spec_loss: 0.46329  (0.46652)\n",
            "     | > decoder_ssim_loss: 0.96693  (0.96835)\n",
            "     | > postnet_ssim_loss: 0.93152  (0.94000)\n",
            "     | > loss: 3.06881  (3.01976)\n",
            "     | > align_error: 0.98616  (0.97895)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.40027  (1.38146)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.24120  (0.93252)\n",
            "     | > loader_time: 0.01630  (0.01223)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 144/406 -- GLOBAL_STEP: 550\u001b[0m\n",
            "     | > decoder_loss: 4.37260  (4.26753)\n",
            "     | > postnet_loss: 2.63572  (2.61975)\n",
            "     | > stopnet_loss: 0.62215  (0.62415)\n",
            "     | > ga_loss: 0.00397  (0.00626)\n",
            "     | > decoder_diff_spec_loss: 0.22461  (0.21967)\n",
            "     | > postnet_diff_spec_loss: 0.46594  (0.46624)\n",
            "     | > decoder_ssim_loss: 0.96888  (0.96826)\n",
            "     | > postnet_ssim_loss: 0.93152  (0.93849)\n",
            "     | > loss: 3.04181  (3.02545)\n",
            "     | > align_error: 0.98678  (0.98022)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.39393  (1.38535)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.27110  (0.99070)\n",
            "     | > loader_time: 0.01670  (0.01306)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 169/406 -- GLOBAL_STEP: 575\u001b[0m\n",
            "     | > decoder_loss: 4.32021  (4.28252)\n",
            "     | > postnet_loss: 2.67067  (2.62141)\n",
            "     | > stopnet_loss: 0.62428  (0.62432)\n",
            "     | > ga_loss: 0.00376  (0.00590)\n",
            "     | > decoder_diff_spec_loss: 0.22260  (0.21980)\n",
            "     | > postnet_diff_spec_loss: 0.46612  (0.46608)\n",
            "     | > decoder_ssim_loss: 0.96798  (0.96818)\n",
            "     | > postnet_ssim_loss: 0.93250  (0.93740)\n",
            "     | > loss: 3.03811  (3.02768)\n",
            "     | > align_error: 0.98769  (0.98126)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38911  (1.38771)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.32400  (1.03974)\n",
            "     | > loader_time: 0.01770  (0.01384)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 194/406 -- GLOBAL_STEP: 600\u001b[0m\n",
            "     | > decoder_loss: 4.38959  (4.29879)\n",
            "     | > postnet_loss: 2.65488  (2.62432)\n",
            "     | > stopnet_loss: 0.62187  (0.62436)\n",
            "     | > ga_loss: 0.00353  (0.00561)\n",
            "     | > decoder_diff_spec_loss: 0.21880  (0.21973)\n",
            "     | > postnet_diff_spec_loss: 0.46257  (0.46569)\n",
            "     | > decoder_ssim_loss: 0.96906  (0.96806)\n",
            "     | > postnet_ssim_loss: 0.93130  (0.93652)\n",
            "     | > loss: 3.04605  (3.03067)\n",
            "     | > align_error: 0.98939  (0.98216)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.40017  (1.38997)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.42320  (1.08946)\n",
            "     | > loader_time: 0.02380  (0.01450)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 219/406 -- GLOBAL_STEP: 625\u001b[0m\n",
            "     | > decoder_loss: 4.38674  (4.31477)\n",
            "     | > postnet_loss: 2.64896  (2.62674)\n",
            "     | > stopnet_loss: 0.62445  (0.62433)\n",
            "     | > ga_loss: 0.00320  (0.00535)\n",
            "     | > decoder_diff_spec_loss: 0.22119  (0.21979)\n",
            "     | > postnet_diff_spec_loss: 0.46742  (0.46548)\n",
            "     | > decoder_ssim_loss: 0.96818  (0.96795)\n",
            "     | > postnet_ssim_loss: 0.93023  (0.93583)\n",
            "     | > loss: 3.04615  (3.03371)\n",
            "     | > align_error: 0.98978  (0.98294)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.40411  (1.39175)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.56380  (1.13900)\n",
            "     | > loader_time: 0.01990  (0.01511)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 244/406 -- GLOBAL_STEP: 650\u001b[0m\n",
            "     | > decoder_loss: 4.38556  (4.32999)\n",
            "     | > postnet_loss: 2.61520  (2.63015)\n",
            "     | > stopnet_loss: 0.62472  (0.62439)\n",
            "     | > ga_loss: 0.00311  (0.00513)\n",
            "     | > decoder_diff_spec_loss: 0.22258  (0.21979)\n",
            "     | > postnet_diff_spec_loss: 0.46975  (0.46528)\n",
            "     | > decoder_ssim_loss: 0.96823  (0.96785)\n",
            "     | > postnet_ssim_loss: 0.93080  (0.93523)\n",
            "     | > loss: 3.03829  (3.03710)\n",
            "     | > align_error: 0.98957  (0.98360)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41000  (1.39347)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.68590  (1.18967)\n",
            "     | > loader_time: 0.02110  (0.01575)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 269/406 -- GLOBAL_STEP: 675\u001b[0m\n",
            "     | > decoder_loss: 4.48678  (4.33849)\n",
            "     | > postnet_loss: 2.67493  (2.63162)\n",
            "     | > stopnet_loss: 0.62329  (0.62434)\n",
            "     | > ga_loss: 0.00294  (0.00493)\n",
            "     | > decoder_diff_spec_loss: 0.21898  (0.21976)\n",
            "     | > postnet_diff_spec_loss: 0.46148  (0.46510)\n",
            "     | > decoder_ssim_loss: 0.96834  (0.96778)\n",
            "     | > postnet_ssim_loss: 0.92786  (0.93473)\n",
            "     | > loss: 3.07259  (3.03837)\n",
            "     | > align_error: 0.99037  (0.98420)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41325  (1.39482)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.96680  (1.23853)\n",
            "     | > loader_time: 0.02220  (0.01635)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 294/406 -- GLOBAL_STEP: 700\u001b[0m\n",
            "     | > decoder_loss: 4.50825  (4.34828)\n",
            "     | > postnet_loss: 2.68309  (2.63388)\n",
            "     | > stopnet_loss: 0.62682  (0.62435)\n",
            "     | > ga_loss: 0.00281  (0.00476)\n",
            "     | > decoder_diff_spec_loss: 0.21602  (0.21974)\n",
            "     | > postnet_diff_spec_loss: 0.45939  (0.46494)\n",
            "     | > decoder_ssim_loss: 0.96507  (0.96766)\n",
            "     | > postnet_ssim_loss: 0.92934  (0.93429)\n",
            "     | > loss: 3.08118  (3.04034)\n",
            "     | > align_error: 0.99082  (0.98473)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41215  (1.39600)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.73940  (1.28689)\n",
            "     | > loader_time: 0.02300  (0.01695)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 319/406 -- GLOBAL_STEP: 725\u001b[0m\n",
            "     | > decoder_loss: 4.53949  (4.35657)\n",
            "     | > postnet_loss: 2.65089  (2.63537)\n",
            "     | > stopnet_loss: 0.62489  (0.62435)\n",
            "     | > ga_loss: 0.00267  (0.00460)\n",
            "     | > decoder_diff_spec_loss: 0.21868  (0.21974)\n",
            "     | > postnet_diff_spec_loss: 0.46056  (0.46481)\n",
            "     | > decoder_ssim_loss: 0.96567  (0.96756)\n",
            "     | > postnet_ssim_loss: 0.92906  (0.93392)\n",
            "     | > loss: 3.07935  (3.04184)\n",
            "     | > align_error: 0.99107  (0.98521)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41758  (1.39687)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.96690  (1.33471)\n",
            "     | > loader_time: 0.02400  (0.01748)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 344/406 -- GLOBAL_STEP: 750\u001b[0m\n",
            "     | > decoder_loss: 4.41973  (4.36493)\n",
            "     | > postnet_loss: 2.62704  (2.63719)\n",
            "     | > stopnet_loss: 0.62648  (0.62436)\n",
            "     | > ga_loss: 0.00256  (0.00446)\n",
            "     | > decoder_diff_spec_loss: 0.21649  (0.21973)\n",
            "     | > postnet_diff_spec_loss: 0.46025  (0.46465)\n",
            "     | > decoder_ssim_loss: 0.96633  (0.96747)\n",
            "     | > postnet_ssim_loss: 0.92942  (0.93358)\n",
            "     | > loss: 3.04412  (3.04354)\n",
            "     | > align_error: 0.99162  (0.98564)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41722  (1.39779)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.11830  (1.37905)\n",
            "     | > loader_time: 0.03270  (0.01803)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 369/406 -- GLOBAL_STEP: 775\u001b[0m\n",
            "     | > decoder_loss: 4.41264  (4.37410)\n",
            "     | > postnet_loss: 2.61460  (2.63873)\n",
            "     | > stopnet_loss: 0.62488  (0.62437)\n",
            "     | > ga_loss: 0.00241  (0.00433)\n",
            "     | > decoder_diff_spec_loss: 0.21815  (0.21966)\n",
            "     | > postnet_diff_spec_loss: 0.46321  (0.46446)\n",
            "     | > decoder_ssim_loss: 0.96767  (0.96740)\n",
            "     | > postnet_ssim_loss: 0.92804  (0.93326)\n",
            "     | > loss: 3.03799  (3.04540)\n",
            "     | > align_error: 0.99292  (0.98604)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41892  (1.39908)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.14800  (1.42231)\n",
            "     | > loader_time: 0.02600  (0.01854)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 394/406 -- GLOBAL_STEP: 800\u001b[0m\n",
            "     | > decoder_loss: 4.51446  (4.38180)\n",
            "     | > postnet_loss: 2.65620  (2.63995)\n",
            "     | > stopnet_loss: 0.62516  (0.62433)\n",
            "     | > ga_loss: 0.00236  (0.00420)\n",
            "     | > decoder_diff_spec_loss: 0.22128  (0.21962)\n",
            "     | > postnet_diff_spec_loss: 0.46562  (0.46431)\n",
            "     | > decoder_ssim_loss: 0.96566  (0.96729)\n",
            "     | > postnet_ssim_loss: 0.92857  (0.93299)\n",
            "     | > loss: 3.07491  (3.04684)\n",
            "     | > align_error: 0.99196  (0.98642)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.41235  (1.39998)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.28730  (1.46531)\n",
            "     | > loader_time: 0.02720  (0.01912)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01270 \u001b[0m(+0.00262)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.37506 \u001b[0m(-0.00410)\n",
            "     | > avg_postnet_loss:\u001b[91m 2.62512 \u001b[0m(+0.00001)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.59448 \u001b[0m(-0.00302)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00336 \u001b[0m(-0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.21605 \u001b[0m(-0.00001)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46484 \u001b[0m(-0.00002)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.92606 \u001b[0m(-0.00050)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.89397 \u001b[0m(-0.00008)\n",
            "     | > avg_loss:\u001b[92m 2.98654 \u001b[0m(-0.00421)\n",
            "     | > avg_align_error:\u001b[91m 0.98975 \u001b[0m(+0.00002)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_812.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 05:55:06) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 13/406 -- GLOBAL_STEP: 825\u001b[0m\n",
            "     | > decoder_loss: 4.12285  (4.08663)\n",
            "     | > postnet_loss: 2.62208  (2.61770)\n",
            "     | > stopnet_loss: 0.62244  (0.62093)\n",
            "     | > ga_loss: 0.00984  (0.01324)\n",
            "     | > decoder_diff_spec_loss: 0.21504  (0.21471)\n",
            "     | > postnet_diff_spec_loss: 0.46335  (0.46640)\n",
            "     | > decoder_ssim_loss: 0.96919  (0.96561)\n",
            "     | > postnet_ssim_loss: 0.94344  (0.93520)\n",
            "     | > loss: 3.00561  (3.00867)\n",
            "     | > align_error: 0.96872  (0.96063)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.34943  (1.33664)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.66360  (0.56898)\n",
            "     | > loader_time: 0.00830  (0.00770)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 38/406 -- GLOBAL_STEP: 850\u001b[0m\n",
            "     | > decoder_loss: 4.17569  (4.11518)\n",
            "     | > postnet_loss: 2.59350  (2.60759)\n",
            "     | > stopnet_loss: 0.62199  (0.62197)\n",
            "     | > ga_loss: 0.00695  (0.00981)\n",
            "     | > decoder_diff_spec_loss: 0.21904  (0.21799)\n",
            "     | > postnet_diff_spec_loss: 0.46893  (0.46797)\n",
            "     | > decoder_ssim_loss: 0.96829  (0.96746)\n",
            "     | > postnet_ssim_loss: 0.94324  (0.94177)\n",
            "     | > loss: 2.99894  (3.00050)\n",
            "     | > align_error: 0.97728  (0.97009)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.36607  (1.35308)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.86100  (0.70185)\n",
            "     | > loader_time: 0.01030  (0.00914)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 63/406 -- GLOBAL_STEP: 875\u001b[0m\n",
            "     | > decoder_loss: 4.34061  (4.15356)\n",
            "     | > postnet_loss: 2.60803  (2.60514)\n",
            "     | > stopnet_loss: 0.62246  (0.62215)\n",
            "     | > ga_loss: 0.00565  (0.00836)\n",
            "     | > decoder_diff_spec_loss: 0.21575  (0.21860)\n",
            "     | > postnet_diff_spec_loss: 0.46042  (0.46736)\n",
            "     | > decoder_ssim_loss: 0.96796  (0.96776)\n",
            "     | > postnet_ssim_loss: 0.94293  (0.94319)\n",
            "     | > loss: 3.03464  (3.00287)\n",
            "     | > align_error: 0.98129  (0.97414)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38547  (1.36192)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.03640  (0.79769)\n",
            "     | > loader_time: 0.01620  (0.01023)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 88/406 -- GLOBAL_STEP: 900\u001b[0m\n",
            "     | > decoder_loss: 4.21909  (4.19643)\n",
            "     | > postnet_loss: 2.60854  (2.61154)\n",
            "     | > stopnet_loss: 0.62533  (0.62227)\n",
            "     | > ga_loss: 0.00478  (0.00747)\n",
            "     | > decoder_diff_spec_loss: 0.22153  (0.21908)\n",
            "     | > postnet_diff_spec_loss: 0.46630  (0.46688)\n",
            "     | > decoder_ssim_loss: 0.96517  (0.96793)\n",
            "     | > postnet_ssim_loss: 0.93040  (0.94207)\n",
            "     | > loss: 3.00201  (3.01058)\n",
            "     | > align_error: 0.98450  (0.97670)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38440  (1.36831)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.05990  (0.86925)\n",
            "     | > loader_time: 0.01440  (0.01115)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 113/406 -- GLOBAL_STEP: 925\u001b[0m\n",
            "     | > decoder_loss: 4.44157  (4.22596)\n",
            "     | > postnet_loss: 2.65804  (2.61554)\n",
            "     | > stopnet_loss: 0.61968  (0.62235)\n",
            "     | > ga_loss: 0.00448  (0.00683)\n",
            "     | > decoder_diff_spec_loss: 0.21705  (0.21939)\n",
            "     | > postnet_diff_spec_loss: 0.46183  (0.46665)\n",
            "     | > decoder_ssim_loss: 0.96783  (0.96796)\n",
            "     | > postnet_ssim_loss: 0.93094  (0.93960)\n",
            "     | > loss: 3.06141  (3.01528)\n",
            "     | > align_error: 0.98521  (0.97858)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38695  (1.37262)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.16490  (0.93076)\n",
            "     | > loader_time: 0.01520  (0.01203)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 138/406 -- GLOBAL_STEP: 950\u001b[0m\n",
            "     | > decoder_loss: 4.51473  (4.25667)\n",
            "     | > postnet_loss: 2.65064  (2.61897)\n",
            "     | > stopnet_loss: 0.62176  (0.62236)\n",
            "     | > ga_loss: 0.00417  (0.00636)\n",
            "     | > decoder_diff_spec_loss: 0.22052  (0.21944)\n",
            "     | > postnet_diff_spec_loss: 0.46382  (0.46623)\n",
            "     | > decoder_ssim_loss: 0.96617  (0.96782)\n",
            "     | > postnet_ssim_loss: 0.93042  (0.93792)\n",
            "     | > loss: 3.07918  (3.02092)\n",
            "     | > align_error: 0.98599  (0.97994)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.40251  (1.37635)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.27240  (0.98805)\n",
            "     | > loader_time: 0.01700  (0.01295)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 163/406 -- GLOBAL_STEP: 975\u001b[0m\n",
            "     | > decoder_loss: 4.44558  (4.27374)\n",
            "     | > postnet_loss: 2.69473  (2.62025)\n",
            "     | > stopnet_loss: 0.62089  (0.62230)\n",
            "     | > ga_loss: 0.00376  (0.00598)\n",
            "     | > decoder_diff_spec_loss: 0.21685  (0.21963)\n",
            "     | > postnet_diff_spec_loss: 0.46046  (0.46616)\n",
            "     | > decoder_ssim_loss: 0.96627  (0.96774)\n",
            "     | > postnet_ssim_loss: 0.92895  (0.93667)\n",
            "     | > loss: 3.06791  (3.02324)\n",
            "     | > align_error: 0.98683  (0.98103)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38671  (1.37862)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.33470  (1.04126)\n",
            "     | > loader_time: 0.01840  (0.01371)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 188/406 -- GLOBAL_STEP: 1000\u001b[0m\n",
            "     | > decoder_loss: 4.57490  (4.28959)\n",
            "     | > postnet_loss: 2.72490  (2.62329)\n",
            "     | > stopnet_loss: 0.61860  (0.62219)\n",
            "     | > ga_loss: 0.00377  (0.00567)\n",
            "     | > decoder_diff_spec_loss: 0.21470  (0.21959)\n",
            "     | > postnet_diff_spec_loss: 0.45571  (0.46580)\n",
            "     | > decoder_ssim_loss: 0.96451  (0.96760)\n",
            "     | > postnet_ssim_loss: 0.92722  (0.93570)\n",
            "     | > loss: 3.10293  (3.02593)\n",
            "     | > align_error: 0.98734  (0.98196)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.39299  (1.38052)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.45800  (1.09084)\n",
            "     | > loader_time: 0.01900  (0.01440)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_1000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 213/406 -- GLOBAL_STEP: 1025\u001b[0m\n",
            "     | > decoder_loss: 4.46015  (4.30525)\n",
            "     | > postnet_loss: 2.66782  (2.62570)\n",
            "     | > stopnet_loss: 0.62114  (0.62218)\n",
            "     | > ga_loss: 0.00325  (0.00540)\n",
            "     | > decoder_diff_spec_loss: 0.22119  (0.21965)\n",
            "     | > postnet_diff_spec_loss: 0.46243  (0.46552)\n",
            "     | > decoder_ssim_loss: 0.96676  (0.96748)\n",
            "     | > postnet_ssim_loss: 0.92858  (0.93490)\n",
            "     | > loss: 3.06413  (3.02882)\n",
            "     | > align_error: 0.98877  (0.98276)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38822  (1.38242)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.46670  (1.13929)\n",
            "     | > loader_time: 0.02000  (0.01524)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 238/406 -- GLOBAL_STEP: 1050\u001b[0m\n",
            "     | > decoder_loss: 4.56118  (4.31998)\n",
            "     | > postnet_loss: 2.67850  (2.62876)\n",
            "     | > stopnet_loss: 0.62130  (0.62216)\n",
            "     | > ga_loss: 0.00319  (0.00518)\n",
            "     | > decoder_diff_spec_loss: 0.21794  (0.21965)\n",
            "     | > postnet_diff_spec_loss: 0.46082  (0.46534)\n",
            "     | > decoder_ssim_loss: 0.96638  (0.96739)\n",
            "     | > postnet_ssim_loss: 0.93070  (0.93424)\n",
            "     | > loss: 3.09113  (3.03188)\n",
            "     | > align_error: 0.98920  (0.98345)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.40003  (1.38383)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.55210  (1.18788)\n",
            "     | > loader_time: 0.02090  (0.01591)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 263/406 -- GLOBAL_STEP: 1075\u001b[0m\n",
            "     | > decoder_loss: 4.41374  (4.32985)\n",
            "     | > postnet_loss: 2.66404  (2.63078)\n",
            "     | > stopnet_loss: 0.62150  (0.62211)\n",
            "     | > ga_loss: 0.00296  (0.00497)\n",
            "     | > decoder_diff_spec_loss: 0.22178  (0.21961)\n",
            "     | > postnet_diff_spec_loss: 0.46555  (0.46515)\n",
            "     | > decoder_ssim_loss: 0.96651  (0.96729)\n",
            "     | > postnet_ssim_loss: 0.92817  (0.93366)\n",
            "     | > loss: 3.05124  (3.03357)\n",
            "     | > align_error: 0.99025  (0.98407)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.39425  (1.38515)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.64590  (1.23877)\n",
            "     | > loader_time: 0.02190  (0.01649)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 288/406 -- GLOBAL_STEP: 1100\u001b[0m\n",
            "     | > decoder_loss: 4.38146  (4.33921)\n",
            "     | > postnet_loss: 2.63799  (2.63280)\n",
            "     | > stopnet_loss: 0.62119  (0.62204)\n",
            "     | > ga_loss: 0.00278  (0.00480)\n",
            "     | > decoder_diff_spec_loss: 0.21739  (0.21960)\n",
            "     | > postnet_diff_spec_loss: 0.46395  (0.46499)\n",
            "     | > decoder_ssim_loss: 0.96729  (0.96720)\n",
            "     | > postnet_ssim_loss: 0.92828  (0.93315)\n",
            "     | > loss: 3.03418  (3.03526)\n",
            "     | > align_error: 0.99154  (0.98461)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.39688  (1.38624)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91010  (1.28781)\n",
            "     | > loader_time: 0.03090  (0.01709)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 313/406 -- GLOBAL_STEP: 1125\u001b[0m\n",
            "     | > decoder_loss: 4.36097  (4.34766)\n",
            "     | > postnet_loss: 2.62594  (2.63472)\n",
            "     | > stopnet_loss: 0.61993  (0.62200)\n",
            "     | > ga_loss: 0.00272  (0.00464)\n",
            "     | > decoder_diff_spec_loss: 0.21978  (0.21956)\n",
            "     | > postnet_diff_spec_loss: 0.46340  (0.46482)\n",
            "     | > decoder_ssim_loss: 0.96351  (0.96707)\n",
            "     | > postnet_ssim_loss: 0.92665  (0.93270)\n",
            "     | > loss: 3.02359  (3.03681)\n",
            "     | > align_error: 0.99056  (0.98509)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38884  (1.38703)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.94640  (1.33438)\n",
            "     | > loader_time: 0.03100  (0.01770)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 338/406 -- GLOBAL_STEP: 1150\u001b[0m\n",
            "     | > decoder_loss: 4.44275  (4.35567)\n",
            "     | > postnet_loss: 2.64950  (2.63633)\n",
            "     | > stopnet_loss: 0.61883  (0.62197)\n",
            "     | > ga_loss: 0.00262  (0.00449)\n",
            "     | > decoder_diff_spec_loss: 0.21796  (0.21956)\n",
            "     | > postnet_diff_spec_loss: 0.46109  (0.46468)\n",
            "     | > decoder_ssim_loss: 0.96549  (0.96695)\n",
            "     | > postnet_ssim_loss: 0.92794  (0.93228)\n",
            "     | > loss: 3.04813  (3.03828)\n",
            "     | > align_error: 0.99191  (0.98554)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.39461  (1.38771)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.97150  (1.38177)\n",
            "     | > loader_time: 0.02490  (0.01826)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 363/406 -- GLOBAL_STEP: 1175\u001b[0m\n",
            "     | > decoder_loss: 4.55247  (4.36504)\n",
            "     | > postnet_loss: 2.68259  (2.63780)\n",
            "     | > stopnet_loss: 0.62097  (0.62188)\n",
            "     | > ga_loss: 0.00246  (0.00436)\n",
            "     | > decoder_diff_spec_loss: 0.22159  (0.21948)\n",
            "     | > postnet_diff_spec_loss: 0.46276  (0.46448)\n",
            "     | > decoder_ssim_loss: 0.96447  (0.96685)\n",
            "     | > postnet_ssim_loss: 0.92643  (0.93190)\n",
            "     | > loss: 3.08585  (3.04005)\n",
            "     | > align_error: 0.99157  (0.98595)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.40658  (1.38881)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.05700  (1.42459)\n",
            "     | > loader_time: 0.02580  (0.01879)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 388/406 -- GLOBAL_STEP: 1200\u001b[0m\n",
            "     | > decoder_loss: 4.44078  (4.37217)\n",
            "     | > postnet_loss: 2.63073  (2.63905)\n",
            "     | > stopnet_loss: 0.61921  (0.62180)\n",
            "     | > ga_loss: 0.00234  (0.00423)\n",
            "     | > decoder_diff_spec_loss: 0.22149  (0.21945)\n",
            "     | > postnet_diff_spec_loss: 0.46488  (0.46435)\n",
            "     | > decoder_ssim_loss: 0.96457  (0.96674)\n",
            "     | > postnet_ssim_loss: 0.92659  (0.93154)\n",
            "     | > loss: 3.04318  (3.04128)\n",
            "     | > align_error: 0.99173  (0.98633)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.39239  (1.38964)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.15560  (1.46909)\n",
            "     | > loader_time: 0.03540  (0.01942)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01096 \u001b[0m(-0.00174)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.36536 \u001b[0m(-0.00969)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.62430 \u001b[0m(-0.00082)\n",
            "     | > avg_stopnet_loss:\u001b[91m 0.59637 \u001b[0m(+0.00189)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00336 \u001b[0m(-0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.21570 \u001b[0m(-0.00035)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46484 \u001b[0m(-0.00000)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.92560 \u001b[0m(-0.00045)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.89067 \u001b[0m(-0.00330)\n",
            "     | > avg_loss:\u001b[92m 2.98477 \u001b[0m(-0.00177)\n",
            "     | > avg_align_error:\u001b[92m 0.98975 \u001b[0m(-0.00000)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_1218.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 06:16:19) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 7/406 -- GLOBAL_STEP: 1225\u001b[0m\n",
            "     | > decoder_loss: 3.98248  (4.04769)\n",
            "     | > postnet_loss: 2.63109  (2.61729)\n",
            "     | > stopnet_loss: 0.61930  (0.61913)\n",
            "     | > ga_loss: 0.01206  (0.01515)\n",
            "     | > decoder_diff_spec_loss: 0.21340  (0.21174)\n",
            "     | > postnet_diff_spec_loss: 0.45935  (0.46358)\n",
            "     | > decoder_ssim_loss: 0.96606  (0.96208)\n",
            "     | > postnet_ssim_loss: 0.93935  (0.93063)\n",
            "     | > loss: 2.97755  (3.00314)\n",
            "     | > align_error: 0.96120  (0.95658)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.32201  (1.31438)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.56200  (0.53058)\n",
            "     | > loader_time: 0.00640  (0.00666)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 32/406 -- GLOBAL_STEP: 1250\u001b[0m\n",
            "     | > decoder_loss: 4.13065  (4.10216)\n",
            "     | > postnet_loss: 2.57123  (2.60831)\n",
            "     | > stopnet_loss: 0.62015  (0.61953)\n",
            "     | > ga_loss: 0.00748  (0.01031)\n",
            "     | > decoder_diff_spec_loss: 0.21646  (0.21777)\n",
            "     | > postnet_diff_spec_loss: 0.46479  (0.46809)\n",
            "     | > decoder_ssim_loss: 0.96592  (0.96620)\n",
            "     | > postnet_ssim_loss: 0.94395  (0.93923)\n",
            "     | > loss: 2.98080  (2.99652)\n",
            "     | > align_error: 0.97680  (0.96865)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.35368  (1.33872)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.74740  (0.66996)\n",
            "     | > loader_time: 0.01020  (0.00863)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 57/406 -- GLOBAL_STEP: 1275\u001b[0m\n",
            "     | > decoder_loss: 4.15738  (4.12786)\n",
            "     | > postnet_loss: 2.57770  (2.60383)\n",
            "     | > stopnet_loss: 0.61903  (0.61925)\n",
            "     | > ga_loss: 0.00587  (0.00863)\n",
            "     | > decoder_diff_spec_loss: 0.22250  (0.21830)\n",
            "     | > postnet_diff_spec_loss: 0.47128  (0.46750)\n",
            "     | > decoder_ssim_loss: 0.96623  (0.96663)\n",
            "     | > postnet_ssim_loss: 0.94366  (0.94101)\n",
            "     | > loss: 2.98308  (2.99367)\n",
            "     | > align_error: 0.98244  (0.97343)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.35426  (1.34690)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.04020  (0.76088)\n",
            "     | > loader_time: 0.01280  (0.00989)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 82/406 -- GLOBAL_STEP: 1300\u001b[0m\n",
            "     | > decoder_loss: 4.46134  (4.17604)\n",
            "     | > postnet_loss: 2.67265  (2.60955)\n",
            "     | > stopnet_loss: 0.62091  (0.61930)\n",
            "     | > ga_loss: 0.00504  (0.00764)\n",
            "     | > decoder_diff_spec_loss: 0.21899  (0.21883)\n",
            "     | > postnet_diff_spec_loss: 0.46155  (0.46710)\n",
            "     | > decoder_ssim_loss: 0.96721  (0.96692)\n",
            "     | > postnet_ssim_loss: 0.92914  (0.94089)\n",
            "     | > loss: 3.07383  (3.00233)\n",
            "     | > align_error: 0.98518  (0.97619)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38900  (1.35417)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.01660  (0.84552)\n",
            "     | > loader_time: 0.01380  (0.01093)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 107/406 -- GLOBAL_STEP: 1325\u001b[0m\n",
            "     | > decoder_loss: 4.23694  (4.20769)\n",
            "     | > postnet_loss: 2.56864  (2.61324)\n",
            "     | > stopnet_loss: 0.61655  (0.61927)\n",
            "     | > ga_loss: 0.00431  (0.00695)\n",
            "     | > decoder_diff_spec_loss: 0.21999  (0.21907)\n",
            "     | > postnet_diff_spec_loss: 0.47027  (0.46666)\n",
            "     | > decoder_ssim_loss: 0.96791  (0.96695)\n",
            "     | > postnet_ssim_loss: 0.92703  (0.93790)\n",
            "     | > loss: 2.98581  (3.00692)\n",
            "     | > align_error: 0.98497  (0.97821)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.36345  (1.35879)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.19420  (0.91095)\n",
            "     | > loader_time: 0.01540  (0.01196)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 132/406 -- GLOBAL_STEP: 1350\u001b[0m\n",
            "     | > decoder_loss: 4.48984  (4.23615)\n",
            "     | > postnet_loss: 2.64768  (2.61665)\n",
            "     | > stopnet_loss: 0.61771  (0.61922)\n",
            "     | > ga_loss: 0.00421  (0.00645)\n",
            "     | > decoder_diff_spec_loss: 0.21492  (0.21919)\n",
            "     | > postnet_diff_spec_loss: 0.45853  (0.46640)\n",
            "     | > decoder_ssim_loss: 0.96683  (0.96694)\n",
            "     | > postnet_ssim_loss: 0.92609  (0.93595)\n",
            "     | > loss: 3.06475  (3.01179)\n",
            "     | > align_error: 0.98539  (0.97969)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38738  (1.36258)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.36680  (0.97288)\n",
            "     | > loader_time: 0.01690  (0.01296)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 157/406 -- GLOBAL_STEP: 1375\u001b[0m\n",
            "     | > decoder_loss: 4.39483  (4.25737)\n",
            "     | > postnet_loss: 2.63347  (2.61838)\n",
            "     | > stopnet_loss: 0.61744  (0.61915)\n",
            "     | > ga_loss: 0.00392  (0.00605)\n",
            "     | > decoder_diff_spec_loss: 0.21655  (0.21939)\n",
            "     | > postnet_diff_spec_loss: 0.46069  (0.46624)\n",
            "     | > decoder_ssim_loss: 0.96731  (0.96677)\n",
            "     | > postnet_ssim_loss: 0.92645  (0.93446)\n",
            "     | > loss: 3.03685  (3.01507)\n",
            "     | > align_error: 0.98690  (0.98082)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38185  (1.36554)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.35450  (1.02592)\n",
            "     | > loader_time: 0.01830  (0.01377)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 182/406 -- GLOBAL_STEP: 1400\u001b[0m\n",
            "     | > decoder_loss: 4.36963  (4.27245)\n",
            "     | > postnet_loss: 2.61414  (2.62114)\n",
            "     | > stopnet_loss: 0.61882  (0.61901)\n",
            "     | > ga_loss: 0.00363  (0.00573)\n",
            "     | > decoder_diff_spec_loss: 0.21752  (0.21939)\n",
            "     | > postnet_diff_spec_loss: 0.46061  (0.46590)\n",
            "     | > decoder_ssim_loss: 0.96680  (0.96665)\n",
            "     | > postnet_ssim_loss: 0.92588  (0.93332)\n",
            "     | > loss: 3.02561  (3.01737)\n",
            "     | > align_error: 0.98797  (0.98177)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38173  (1.36729)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.39550  (1.07662)\n",
            "     | > loader_time: 0.01880  (0.01445)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 207/406 -- GLOBAL_STEP: 1425\u001b[0m\n",
            "     | > decoder_loss: 4.36249  (4.28918)\n",
            "     | > postnet_loss: 2.63298  (2.62392)\n",
            "     | > stopnet_loss: 0.61869  (0.61891)\n",
            "     | > ga_loss: 0.00336  (0.00546)\n",
            "     | > decoder_diff_spec_loss: 0.22115  (0.21936)\n",
            "     | > postnet_diff_spec_loss: 0.46272  (0.46555)\n",
            "     | > decoder_ssim_loss: 0.96272  (0.96652)\n",
            "     | > postnet_ssim_loss: 0.92611  (0.93240)\n",
            "     | > loss: 3.02755  (3.02043)\n",
            "     | > align_error: 0.98863  (0.98260)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38116  (1.36925)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.45350  (1.12433)\n",
            "     | > loader_time: 0.01990  (0.01507)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 232/406 -- GLOBAL_STEP: 1450\u001b[0m\n",
            "     | > decoder_loss: 4.42550  (4.30410)\n",
            "     | > postnet_loss: 2.65963  (2.62696)\n",
            "     | > stopnet_loss: 0.61691  (0.61882)\n",
            "     | > ga_loss: 0.00314  (0.00522)\n",
            "     | > decoder_diff_spec_loss: 0.22076  (0.21940)\n",
            "     | > postnet_diff_spec_loss: 0.46587  (0.46541)\n",
            "     | > decoder_ssim_loss: 0.96424  (0.96640)\n",
            "     | > postnet_ssim_loss: 0.92501  (0.93160)\n",
            "     | > loss: 3.04787  (3.02339)\n",
            "     | > align_error: 0.99038  (0.98331)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38442  (1.37055)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.71320  (1.17396)\n",
            "     | > loader_time: 0.02080  (0.01568)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 257/406 -- GLOBAL_STEP: 1475\u001b[0m\n",
            "     | > decoder_loss: 4.42811  (4.31523)\n",
            "     | > postnet_loss: 2.63108  (2.62932)\n",
            "     | > stopnet_loss: 0.61796  (0.61872)\n",
            "     | > ga_loss: 0.00298  (0.00501)\n",
            "     | > decoder_diff_spec_loss: 0.22068  (0.21937)\n",
            "     | > postnet_diff_spec_loss: 0.46586  (0.46520)\n",
            "     | > decoder_ssim_loss: 0.96702  (0.96626)\n",
            "     | > postnet_ssim_loss: 0.92592  (0.93093)\n",
            "     | > loss: 3.04255  (3.02537)\n",
            "     | > align_error: 0.99003  (0.98394)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.39538  (1.37181)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.79070  (1.22597)\n",
            "     | > loader_time: 0.02230  (0.01636)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 282/406 -- GLOBAL_STEP: 1500\u001b[0m\n",
            "     | > decoder_loss: 4.46802  (4.32467)\n",
            "     | > postnet_loss: 2.66713  (2.63166)\n",
            "     | > stopnet_loss: 0.61668  (0.61858)\n",
            "     | > ga_loss: 0.00287  (0.00483)\n",
            "     | > decoder_diff_spec_loss: 0.21771  (0.21935)\n",
            "     | > postnet_diff_spec_loss: 0.46205  (0.46502)\n",
            "     | > decoder_ssim_loss: 0.96618  (0.96614)\n",
            "     | > postnet_ssim_loss: 0.92397  (0.93033)\n",
            "     | > loss: 3.05729  (3.02702)\n",
            "     | > align_error: 0.99014  (0.98450)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38572  (1.37290)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.96830  (1.27254)\n",
            "     | > loader_time: 0.02260  (0.01695)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 307/406 -- GLOBAL_STEP: 1525\u001b[0m\n",
            "     | > decoder_loss: 4.43254  (4.33386)\n",
            "     | > postnet_loss: 2.63659  (2.63372)\n",
            "     | > stopnet_loss: 0.61958  (0.61845)\n",
            "     | > ga_loss: 0.00273  (0.00467)\n",
            "     | > decoder_diff_spec_loss: 0.21732  (0.21928)\n",
            "     | > postnet_diff_spec_loss: 0.46109  (0.46482)\n",
            "     | > decoder_ssim_loss: 0.96384  (0.96599)\n",
            "     | > postnet_ssim_loss: 0.92283  (0.92978)\n",
            "     | > loss: 3.04179  (3.02864)\n",
            "     | > align_error: 0.99098  (0.98500)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38261  (1.37356)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.83150  (1.31793)\n",
            "     | > loader_time: 0.02330  (0.01751)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 332/406 -- GLOBAL_STEP: 1550\u001b[0m\n",
            "     | > decoder_loss: 4.36351  (4.34077)\n",
            "     | > postnet_loss: 2.63543  (2.63488)\n",
            "     | > stopnet_loss: 0.61709  (0.61832)\n",
            "     | > ga_loss: 0.00260  (0.00452)\n",
            "     | > decoder_diff_spec_loss: 0.22100  (0.21933)\n",
            "     | > postnet_diff_spec_loss: 0.46590  (0.46473)\n",
            "     | > decoder_ssim_loss: 0.96348  (0.96585)\n",
            "     | > postnet_ssim_loss: 0.92330  (0.92927)\n",
            "     | > loss: 3.02326  (3.02961)\n",
            "     | > align_error: 0.99152  (0.98546)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.37857  (1.37414)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.05060  (1.36574)\n",
            "     | > loader_time: 0.02530  (0.01809)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 357/406 -- GLOBAL_STEP: 1575\u001b[0m\n",
            "     | > decoder_loss: 4.40611  (4.34985)\n",
            "     | > postnet_loss: 2.63285  (2.63647)\n",
            "     | > stopnet_loss: 0.61521  (0.61820)\n",
            "     | > ga_loss: 0.00246  (0.00438)\n",
            "     | > decoder_diff_spec_loss: 0.22144  (0.21922)\n",
            "     | > postnet_diff_spec_loss: 0.46510  (0.46449)\n",
            "     | > decoder_ssim_loss: 0.96258  (0.96574)\n",
            "     | > postnet_ssim_loss: 0.92292  (0.92880)\n",
            "     | > loss: 3.03027  (3.03125)\n",
            "     | > align_error: 0.99154  (0.98587)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.37767  (1.37516)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.89160  (1.41012)\n",
            "     | > loader_time: 0.02610  (0.01859)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 382/406 -- GLOBAL_STEP: 1600\u001b[0m\n",
            "     | > decoder_loss: 4.45536  (4.35688)\n",
            "     | > postnet_loss: 2.66933  (2.63795)\n",
            "     | > stopnet_loss: 0.61565  (0.61806)\n",
            "     | > ga_loss: 0.00240  (0.00426)\n",
            "     | > decoder_diff_spec_loss: 0.22180  (0.21917)\n",
            "     | > postnet_diff_spec_loss: 0.46440  (0.46435)\n",
            "     | > decoder_ssim_loss: 0.96230  (0.96562)\n",
            "     | > postnet_ssim_loss: 0.92103  (0.92835)\n",
            "     | > loss: 3.05120  (3.03242)\n",
            "     | > align_error: 0.99231  (0.98626)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.38180  (1.37598)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.22670  (1.45611)\n",
            "     | > loader_time: 0.02760  (0.01913)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01110 \u001b[0m(+0.00014)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.35063 \u001b[0m(-0.01473)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.62295 \u001b[0m(-0.00136)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.58994 \u001b[0m(-0.00643)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00335 \u001b[0m(-0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.21538 \u001b[0m(-0.00032)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46483 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.92454 \u001b[0m(-0.00106)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.88603 \u001b[0m(-0.00465)\n",
            "     | > avg_loss:\u001b[92m 2.97280 \u001b[0m(-0.01197)\n",
            "     | > avg_align_error:\u001b[91m 0.98975 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_1624.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 06:37:23) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 1/406 -- GLOBAL_STEP: 1625\u001b[0m\n",
            "     | > decoder_loss: 4.05190  (4.05190)\n",
            "     | > postnet_loss: 2.64828  (2.64828)\n",
            "     | > stopnet_loss: 0.61168  (0.61168)\n",
            "     | > ga_loss: 0.01865  (0.01865)\n",
            "     | > decoder_diff_spec_loss: 0.21445  (0.21445)\n",
            "     | > postnet_diff_spec_loss: 0.46975  (0.46975)\n",
            "     | > decoder_ssim_loss: 0.95270  (0.95270)\n",
            "     | > postnet_ssim_loss: 0.90982  (0.90982)\n",
            "     | > loss: 3.01664  (3.01664)\n",
            "     | > align_error: 0.94787  (0.94787)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.28020  (1.28020)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.58920  (0.58915)\n",
            "     | > loader_time: 0.01040  (0.01039)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 26/406 -- GLOBAL_STEP: 1650\u001b[0m\n",
            "     | > decoder_loss: 4.16029  (4.08285)\n",
            "     | > postnet_loss: 2.60366  (2.61251)\n",
            "     | > stopnet_loss: 0.61459  (0.61363)\n",
            "     | > ga_loss: 0.00786  (0.01094)\n",
            "     | > decoder_diff_spec_loss: 0.22477  (0.21698)\n",
            "     | > postnet_diff_spec_loss: 0.47489  (0.46794)\n",
            "     | > decoder_ssim_loss: 0.96494  (0.96430)\n",
            "     | > postnet_ssim_loss: 0.93780  (0.93518)\n",
            "     | > loss: 2.99548  (2.98829)\n",
            "     | > align_error: 0.97513  (0.96693)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.34268  (1.32076)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.77190  (0.65188)\n",
            "     | > loader_time: 0.00980  (0.00851)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 51/406 -- GLOBAL_STEP: 1675\u001b[0m\n",
            "     | > decoder_loss: 4.27608  (4.10316)\n",
            "     | > postnet_loss: 2.69606  (2.60386)\n",
            "     | > stopnet_loss: 0.61133  (0.61348)\n",
            "     | > ga_loss: 0.00626  (0.00893)\n",
            "     | > decoder_diff_spec_loss: 0.21262  (0.21769)\n",
            "     | > postnet_diff_spec_loss: 0.45997  (0.46736)\n",
            "     | > decoder_ssim_loss: 0.96862  (0.96512)\n",
            "     | > postnet_ssim_loss: 0.93813  (0.93729)\n",
            "     | > loss: 3.03050  (2.98172)\n",
            "     | > align_error: 0.98133  (0.97254)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.35399  (1.33098)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.91180  (0.74845)\n",
            "     | > loader_time: 0.01180  (0.00994)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 76/406 -- GLOBAL_STEP: 1700\u001b[0m\n",
            "     | > decoder_loss: 4.22491  (4.15160)\n",
            "     | > postnet_loss: 2.60974  (2.60743)\n",
            "     | > stopnet_loss: 0.61351  (0.61362)\n",
            "     | > ga_loss: 0.00519  (0.00783)\n",
            "     | > decoder_diff_spec_loss: 0.22744  (0.21850)\n",
            "     | > postnet_diff_spec_loss: 0.47527  (0.46719)\n",
            "     | > decoder_ssim_loss: 0.96435  (0.96521)\n",
            "     | > postnet_ssim_loss: 0.93863  (0.93783)\n",
            "     | > loss: 2.99955  (2.98969)\n",
            "     | > align_error: 0.98301  (0.97563)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.34912  (1.33870)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.08800  (0.83202)\n",
            "     | > loader_time: 0.01370  (0.01110)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 101/406 -- GLOBAL_STEP: 1725\u001b[0m\n",
            "     | > decoder_loss: 4.32031  (4.18390)\n",
            "     | > postnet_loss: 2.65230  (2.61234)\n",
            "     | > stopnet_loss: 0.60873  (0.61368)\n",
            "     | > ga_loss: 0.00467  (0.00709)\n",
            "     | > decoder_diff_spec_loss: 0.21490  (0.21869)\n",
            "     | > postnet_diff_spec_loss: 0.46037  (0.46658)\n",
            "     | > decoder_ssim_loss: 0.96633  (0.96531)\n",
            "     | > postnet_ssim_loss: 0.92063  (0.93445)\n",
            "     | > loss: 3.01581  (2.99444)\n",
            "     | > align_error: 0.98454  (0.97783)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.35314  (1.34360)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.13680  (0.90030)\n",
            "     | > loader_time: 0.01500  (0.01202)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 126/406 -- GLOBAL_STEP: 1750\u001b[0m\n",
            "     | > decoder_loss: 4.23002  (4.21101)\n",
            "     | > postnet_loss: 2.59310  (2.61464)\n",
            "     | > stopnet_loss: 0.61305  (0.61370)\n",
            "     | > ga_loss: 0.00408  (0.00655)\n",
            "     | > decoder_diff_spec_loss: 0.22074  (0.21896)\n",
            "     | > postnet_diff_spec_loss: 0.46638  (0.46649)\n",
            "     | > decoder_ssim_loss: 0.96430  (0.96527)\n",
            "     | > postnet_ssim_loss: 0.92195  (0.93217)\n",
            "     | > loss: 2.98256  (2.99856)\n",
            "     | > align_error: 0.98702  (0.97943)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.35661  (1.34759)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.25100  (0.96004)\n",
            "     | > loader_time: 0.01610  (0.01280)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 151/406 -- GLOBAL_STEP: 1775\u001b[0m\n",
            "     | > decoder_loss: 4.27157  (4.23740)\n",
            "     | > postnet_loss: 2.61998  (2.61748)\n",
            "     | > stopnet_loss: 0.61156  (0.61363)\n",
            "     | > ga_loss: 0.00388  (0.00613)\n",
            "     | > decoder_diff_spec_loss: 0.22101  (0.21913)\n",
            "     | > postnet_diff_spec_loss: 0.46929  (0.46628)\n",
            "     | > decoder_ssim_loss: 0.96617  (0.96516)\n",
            "     | > postnet_ssim_loss: 0.92344  (0.93044)\n",
            "     | > loss: 2.99882  (3.00326)\n",
            "     | > align_error: 0.98713  (0.98060)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.34817  (1.35083)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.31070  (1.01513)\n",
            "     | > loader_time: 0.01710  (0.01353)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 176/406 -- GLOBAL_STEP: 1800\u001b[0m\n",
            "     | > decoder_loss: 4.32291  (4.25073)\n",
            "     | > postnet_loss: 2.62111  (2.61938)\n",
            "     | > stopnet_loss: 0.60933  (0.61346)\n",
            "     | > ga_loss: 0.00364  (0.00579)\n",
            "     | > decoder_diff_spec_loss: 0.22107  (0.21917)\n",
            "     | > postnet_diff_spec_loss: 0.46613  (0.46602)\n",
            "     | > decoder_ssim_loss: 0.96389  (0.96505)\n",
            "     | > postnet_ssim_loss: 0.92030  (0.92905)\n",
            "     | > loss: 3.00637  (3.00477)\n",
            "     | > align_error: 0.98832  (0.98159)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.35575  (1.35255)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.37470  (1.06588)\n",
            "     | > loader_time: 0.01830  (0.01418)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 201/406 -- GLOBAL_STEP: 1825\u001b[0m\n",
            "     | > decoder_loss: 4.24279  (4.26612)\n",
            "     | > postnet_loss: 2.63323  (2.62234)\n",
            "     | > stopnet_loss: 0.61585  (0.61336)\n",
            "     | > ga_loss: 0.00334  (0.00551)\n",
            "     | > decoder_diff_spec_loss: 0.22517  (0.21911)\n",
            "     | > postnet_diff_spec_loss: 0.47179  (0.46562)\n",
            "     | > decoder_ssim_loss: 0.96378  (0.96489)\n",
            "     | > postnet_ssim_loss: 0.92168  (0.92793)\n",
            "     | > loss: 2.99716  (3.00741)\n",
            "     | > align_error: 0.98881  (0.98244)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.36597  (1.35489)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.55380  (1.11535)\n",
            "     | > loader_time: 0.01920  (0.01479)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 226/406 -- GLOBAL_STEP: 1850\u001b[0m\n",
            "     | > decoder_loss: 4.44480  (4.28272)\n",
            "     | > postnet_loss: 2.65497  (2.62482)\n",
            "     | > stopnet_loss: 0.61125  (0.61318)\n",
            "     | > ga_loss: 0.00323  (0.00526)\n",
            "     | > decoder_diff_spec_loss: 0.21991  (0.21915)\n",
            "     | > postnet_diff_spec_loss: 0.46307  (0.46544)\n",
            "     | > decoder_ssim_loss: 0.96199  (0.96474)\n",
            "     | > postnet_ssim_loss: 0.91759  (0.92695)\n",
            "     | > loss: 3.04299  (3.01046)\n",
            "     | > align_error: 0.98935  (0.98317)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.36976  (1.35649)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.57500  (1.16328)\n",
            "     | > loader_time: 0.02040  (0.01539)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 251/406 -- GLOBAL_STEP: 1875\u001b[0m\n",
            "     | > decoder_loss: 4.36640  (4.29443)\n",
            "     | > postnet_loss: 2.61470  (2.62784)\n",
            "     | > stopnet_loss: 0.61278  (0.61305)\n",
            "     | > ga_loss: 0.00310  (0.00505)\n",
            "     | > decoder_diff_spec_loss: 0.22240  (0.21914)\n",
            "     | > postnet_diff_spec_loss: 0.46789  (0.46524)\n",
            "     | > decoder_ssim_loss: 0.96435  (0.96461)\n",
            "     | > postnet_ssim_loss: 0.91850  (0.92614)\n",
            "     | > loss: 3.01682  (3.01267)\n",
            "     | > align_error: 0.98959  (0.98382)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.37070  (1.35803)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.86250  (1.21351)\n",
            "     | > loader_time: 0.02210  (0.01601)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 276/406 -- GLOBAL_STEP: 1900\u001b[0m\n",
            "     | > decoder_loss: 4.40482  (4.30371)\n",
            "     | > postnet_loss: 2.67456  (2.62982)\n",
            "     | > stopnet_loss: 0.61168  (0.61283)\n",
            "     | > ga_loss: 0.00287  (0.00486)\n",
            "     | > decoder_diff_spec_loss: 0.21935  (0.21908)\n",
            "     | > postnet_diff_spec_loss: 0.46461  (0.46502)\n",
            "     | > decoder_ssim_loss: 0.96267  (0.96446)\n",
            "     | > postnet_ssim_loss: 0.91914  (0.92539)\n",
            "     | > loss: 3.03733  (3.01403)\n",
            "     | > align_error: 0.99064  (0.98440)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.37507  (1.35927)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.92160  (1.26434)\n",
            "     | > loader_time: 0.02290  (0.01659)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 301/406 -- GLOBAL_STEP: 1925\u001b[0m\n",
            "     | > decoder_loss: 4.49871  (4.31258)\n",
            "     | > postnet_loss: 2.71129  (2.63187)\n",
            "     | > stopnet_loss: 0.60991  (0.61263)\n",
            "     | > ga_loss: 0.00285  (0.00470)\n",
            "     | > decoder_diff_spec_loss: 0.21384  (0.21904)\n",
            "     | > postnet_diff_spec_loss: 0.45644  (0.46483)\n",
            "     | > decoder_ssim_loss: 0.96125  (0.96430)\n",
            "     | > postnet_ssim_loss: 0.91500  (0.92471)\n",
            "     | > loss: 3.06328  (3.01544)\n",
            "     | > align_error: 0.99114  (0.98491)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.37746  (1.36003)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.02270  (1.31291)\n",
            "     | > loader_time: 0.02390  (0.01718)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 326/406 -- GLOBAL_STEP: 1950\u001b[0m\n",
            "     | > decoder_loss: 4.39005  (4.31905)\n",
            "     | > postnet_loss: 2.63226  (2.63289)\n",
            "     | > stopnet_loss: 0.60901  (0.61249)\n",
            "     | > ga_loss: 0.00262  (0.00454)\n",
            "     | > decoder_diff_spec_loss: 0.22521  (0.21910)\n",
            "     | > postnet_diff_spec_loss: 0.46787  (0.46477)\n",
            "     | > decoder_ssim_loss: 0.96172  (0.96415)\n",
            "     | > postnet_ssim_loss: 0.91564  (0.92406)\n",
            "     | > loss: 3.02031  (3.01621)\n",
            "     | > align_error: 0.99155  (0.98538)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.37239  (1.36080)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.04480  (1.35867)\n",
            "     | > loader_time: 0.02470  (0.01779)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 351/406 -- GLOBAL_STEP: 1975\u001b[0m\n",
            "     | > decoder_loss: 4.39691  (4.32809)\n",
            "     | > postnet_loss: 2.65605  (2.63483)\n",
            "     | > stopnet_loss: 0.61117  (0.61234)\n",
            "     | > ga_loss: 0.00253  (0.00441)\n",
            "     | > decoder_diff_spec_loss: 0.21641  (0.21901)\n",
            "     | > postnet_diff_spec_loss: 0.46234  (0.46454)\n",
            "     | > decoder_ssim_loss: 0.96313  (0.96401)\n",
            "     | > postnet_ssim_loss: 0.91542  (0.92347)\n",
            "     | > loss: 3.02641  (3.01786)\n",
            "     | > align_error: 0.99125  (0.98580)\n",
            "     | > amp_scaler: 65536.00000  (65536.00000)\n",
            "     | > grad_norm: 1.37090  (1.36204)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.03930  (1.40273)\n",
            "     | > loader_time: 0.02640  (0.01841)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 376/406 -- GLOBAL_STEP: 2000\u001b[0m\n",
            "     | > decoder_loss: 4.32436  (4.33561)\n",
            "     | > postnet_loss: 2.64842  (2.63633)\n",
            "     | > stopnet_loss: 0.60896  (0.61217)\n",
            "     | > ga_loss: 0.00241  (0.00428)\n",
            "     | > decoder_diff_spec_loss: 0.21746  (0.21895)\n",
            "     | > postnet_diff_spec_loss: 0.46376  (0.46437)\n",
            "     | > decoder_ssim_loss: 0.96157  (0.96388)\n",
            "     | > postnet_ssim_loss: 0.91540  (0.92291)\n",
            "     | > loss: 3.00374  (3.01907)\n",
            "     | > align_error: 0.99188  (0.98619)\n",
            "     | > amp_scaler: 131072.00000  (65884.59574)\n",
            "     | > grad_norm: 1.37352  (1.36323)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.08290  (1.44742)\n",
            "     | > loader_time: 0.03520  (0.01902)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_2000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 401/406 -- GLOBAL_STEP: 2025\u001b[0m\n",
            "     | > decoder_loss: 4.40458  (4.34361)\n",
            "     | > postnet_loss: 2.63090  (2.63763)\n",
            "     | > stopnet_loss: 0.61119  (0.61198)\n",
            "     | > ga_loss: 0.00230  (0.00416)\n",
            "     | > decoder_diff_spec_loss: 0.21533  (0.21892)\n",
            "     | > postnet_diff_spec_loss: 0.46009  (0.46423)\n",
            "     | > decoder_ssim_loss: 0.96112  (0.96373)\n",
            "     | > postnet_ssim_loss: 0.91461  (0.92242)\n",
            "     | > loss: 3.01936  (3.02041)\n",
            "     | > align_error: 0.99243  (0.98656)\n",
            "     | > amp_scaler: 131072.00000  (69948.64838)\n",
            "     | > grad_norm: 1.36987  (1.36392)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.89210  (1.48770)\n",
            "     | > loader_time: 0.02810  (0.01972)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01282 \u001b[0m(+0.00172)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.32883 \u001b[0m(-0.02180)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.62084 \u001b[0m(-0.00211)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.58175 \u001b[0m(-0.00819)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00335 \u001b[0m(-0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.21523 \u001b[0m(-0.00015)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[91m 0.46484 \u001b[0m(+0.00001)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.92286 \u001b[0m(-0.00168)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.87607 \u001b[0m(-0.00996)\n",
            "     | > avg_loss:\u001b[92m 2.95567 \u001b[0m(-0.01713)\n",
            "     | > avg_align_error:\u001b[91m 0.98976 \u001b[0m(+0.00001)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_2030.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 5/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 06:58:36) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 20/406 -- GLOBAL_STEP: 2050\u001b[0m\n",
            "     | > decoder_loss: 3.85462  (4.03901)\n",
            "     | > postnet_loss: 2.58157  (2.60970)\n",
            "     | > stopnet_loss: 0.60903  (0.60869)\n",
            "     | > ga_loss: 0.00823  (0.01176)\n",
            "     | > decoder_diff_spec_loss: 0.22254  (0.21618)\n",
            "     | > postnet_diff_spec_loss: 0.47546  (0.46806)\n",
            "     | > decoder_ssim_loss: 0.96524  (0.96200)\n",
            "     | > postnet_ssim_loss: 0.93721  (0.92818)\n",
            "     | > loss: 2.90932  (2.97326)\n",
            "     | > align_error: 0.97585  (0.96466)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.31241  (1.31111)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.72500  (0.65151)\n",
            "     | > loader_time: 0.00920  (0.00922)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 45/406 -- GLOBAL_STEP: 2075\u001b[0m\n",
            "     | > decoder_loss: 4.10097  (4.06250)\n",
            "     | > postnet_loss: 2.53234  (2.59976)\n",
            "     | > stopnet_loss: 0.60806  (0.60756)\n",
            "     | > ga_loss: 0.00639  (0.00925)\n",
            "     | > decoder_diff_spec_loss: 0.21989  (0.21777)\n",
            "     | > postnet_diff_spec_loss: 0.46895  (0.46784)\n",
            "     | > decoder_ssim_loss: 0.96597  (0.96275)\n",
            "     | > postnet_ssim_loss: 0.93359  (0.93099)\n",
            "     | > loss: 2.94543  (2.96419)\n",
            "     | > align_error: 0.98003  (0.97164)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.33228  (1.32152)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.92020  (0.74423)\n",
            "     | > loader_time: 0.01160  (0.01000)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 70/406 -- GLOBAL_STEP: 2100\u001b[0m\n",
            "     | > decoder_loss: 4.22830  (4.11686)\n",
            "     | > postnet_loss: 2.62061  (2.60415)\n",
            "     | > stopnet_loss: 0.60833  (0.60769)\n",
            "     | > ga_loss: 0.00536  (0.00803)\n",
            "     | > decoder_diff_spec_loss: 0.22174  (0.21818)\n",
            "     | > postnet_diff_spec_loss: 0.46703  (0.46717)\n",
            "     | > decoder_ssim_loss: 0.96176  (0.96294)\n",
            "     | > postnet_ssim_loss: 0.93078  (0.93138)\n",
            "     | > loss: 2.99266  (2.97300)\n",
            "     | > align_error: 0.98207  (0.97505)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.35358  (1.33041)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.01890  (0.81952)\n",
            "     | > loader_time: 0.01710  (0.01103)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 95/406 -- GLOBAL_STEP: 2125\u001b[0m\n",
            "     | > decoder_loss: 4.22963  (4.15545)\n",
            "     | > postnet_loss: 2.62464  (2.61031)\n",
            "     | > stopnet_loss: 0.61001  (0.60768)\n",
            "     | > ga_loss: 0.00456  (0.00723)\n",
            "     | > decoder_diff_spec_loss: 0.22326  (0.21854)\n",
            "     | > postnet_diff_spec_loss: 0.46792  (0.46666)\n",
            "     | > decoder_ssim_loss: 0.96325  (0.96301)\n",
            "     | > postnet_ssim_loss: 0.91683  (0.92857)\n",
            "     | > loss: 2.98918  (2.97945)\n",
            "     | > align_error: 0.98481  (0.97739)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.35381  (1.33684)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.20030  (0.88672)\n",
            "     | > loader_time: 0.01880  (0.01199)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 120/406 -- GLOBAL_STEP: 2150\u001b[0m\n",
            "     | > decoder_loss: 4.34747  (4.18145)\n",
            "     | > postnet_loss: 2.62942  (2.61314)\n",
            "     | > stopnet_loss: 0.60539  (0.60735)\n",
            "     | > ga_loss: 0.00428  (0.00665)\n",
            "     | > decoder_diff_spec_loss: 0.22051  (0.21880)\n",
            "     | > postnet_diff_spec_loss: 0.46746  (0.46649)\n",
            "     | > decoder_ssim_loss: 0.96348  (0.96296)\n",
            "     | > postnet_ssim_loss: 0.91541  (0.92585)\n",
            "     | > loss: 3.01273  (2.98277)\n",
            "     | > align_error: 0.98578  (0.97910)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.35657  (1.34066)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.21020  (0.94664)\n",
            "     | > loader_time: 0.01630  (0.01275)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 145/406 -- GLOBAL_STEP: 2175\u001b[0m\n",
            "     | > decoder_loss: 4.18211  (4.20870)\n",
            "     | > postnet_loss: 2.58551  (2.61552)\n",
            "     | > stopnet_loss: 0.60678  (0.60716)\n",
            "     | > ga_loss: 0.00379  (0.00621)\n",
            "     | > decoder_diff_spec_loss: 0.22097  (0.21890)\n",
            "     | > postnet_diff_spec_loss: 0.46681  (0.46620)\n",
            "     | > decoder_ssim_loss: 0.95950  (0.96273)\n",
            "     | > postnet_ssim_loss: 0.91298  (0.92381)\n",
            "     | > loss: 2.95771  (2.98718)\n",
            "     | > align_error: 0.98795  (0.98036)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.35614  (1.34452)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.30400  (1.00687)\n",
            "     | > loader_time: 0.01670  (0.01351)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 170/406 -- GLOBAL_STEP: 2200\u001b[0m\n",
            "     | > decoder_loss: 4.28557  (4.22330)\n",
            "     | > postnet_loss: 2.62288  (2.61737)\n",
            "     | > stopnet_loss: 0.60481  (0.60700)\n",
            "     | > ga_loss: 0.00368  (0.00586)\n",
            "     | > decoder_diff_spec_loss: 0.22137  (0.21902)\n",
            "     | > postnet_diff_spec_loss: 0.46292  (0.46603)\n",
            "     | > decoder_ssim_loss: 0.96086  (0.96258)\n",
            "     | > postnet_ssim_loss: 0.91390  (0.92230)\n",
            "     | > loss: 2.99006  (2.98892)\n",
            "     | > align_error: 0.98779  (0.98139)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.35691  (1.34686)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.38470  (1.05857)\n",
            "     | > loader_time: 0.01830  (0.01422)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 195/406 -- GLOBAL_STEP: 2225\u001b[0m\n",
            "     | > decoder_loss: 4.23609  (4.23818)\n",
            "     | > postnet_loss: 2.59933  (2.62007)\n",
            "     | > stopnet_loss: 0.60419  (0.60686)\n",
            "     | > ga_loss: 0.00343  (0.00556)\n",
            "     | > decoder_diff_spec_loss: 0.22349  (0.21897)\n",
            "     | > postnet_diff_spec_loss: 0.46852  (0.46567)\n",
            "     | > decoder_ssim_loss: 0.96005  (0.96238)\n",
            "     | > postnet_ssim_loss: 0.91301  (0.92101)\n",
            "     | > loss: 2.97146  (2.99124)\n",
            "     | > align_error: 0.98884  (0.98228)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.36230  (1.34959)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.90880  (1.11005)\n",
            "     | > loader_time: 0.01930  (0.01480)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 220/406 -- GLOBAL_STEP: 2250\u001b[0m\n",
            "     | > decoder_loss: 4.53536  (4.25445)\n",
            "     | > postnet_loss: 2.69418  (2.62286)\n",
            "     | > stopnet_loss: 0.60568  (0.60665)\n",
            "     | > ga_loss: 0.00332  (0.00531)\n",
            "     | > decoder_diff_spec_loss: 0.21859  (0.21901)\n",
            "     | > postnet_diff_spec_loss: 0.46258  (0.46543)\n",
            "     | > decoder_ssim_loss: 0.96127  (0.96218)\n",
            "     | > postnet_ssim_loss: 0.90922  (0.91990)\n",
            "     | > loss: 3.06758  (2.99415)\n",
            "     | > align_error: 0.98914  (0.98304)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.37738  (1.35172)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.53730  (1.15539)\n",
            "     | > loader_time: 0.02100  (0.01547)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 245/406 -- GLOBAL_STEP: 2275\u001b[0m\n",
            "     | > decoder_loss: 4.36275  (4.26781)\n",
            "     | > postnet_loss: 2.63713  (2.62592)\n",
            "     | > stopnet_loss: 0.60435  (0.60637)\n",
            "     | > ga_loss: 0.00306  (0.00509)\n",
            "     | > decoder_diff_spec_loss: 0.22016  (0.21902)\n",
            "     | > postnet_diff_spec_loss: 0.46402  (0.46524)\n",
            "     | > decoder_ssim_loss: 0.95949  (0.96201)\n",
            "     | > postnet_ssim_loss: 0.91061  (0.91897)\n",
            "     | > loss: 3.00819  (2.99657)\n",
            "     | > align_error: 0.98965  (0.98370)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.37015  (1.35367)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.63290  (1.20599)\n",
            "     | > loader_time: 0.02130  (0.01604)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 270/406 -- GLOBAL_STEP: 2300\u001b[0m\n",
            "     | > decoder_loss: 4.31848  (4.27515)\n",
            "     | > postnet_loss: 2.64020  (2.62732)\n",
            "     | > stopnet_loss: 0.60493  (0.60611)\n",
            "     | > ga_loss: 0.00295  (0.00490)\n",
            "     | > decoder_diff_spec_loss: 0.21978  (0.21900)\n",
            "     | > postnet_diff_spec_loss: 0.46232  (0.46505)\n",
            "     | > decoder_ssim_loss: 0.96006  (0.96181)\n",
            "     | > postnet_ssim_loss: 0.91014  (0.91814)\n",
            "     | > loss: 2.99742  (2.99722)\n",
            "     | > align_error: 0.99021  (0.98430)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.36829  (1.35532)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.86820  (1.25522)\n",
            "     | > loader_time: 0.02210  (0.01660)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 295/406 -- GLOBAL_STEP: 2325\u001b[0m\n",
            "     | > decoder_loss: 4.46465  (4.28449)\n",
            "     | > postnet_loss: 2.63861  (2.62949)\n",
            "     | > stopnet_loss: 0.60522  (0.60585)\n",
            "     | > ga_loss: 0.00277  (0.00473)\n",
            "     | > decoder_diff_spec_loss: 0.21706  (0.21897)\n",
            "     | > postnet_diff_spec_loss: 0.46112  (0.46489)\n",
            "     | > decoder_ssim_loss: 0.95997  (0.96161)\n",
            "     | > postnet_ssim_loss: 0.90937  (0.91738)\n",
            "     | > loss: 3.03178  (2.99869)\n",
            "     | > align_error: 0.99052  (0.98482)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.38337  (1.35666)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.75340  (1.30255)\n",
            "     | > loader_time: 0.02310  (0.01718)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 320/406 -- GLOBAL_STEP: 2350\u001b[0m\n",
            "     | > decoder_loss: 4.30713  (4.29131)\n",
            "     | > postnet_loss: 2.63640  (2.63091)\n",
            "     | > stopnet_loss: 0.60338  (0.60569)\n",
            "     | > ga_loss: 0.00264  (0.00457)\n",
            "     | > decoder_diff_spec_loss: 0.22173  (0.21898)\n",
            "     | > postnet_diff_spec_loss: 0.46700  (0.46477)\n",
            "     | > decoder_ssim_loss: 0.96011  (0.96142)\n",
            "     | > postnet_ssim_loss: 0.90913  (0.91669)\n",
            "     | > loss: 2.99193  (2.99956)\n",
            "     | > align_error: 0.99082  (0.98530)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.36766  (1.35798)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.89330  (1.34909)\n",
            "     | > loader_time: 0.02500  (0.01774)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 345/406 -- GLOBAL_STEP: 2375\u001b[0m\n",
            "     | > decoder_loss: 4.54522  (4.29944)\n",
            "     | > postnet_loss: 2.64404  (2.63268)\n",
            "     | > stopnet_loss: 0.60382  (0.60547)\n",
            "     | > ga_loss: 0.00260  (0.00443)\n",
            "     | > decoder_diff_spec_loss: 0.21566  (0.21895)\n",
            "     | > postnet_diff_spec_loss: 0.45778  (0.46458)\n",
            "     | > decoder_ssim_loss: 0.95848  (0.96122)\n",
            "     | > postnet_ssim_loss: 0.90684  (0.91604)\n",
            "     | > loss: 3.04884  (3.00085)\n",
            "     | > align_error: 0.99111  (0.98572)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.39929  (1.35958)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.02160  (1.39332)\n",
            "     | > loader_time: 0.02490  (0.01831)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 370/406 -- GLOBAL_STEP: 2400\u001b[0m\n",
            "     | > decoder_loss: 4.56944  (4.30767)\n",
            "     | > postnet_loss: 2.71006  (2.63433)\n",
            "     | > stopnet_loss: 0.59904  (0.60519)\n",
            "     | > ga_loss: 0.00243  (0.00430)\n",
            "     | > decoder_diff_spec_loss: 0.21785  (0.21890)\n",
            "     | > postnet_diff_spec_loss: 0.45820  (0.46440)\n",
            "     | > decoder_ssim_loss: 0.95849  (0.96103)\n",
            "     | > postnet_ssim_loss: 0.90520  (0.91542)\n",
            "     | > loss: 3.06598  (3.00212)\n",
            "     | > align_error: 0.99195  (0.98613)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.38632  (1.36118)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.97710  (1.43753)\n",
            "     | > loader_time: 0.02590  (0.01889)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 395/406 -- GLOBAL_STEP: 2425\u001b[0m\n",
            "     | > decoder_loss: 4.44952  (4.31410)\n",
            "     | > postnet_loss: 2.67437  (2.63538)\n",
            "     | > stopnet_loss: 0.60061  (0.60494)\n",
            "     | > ga_loss: 0.00234  (0.00418)\n",
            "     | > decoder_diff_spec_loss: 0.21495  (0.21885)\n",
            "     | > postnet_diff_spec_loss: 0.45917  (0.46425)\n",
            "     | > decoder_ssim_loss: 0.95829  (0.96081)\n",
            "     | > postnet_ssim_loss: 0.90566  (0.91484)\n",
            "     | > loss: 3.02778  (3.00289)\n",
            "     | > align_error: 0.99242  (0.98650)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.38150  (1.36223)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.05310  (1.48016)\n",
            "     | > loader_time: 0.02830  (0.01943)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01474 \u001b[0m(+0.00192)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.30162 \u001b[0m(-0.02721)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.61855 \u001b[0m(-0.00228)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.57499 \u001b[0m(-0.00676)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00335 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.21524 \u001b[0m(+0.00001)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46483 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.92079 \u001b[0m(-0.00207)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.86533 \u001b[0m(-0.01074)\n",
            "     | > avg_loss:\u001b[92m 2.93831 \u001b[0m(-0.01736)\n",
            "     | > avg_align_error:\u001b[91m 0.98976 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_2436.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 6/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 07:19:41) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 14/406 -- GLOBAL_STEP: 2450\u001b[0m\n",
            "     | > decoder_loss: 4.20014  (4.02360)\n",
            "     | > postnet_loss: 2.67172  (2.61649)\n",
            "     | > stopnet_loss: 0.59630  (0.60069)\n",
            "     | > ga_loss: 0.00989  (0.01290)\n",
            "     | > decoder_diff_spec_loss: 0.21696  (0.21430)\n",
            "     | > postnet_diff_spec_loss: 0.46423  (0.46618)\n",
            "     | > decoder_ssim_loss: 0.96006  (0.95718)\n",
            "     | > postnet_ssim_loss: 0.92470  (0.91802)\n",
            "     | > loss: 3.00520  (2.96413)\n",
            "     | > align_error: 0.97149  (0.96178)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.32888  (1.31494)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.65750  (0.60253)\n",
            "     | > loader_time: 0.00840  (0.00785)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 39/406 -- GLOBAL_STEP: 2475\u001b[0m\n",
            "     | > decoder_loss: 3.99538  (4.03571)\n",
            "     | > postnet_loss: 2.56799  (2.60125)\n",
            "     | > stopnet_loss: 0.60208  (0.60004)\n",
            "     | > ga_loss: 0.00676  (0.00965)\n",
            "     | > decoder_diff_spec_loss: 0.22004  (0.21748)\n",
            "     | > postnet_diff_spec_loss: 0.46646  (0.46787)\n",
            "     | > decoder_ssim_loss: 0.95788  (0.95885)\n",
            "     | > postnet_ssim_loss: 0.92643  (0.92271)\n",
            "     | > loss: 2.91941  (2.94925)\n",
            "     | > align_error: 0.97577  (0.97048)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.33612  (1.32919)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.79110  (0.71811)\n",
            "     | > loader_time: 0.01070  (0.00927)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 64/406 -- GLOBAL_STEP: 2500\u001b[0m\n",
            "     | > decoder_loss: 4.02221  (4.07280)\n",
            "     | > postnet_loss: 2.58227  (2.59933)\n",
            "     | > stopnet_loss: 0.59626  (0.59978)\n",
            "     | > ga_loss: 0.00521  (0.00824)\n",
            "     | > decoder_diff_spec_loss: 0.22518  (0.21812)\n",
            "     | > postnet_diff_spec_loss: 0.47654  (0.46744)\n",
            "     | > decoder_ssim_loss: 0.95882  (0.95904)\n",
            "     | > postnet_ssim_loss: 0.92359  (0.92295)\n",
            "     | > loss: 2.91945  (2.95091)\n",
            "     | > align_error: 0.98273  (0.97448)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.34125  (1.33848)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.99810  (0.79844)\n",
            "     | > loader_time: 0.01270  (0.01037)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 89/406 -- GLOBAL_STEP: 2525\u001b[0m\n",
            "     | > decoder_loss: 4.14255  (4.11520)\n",
            "     | > postnet_loss: 2.56192  (2.60541)\n",
            "     | > stopnet_loss: 0.60209  (0.59970)\n",
            "     | > ga_loss: 0.00488  (0.00737)\n",
            "     | > decoder_diff_spec_loss: 0.21863  (0.21849)\n",
            "     | > postnet_diff_spec_loss: 0.46592  (0.46681)\n",
            "     | > decoder_ssim_loss: 0.95760  (0.95908)\n",
            "     | > postnet_ssim_loss: 0.90763  (0.92090)\n",
            "     | > loss: 2.94006  (2.95803)\n",
            "     | > align_error: 0.98377  (0.97697)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.36550  (1.34607)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.05360  (0.86852)\n",
            "     | > loader_time: 0.01450  (0.01153)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 114/406 -- GLOBAL_STEP: 2550\u001b[0m\n",
            "     | > decoder_loss: 4.43187  (4.14554)\n",
            "     | > postnet_loss: 2.68373  (2.61047)\n",
            "     | > stopnet_loss: 0.60032  (0.59940)\n",
            "     | > ga_loss: 0.00443  (0.00675)\n",
            "     | > decoder_diff_spec_loss: 0.21776  (0.21881)\n",
            "     | > postnet_diff_spec_loss: 0.46300  (0.46655)\n",
            "     | > decoder_ssim_loss: 0.95759  (0.95892)\n",
            "     | > postnet_ssim_loss: 0.90519  (0.91791)\n",
            "     | > loss: 3.03723  (2.96270)\n",
            "     | > align_error: 0.98547  (0.97881)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.37558  (1.35126)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.23870  (0.93149)\n",
            "     | > loader_time: 0.01560  (0.01250)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 139/406 -- GLOBAL_STEP: 2575\u001b[0m\n",
            "     | > decoder_loss: 4.33606  (4.17362)\n",
            "     | > postnet_loss: 2.61444  (2.61320)\n",
            "     | > stopnet_loss: 0.59578  (0.59929)\n",
            "     | > ga_loss: 0.00408  (0.00629)\n",
            "     | > decoder_diff_spec_loss: 0.21992  (0.21888)\n",
            "     | > postnet_diff_spec_loss: 0.46439  (0.46616)\n",
            "     | > decoder_ssim_loss: 0.95617  (0.95869)\n",
            "     | > postnet_ssim_loss: 0.90374  (0.91575)\n",
            "     | > loss: 2.98984  (2.96730)\n",
            "     | > align_error: 0.98627  (0.98015)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.37029  (1.35606)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.31130  (0.99010)\n",
            "     | > loader_time: 0.01690  (0.01328)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 164/406 -- GLOBAL_STEP: 2600\u001b[0m\n",
            "     | > decoder_loss: 4.26020  (4.18896)\n",
            "     | > postnet_loss: 2.59289  (2.61426)\n",
            "     | > stopnet_loss: 0.59778  (0.59906)\n",
            "     | > ga_loss: 0.00372  (0.00592)\n",
            "     | > decoder_diff_spec_loss: 0.21645  (0.21907)\n",
            "     | > postnet_diff_spec_loss: 0.45950  (0.46605)\n",
            "     | > decoder_ssim_loss: 0.95640  (0.95847)\n",
            "     | > postnet_ssim_loss: 0.90365  (0.91412)\n",
            "     | > loss: 2.96363  (2.96887)\n",
            "     | > align_error: 0.98744  (0.98122)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.38085  (1.35910)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.38260  (1.04531)\n",
            "     | > loader_time: 0.01800  (0.01410)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 189/406 -- GLOBAL_STEP: 2625\u001b[0m\n",
            "     | > decoder_loss: 4.29369  (4.20372)\n",
            "     | > postnet_loss: 2.61517  (2.61734)\n",
            "     | > stopnet_loss: 0.59980  (0.59885)\n",
            "     | > ga_loss: 0.00360  (0.00561)\n",
            "     | > decoder_diff_spec_loss: 0.21994  (0.21907)\n",
            "     | > postnet_diff_spec_loss: 0.46192  (0.46571)\n",
            "     | > decoder_ssim_loss: 0.95427  (0.95819)\n",
            "     | > postnet_ssim_loss: 0.90262  (0.91280)\n",
            "     | > loss: 2.97970  (2.97112)\n",
            "     | > align_error: 0.98752  (0.98213)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.38275  (1.36244)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.59580  (1.09411)\n",
            "     | > loader_time: 0.01900  (0.01473)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 214/406 -- GLOBAL_STEP: 2650\u001b[0m\n",
            "     | > decoder_loss: 4.37911  (4.21852)\n",
            "     | > postnet_loss: 2.62813  (2.61972)\n",
            "     | > stopnet_loss: 0.59698  (0.59850)\n",
            "     | > ga_loss: 0.00325  (0.00535)\n",
            "     | > decoder_diff_spec_loss: 0.21926  (0.21913)\n",
            "     | > postnet_diff_spec_loss: 0.46142  (0.46543)\n",
            "     | > decoder_ssim_loss: 0.95469  (0.95791)\n",
            "     | > postnet_ssim_loss: 0.90318  (0.91169)\n",
            "     | > loss: 2.99967  (2.97335)\n",
            "     | > align_error: 0.98883  (0.98293)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.39214  (1.36521)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.51760  (1.14148)\n",
            "     | > loader_time: 0.02570  (0.01541)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 239/406 -- GLOBAL_STEP: 2675\u001b[0m\n",
            "     | > decoder_loss: 4.34472  (4.23186)\n",
            "     | > postnet_loss: 2.66692  (2.62285)\n",
            "     | > stopnet_loss: 0.59635  (0.59821)\n",
            "     | > ga_loss: 0.00320  (0.00513)\n",
            "     | > decoder_diff_spec_loss: 0.21616  (0.21914)\n",
            "     | > postnet_diff_spec_loss: 0.45706  (0.46523)\n",
            "     | > decoder_ssim_loss: 0.95453  (0.95765)\n",
            "     | > postnet_ssim_loss: 0.89938  (0.91072)\n",
            "     | > loss: 2.99703  (2.97571)\n",
            "     | > align_error: 0.98921  (0.98361)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.39556  (1.36807)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.74690  (1.19014)\n",
            "     | > loader_time: 0.02730  (0.01604)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 264/406 -- GLOBAL_STEP: 2700\u001b[0m\n",
            "     | > decoder_loss: 4.33554  (4.24058)\n",
            "     | > postnet_loss: 2.58604  (2.62446)\n",
            "     | > stopnet_loss: 0.59307  (0.59792)\n",
            "     | > ga_loss: 0.00299  (0.00493)\n",
            "     | > decoder_diff_spec_loss: 0.21973  (0.21914)\n",
            "     | > postnet_diff_spec_loss: 0.46192  (0.46506)\n",
            "     | > decoder_ssim_loss: 0.95577  (0.95740)\n",
            "     | > postnet_ssim_loss: 0.90136  (0.90989)\n",
            "     | > loss: 2.97313  (2.97669)\n",
            "     | > align_error: 0.99024  (0.98422)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.39707  (1.37062)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.65640  (1.23798)\n",
            "     | > loader_time: 0.02280  (0.01661)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 289/406 -- GLOBAL_STEP: 2725\u001b[0m\n",
            "     | > decoder_loss: 4.30741  (4.24879)\n",
            "     | > postnet_loss: 2.61055  (2.62648)\n",
            "     | > stopnet_loss: 0.59311  (0.59762)\n",
            "     | > ga_loss: 0.00275  (0.00475)\n",
            "     | > decoder_diff_spec_loss: 0.22015  (0.21914)\n",
            "     | > postnet_diff_spec_loss: 0.46300  (0.46491)\n",
            "     | > decoder_ssim_loss: 0.95305  (0.95714)\n",
            "     | > postnet_ssim_loss: 0.90176  (0.90914)\n",
            "     | > loss: 2.97085  (2.97778)\n",
            "     | > align_error: 0.99078  (0.98475)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.39470  (1.37269)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.84430  (1.28678)\n",
            "     | > loader_time: 0.02350  (0.01726)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 314/406 -- GLOBAL_STEP: 2750\u001b[0m\n",
            "     | > decoder_loss: 4.35612  (4.25635)\n",
            "     | > postnet_loss: 2.62267  (2.62836)\n",
            "     | > stopnet_loss: 0.59290  (0.59735)\n",
            "     | > ga_loss: 0.00265  (0.00459)\n",
            "     | > decoder_diff_spec_loss: 0.21808  (0.21911)\n",
            "     | > postnet_diff_spec_loss: 0.46297  (0.46474)\n",
            "     | > decoder_ssim_loss: 0.95375  (0.95687)\n",
            "     | > postnet_ssim_loss: 0.90049  (0.90846)\n",
            "     | > loss: 2.98468  (2.97879)\n",
            "     | > align_error: 0.99119  (0.98523)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.40529  (1.37477)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.80500  (1.33152)\n",
            "     | > loader_time: 0.02460  (0.01786)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 339/406 -- GLOBAL_STEP: 2775\u001b[0m\n",
            "     | > decoder_loss: 4.32740  (4.26325)\n",
            "     | > postnet_loss: 2.64666  (2.62996)\n",
            "     | > stopnet_loss: 0.59149  (0.59706)\n",
            "     | > ga_loss: 0.00257  (0.00445)\n",
            "     | > decoder_diff_spec_loss: 0.22264  (0.21914)\n",
            "     | > postnet_diff_spec_loss: 0.46581  (0.46460)\n",
            "     | > decoder_ssim_loss: 0.95442  (0.95658)\n",
            "     | > postnet_ssim_loss: 0.89933  (0.90780)\n",
            "     | > loss: 2.98340  (2.97964)\n",
            "     | > align_error: 0.99167  (0.98567)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.40562  (1.37708)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.90030  (1.37889)\n",
            "     | > loader_time: 0.02540  (0.01844)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 364/406 -- GLOBAL_STEP: 2800\u001b[0m\n",
            "     | > decoder_loss: 4.42448  (4.27182)\n",
            "     | > postnet_loss: 2.67687  (2.63144)\n",
            "     | > stopnet_loss: 0.59312  (0.59673)\n",
            "     | > ga_loss: 0.00247  (0.00432)\n",
            "     | > decoder_diff_spec_loss: 0.21754  (0.21907)\n",
            "     | > postnet_diff_spec_loss: 0.45888  (0.46439)\n",
            "     | > decoder_ssim_loss: 0.95330  (0.95633)\n",
            "     | > postnet_ssim_loss: 0.89760  (0.90718)\n",
            "     | > loss: 3.01265  (2.98087)\n",
            "     | > align_error: 0.99153  (0.98608)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.41144  (1.37946)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.09810  (1.42302)\n",
            "     | > loader_time: 0.02670  (0.01901)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 389/406 -- GLOBAL_STEP: 2825\u001b[0m\n",
            "     | > decoder_loss: 4.45419  (4.27800)\n",
            "     | > postnet_loss: 2.65186  (2.63253)\n",
            "     | > stopnet_loss: 0.58977  (0.59638)\n",
            "     | > ga_loss: 0.00236  (0.00419)\n",
            "     | > decoder_diff_spec_loss: 0.21550  (0.21905)\n",
            "     | > postnet_diff_spec_loss: 0.45767  (0.46425)\n",
            "     | > decoder_ssim_loss: 0.95077  (0.95605)\n",
            "     | > postnet_ssim_loss: 0.89797  (0.90663)\n",
            "     | > loss: 3.00855  (2.98149)\n",
            "     | > align_error: 0.99246  (0.98646)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.41535  (1.38131)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.09830  (1.46746)\n",
            "     | > loader_time: 0.02800  (0.01967)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01110 \u001b[0m(-0.00364)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.26493 \u001b[0m(-0.03669)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.61558 \u001b[0m(-0.00298)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.56486 \u001b[0m(-0.01013)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00334 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.21519 \u001b[0m(-0.00005)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46483 \u001b[0m(-0.00000)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.91794 \u001b[0m(-0.00285)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.85563 \u001b[0m(-0.00970)\n",
            "     | > avg_loss:\u001b[92m 2.91507 \u001b[0m(-0.02323)\n",
            "     | > avg_align_error:\u001b[91m 0.98977 \u001b[0m(+0.00001)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_2842.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 7/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 07:40:42) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 8/406 -- GLOBAL_STEP: 2850\u001b[0m\n",
            "     | > decoder_loss: 3.99165  (3.95126)\n",
            "     | > postnet_loss: 2.69959  (2.62128)\n",
            "     | > stopnet_loss: 0.58951  (0.58860)\n",
            "     | > ga_loss: 0.01206  (0.01465)\n",
            "     | > decoder_diff_spec_loss: 0.21633  (0.21255)\n",
            "     | > postnet_diff_spec_loss: 0.46974  (0.46427)\n",
            "     | > decoder_ssim_loss: 0.94803  (0.94917)\n",
            "     | > postnet_ssim_loss: 0.90800  (0.90690)\n",
            "     | > loss: 2.95814  (2.93819)\n",
            "     | > align_error: 0.96446  (0.95786)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.34843  (1.33712)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.67330  (0.59116)\n",
            "     | > loader_time: 0.00930  (0.00749)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 33/406 -- GLOBAL_STEP: 2875\u001b[0m\n",
            "     | > decoder_loss: 4.00700  (3.99808)\n",
            "     | > postnet_loss: 2.58343  (2.60039)\n",
            "     | > stopnet_loss: 0.59132  (0.59036)\n",
            "     | > ga_loss: 0.00732  (0.01010)\n",
            "     | > decoder_diff_spec_loss: 0.21590  (0.21782)\n",
            "     | > postnet_diff_spec_loss: 0.46397  (0.46787)\n",
            "     | > decoder_ssim_loss: 0.95529  (0.95306)\n",
            "     | > postnet_ssim_loss: 0.91691  (0.91334)\n",
            "     | > loss: 2.91355  (2.92851)\n",
            "     | > align_error: 0.97705  (0.96918)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.38152  (1.36147)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.80430  (0.69025)\n",
            "     | > loader_time: 0.01050  (0.00886)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 58/406 -- GLOBAL_STEP: 2900\u001b[0m\n",
            "     | > decoder_loss: 4.23723  (4.02537)\n",
            "     | > postnet_loss: 2.62268  (2.59682)\n",
            "     | > stopnet_loss: 0.58706  (0.58978)\n",
            "     | > ga_loss: 0.00596  (0.00848)\n",
            "     | > decoder_diff_spec_loss: 0.22063  (0.21847)\n",
            "     | > postnet_diff_spec_loss: 0.46753  (0.46740)\n",
            "     | > decoder_ssim_loss: 0.95269  (0.95321)\n",
            "     | > postnet_ssim_loss: 0.91310  (0.91392)\n",
            "     | > loss: 2.97031  (2.92598)\n",
            "     | > align_error: 0.98070  (0.97380)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.39128  (1.37159)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.94730  (0.77622)\n",
            "     | > loader_time: 0.01190  (0.01012)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 83/406 -- GLOBAL_STEP: 2925\u001b[0m\n",
            "     | > decoder_loss: 4.13044  (4.06871)\n",
            "     | > postnet_loss: 2.59041  (2.60184)\n",
            "     | > stopnet_loss: 0.58906  (0.58964)\n",
            "     | > ga_loss: 0.00504  (0.00752)\n",
            "     | > decoder_diff_spec_loss: 0.21808  (0.21899)\n",
            "     | > postnet_diff_spec_loss: 0.46455  (0.46696)\n",
            "     | > decoder_ssim_loss: 0.95048  (0.95321)\n",
            "     | > postnet_ssim_loss: 0.90113  (0.91283)\n",
            "     | > loss: 2.92803  (2.93288)\n",
            "     | > align_error: 0.98380  (0.97650)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.40374  (1.38055)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.04250  (0.85443)\n",
            "     | > loader_time: 0.01430  (0.01111)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 108/406 -- GLOBAL_STEP: 2950\u001b[0m\n",
            "     | > decoder_loss: 4.17329  (4.09872)\n",
            "     | > postnet_loss: 2.62699  (2.60577)\n",
            "     | > stopnet_loss: 0.58780  (0.58935)\n",
            "     | > ga_loss: 0.00433  (0.00685)\n",
            "     | > decoder_diff_spec_loss: 0.22497  (0.21932)\n",
            "     | > postnet_diff_spec_loss: 0.47135  (0.46659)\n",
            "     | > decoder_ssim_loss: 0.95350  (0.95313)\n",
            "     | > postnet_ssim_loss: 0.90090  (0.90984)\n",
            "     | > loss: 2.94720  (2.93695)\n",
            "     | > align_error: 0.98611  (0.97849)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.40662  (1.38682)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.18720  (0.91572)\n",
            "     | > loader_time: 0.01520  (0.01209)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 133/406 -- GLOBAL_STEP: 2975\u001b[0m\n",
            "     | > decoder_loss: 4.27054  (4.12598)\n",
            "     | > postnet_loss: 2.62071  (2.60897)\n",
            "     | > stopnet_loss: 0.58870  (0.58911)\n",
            "     | > ga_loss: 0.00408  (0.00636)\n",
            "     | > decoder_diff_spec_loss: 0.21872  (0.21940)\n",
            "     | > postnet_diff_spec_loss: 0.46516  (0.46628)\n",
            "     | > decoder_ssim_loss: 0.95017  (0.95286)\n",
            "     | > postnet_ssim_loss: 0.89843  (0.90774)\n",
            "     | > loss: 2.96506  (2.94121)\n",
            "     | > align_error: 0.98649  (0.97993)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.42613  (1.39266)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.23390  (0.97383)\n",
            "     | > loader_time: 0.01670  (0.01297)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 158/406 -- GLOBAL_STEP: 3000\u001b[0m\n",
            "     | > decoder_loss: 4.36967  (4.14629)\n",
            "     | > postnet_loss: 2.66357  (2.61084)\n",
            "     | > stopnet_loss: 0.58533  (0.58873)\n",
            "     | > ga_loss: 0.00380  (0.00597)\n",
            "     | > decoder_diff_spec_loss: 0.22351  (0.21964)\n",
            "     | > postnet_diff_spec_loss: 0.46626  (0.46612)\n",
            "     | > decoder_ssim_loss: 0.95080  (0.95253)\n",
            "     | > postnet_ssim_loss: 0.89849  (0.90617)\n",
            "     | > loss: 2.99740  (2.94399)\n",
            "     | > align_error: 0.98746  (0.98105)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.42369  (1.39667)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.42840  (1.02886)\n",
            "     | > loader_time: 0.01820  (0.01366)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_3000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 183/406 -- GLOBAL_STEP: 3025\u001b[0m\n",
            "     | > decoder_loss: 4.21707  (4.15910)\n",
            "     | > postnet_loss: 2.61460  (2.61317)\n",
            "     | > stopnet_loss: 0.58288  (0.58829)\n",
            "     | > ga_loss: 0.00349  (0.00566)\n",
            "     | > decoder_diff_spec_loss: 0.21963  (0.21962)\n",
            "     | > postnet_diff_spec_loss: 0.46522  (0.46578)\n",
            "     | > decoder_ssim_loss: 0.95135  (0.95221)\n",
            "     | > postnet_ssim_loss: 0.89781  (0.90490)\n",
            "     | > loss: 2.94178  (2.94526)\n",
            "     | > align_error: 0.98900  (0.98199)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.43182  (1.40059)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.46280  (1.07957)\n",
            "     | > loader_time: 0.01820  (0.01444)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 208/406 -- GLOBAL_STEP: 3050\u001b[0m\n",
            "     | > decoder_loss: 4.40265  (4.17524)\n",
            "     | > postnet_loss: 2.64343  (2.61597)\n",
            "     | > stopnet_loss: 0.58354  (0.58793)\n",
            "     | > ga_loss: 0.00327  (0.00539)\n",
            "     | > decoder_diff_spec_loss: 0.22491  (0.21965)\n",
            "     | > postnet_diff_spec_loss: 0.46507  (0.46543)\n",
            "     | > decoder_ssim_loss: 0.94645  (0.95186)\n",
            "     | > postnet_ssim_loss: 0.89535  (0.90379)\n",
            "     | > loss: 2.99435  (2.94785)\n",
            "     | > align_error: 0.98926  (0.98281)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.43966  (1.40461)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.58910  (1.12761)\n",
            "     | > loader_time: 0.02040  (0.01509)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 233/406 -- GLOBAL_STEP: 3075\u001b[0m\n",
            "     | > decoder_loss: 4.26660  (4.18814)\n",
            "     | > postnet_loss: 2.65442  (2.61891)\n",
            "     | > stopnet_loss: 0.58099  (0.58746)\n",
            "     | > ga_loss: 0.00320  (0.00516)\n",
            "     | > decoder_diff_spec_loss: 0.21697  (0.21969)\n",
            "     | > postnet_diff_spec_loss: 0.45935  (0.46526)\n",
            "     | > decoder_ssim_loss: 0.94802  (0.95157)\n",
            "     | > postnet_ssim_loss: 0.89478  (0.90287)\n",
            "     | > loss: 2.95701  (2.94985)\n",
            "     | > align_error: 0.99133  (0.98352)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.46612  (1.40842)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.81720  (1.17887)\n",
            "     | > loader_time: 0.02030  (0.01573)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 258/406 -- GLOBAL_STEP: 3100\u001b[0m\n",
            "     | > decoder_loss: 4.35158  (4.19832)\n",
            "     | > postnet_loss: 2.62746  (2.62104)\n",
            "     | > stopnet_loss: 0.58454  (0.58705)\n",
            "     | > ga_loss: 0.00305  (0.00495)\n",
            "     | > decoder_diff_spec_loss: 0.21959  (0.21970)\n",
            "     | > postnet_diff_spec_loss: 0.46143  (0.46506)\n",
            "     | > decoder_ssim_loss: 0.94824  (0.95125)\n",
            "     | > postnet_ssim_loss: 0.89275  (0.90207)\n",
            "     | > loss: 2.97506  (2.95118)\n",
            "     | > align_error: 0.99042  (0.98414)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.46842  (1.41206)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.76200  (1.22944)\n",
            "     | > loader_time: 0.02220  (0.01636)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 283/406 -- GLOBAL_STEP: 3125\u001b[0m\n",
            "     | > decoder_loss: 4.35312  (4.20657)\n",
            "     | > postnet_loss: 2.65574  (2.62337)\n",
            "     | > stopnet_loss: 0.58000  (0.58662)\n",
            "     | > ga_loss: 0.00285  (0.00477)\n",
            "     | > decoder_diff_spec_loss: 0.22019  (0.21970)\n",
            "     | > postnet_diff_spec_loss: 0.46257  (0.46488)\n",
            "     | > decoder_ssim_loss: 0.94557  (0.95094)\n",
            "     | > postnet_ssim_loss: 0.89341  (0.90137)\n",
            "     | > loss: 2.97691  (2.95220)\n",
            "     | > align_error: 0.99080  (0.98468)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.45522  (1.41498)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.79550  (1.27975)\n",
            "     | > loader_time: 0.03000  (0.01699)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 308/406 -- GLOBAL_STEP: 3150\u001b[0m\n",
            "     | > decoder_loss: 4.24723  (4.21417)\n",
            "     | > postnet_loss: 2.65042  (2.62530)\n",
            "     | > stopnet_loss: 0.58090  (0.58618)\n",
            "     | > ga_loss: 0.00270  (0.00461)\n",
            "     | > decoder_diff_spec_loss: 0.22170  (0.21968)\n",
            "     | > postnet_diff_spec_loss: 0.46638  (0.46469)\n",
            "     | > decoder_ssim_loss: 0.94717  (0.95062)\n",
            "     | > postnet_ssim_loss: 0.89466  (0.90072)\n",
            "     | > loss: 2.95129  (2.95304)\n",
            "     | > align_error: 0.99125  (0.98518)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.45682  (1.41813)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.86290  (1.32608)\n",
            "     | > loader_time: 0.02410  (0.01754)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 333/406 -- GLOBAL_STEP: 3175\u001b[0m\n",
            "     | > decoder_loss: 4.31947  (4.22021)\n",
            "     | > postnet_loss: 2.67853  (2.62642)\n",
            "     | > stopnet_loss: 0.58310  (0.58579)\n",
            "     | > ga_loss: 0.00268  (0.00447)\n",
            "     | > decoder_diff_spec_loss: 0.21822  (0.21974)\n",
            "     | > postnet_diff_spec_loss: 0.46154  (0.46459)\n",
            "     | > decoder_ssim_loss: 0.94721  (0.95032)\n",
            "     | > postnet_ssim_loss: 0.89329  (0.90011)\n",
            "     | > loss: 2.97608  (2.95347)\n",
            "     | > align_error: 0.99077  (0.98563)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.46107  (1.42130)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91970  (1.37291)\n",
            "     | > loader_time: 0.02460  (0.01810)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 358/406 -- GLOBAL_STEP: 3200\u001b[0m\n",
            "     | > decoder_loss: 4.46271  (4.22850)\n",
            "     | > postnet_loss: 2.65291  (2.62782)\n",
            "     | > stopnet_loss: 0.57889  (0.58538)\n",
            "     | > ga_loss: 0.00245  (0.00433)\n",
            "     | > decoder_diff_spec_loss: 0.21952  (0.21966)\n",
            "     | > postnet_diff_spec_loss: 0.46096  (0.46434)\n",
            "     | > decoder_ssim_loss: 0.94499  (0.95002)\n",
            "     | > postnet_ssim_loss: 0.88949  (0.89954)\n",
            "     | > loss: 2.99876  (2.95452)\n",
            "     | > align_error: 0.99180  (0.98604)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.48527  (1.42472)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.11490  (1.41725)\n",
            "     | > loader_time: 0.02590  (0.01867)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 383/406 -- GLOBAL_STEP: 3225\u001b[0m\n",
            "     | > decoder_loss: 4.36892  (4.23413)\n",
            "     | > postnet_loss: 2.65732  (2.62920)\n",
            "     | > stopnet_loss: 0.57727  (0.58494)\n",
            "     | > ga_loss: 0.00240  (0.00421)\n",
            "     | > decoder_diff_spec_loss: 0.21995  (0.21965)\n",
            "     | > postnet_diff_spec_loss: 0.46176  (0.46421)\n",
            "     | > decoder_ssim_loss: 0.94454  (0.94974)\n",
            "     | > postnet_ssim_loss: 0.89252  (0.89903)\n",
            "     | > loss: 2.97554  (2.95497)\n",
            "     | > align_error: 0.99201  (0.98642)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.47676  (1.42759)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.98910  (1.46052)\n",
            "     | > loader_time: 0.02750  (0.01924)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01322 \u001b[0m(+0.00212)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.22048 \u001b[0m(-0.04444)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.61169 \u001b[0m(-0.00389)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.55326 \u001b[0m(-0.01160)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00333 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.21558 \u001b[0m(+0.00039)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46475 \u001b[0m(-0.00009)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.91157 \u001b[0m(-0.00637)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.84872 \u001b[0m(-0.00690)\n",
            "     | > avg_loss:\u001b[92m 2.88811 \u001b[0m(-0.02696)\n",
            "     | > avg_align_error:\u001b[91m 0.98977 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_3248.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 8/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 08:01:51) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 2/406 -- GLOBAL_STEP: 3250\u001b[0m\n",
            "     | > decoder_loss: 4.23748  (4.07965)\n",
            "     | > postnet_loss: 2.71123  (2.67503)\n",
            "     | > stopnet_loss: 0.58046  (0.57933)\n",
            "     | > ga_loss: 0.01723  (0.01781)\n",
            "     | > decoder_diff_spec_loss: 0.20776  (0.21166)\n",
            "     | > postnet_diff_spec_loss: 0.45570  (0.46264)\n",
            "     | > decoder_ssim_loss: 0.94347  (0.93931)\n",
            "     | > postnet_ssim_loss: 0.89644  (0.89053)\n",
            "     | > loss: 3.02964  (2.98310)\n",
            "     | > align_error: 0.95171  (0.95016)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.42554  (1.40604)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.45080  (0.56234)\n",
            "     | > loader_time: 0.01740  (0.01127)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 27/406 -- GLOBAL_STEP: 3275\u001b[0m\n",
            "     | > decoder_loss: 3.91892  (3.94907)\n",
            "     | > postnet_loss: 2.54906  (2.60084)\n",
            "     | > stopnet_loss: 0.57823  (0.57615)\n",
            "     | > ga_loss: 0.00742  (0.01066)\n",
            "     | > decoder_diff_spec_loss: 0.22192  (0.21837)\n",
            "     | > postnet_diff_spec_loss: 0.47043  (0.46786)\n",
            "     | > decoder_ssim_loss: 0.94740  (0.94626)\n",
            "     | > postnet_ssim_loss: 0.91044  (0.90601)\n",
            "     | > loss: 2.86986  (2.90155)\n",
            "     | > align_error: 0.97555  (0.96759)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.43153  (1.42021)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.80460  (0.65419)\n",
            "     | > loader_time: 0.00990  (0.00865)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 52/406 -- GLOBAL_STEP: 3300\u001b[0m\n",
            "     | > decoder_loss: 4.08099  (3.97068)\n",
            "     | > postnet_loss: 2.56353  (2.59346)\n",
            "     | > stopnet_loss: 0.57464  (0.57646)\n",
            "     | > ga_loss: 0.00595  (0.00874)\n",
            "     | > decoder_diff_spec_loss: 0.22373  (0.21905)\n",
            "     | > postnet_diff_spec_loss: 0.46660  (0.46717)\n",
            "     | > decoder_ssim_loss: 0.94572  (0.94641)\n",
            "     | > postnet_ssim_loss: 0.90727  (0.90692)\n",
            "     | > loss: 2.90133  (2.89607)\n",
            "     | > align_error: 0.98221  (0.97303)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.48069  (1.43566)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.94440  (0.75250)\n",
            "     | > loader_time: 0.01190  (0.00985)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 77/406 -- GLOBAL_STEP: 3325\u001b[0m\n",
            "     | > decoder_loss: 4.07365  (4.01545)\n",
            "     | > postnet_loss: 2.58614  (2.59731)\n",
            "     | > stopnet_loss: 0.57637  (0.57615)\n",
            "     | > ga_loss: 0.00513  (0.00768)\n",
            "     | > decoder_diff_spec_loss: 0.22094  (0.21984)\n",
            "     | > postnet_diff_spec_loss: 0.46695  (0.46701)\n",
            "     | > decoder_ssim_loss: 0.94598  (0.94645)\n",
            "     | > postnet_ssim_loss: 0.90628  (0.90648)\n",
            "     | > loss: 2.90201  (2.90267)\n",
            "     | > align_error: 0.98302  (0.97601)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.47524  (1.44653)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.06680  (0.83483)\n",
            "     | > loader_time: 0.01360  (0.01088)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 102/406 -- GLOBAL_STEP: 3350\u001b[0m\n",
            "     | > decoder_loss: 4.24046  (4.04668)\n",
            "     | > postnet_loss: 2.64449  (2.60262)\n",
            "     | > stopnet_loss: 0.57571  (0.57568)\n",
            "     | > ga_loss: 0.00458  (0.00696)\n",
            "     | > decoder_diff_spec_loss: 0.22163  (0.22010)\n",
            "     | > postnet_diff_spec_loss: 0.46343  (0.46636)\n",
            "     | > decoder_ssim_loss: 0.94393  (0.94623)\n",
            "     | > postnet_ssim_loss: 0.89366  (0.90320)\n",
            "     | > loss: 2.95050  (2.90679)\n",
            "     | > align_error: 0.98483  (0.97815)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.48639  (1.45536)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.12610  (0.89515)\n",
            "     | > loader_time: 0.01520  (0.01188)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 127/406 -- GLOBAL_STEP: 3375\u001b[0m\n",
            "     | > decoder_loss: 4.23033  (4.07118)\n",
            "     | > postnet_loss: 2.65784  (2.60479)\n",
            "     | > stopnet_loss: 0.57452  (0.57520)\n",
            "     | > ga_loss: 0.00414  (0.00643)\n",
            "     | > decoder_diff_spec_loss: 0.22465  (0.22044)\n",
            "     | > postnet_diff_spec_loss: 0.46783  (0.46631)\n",
            "     | > decoder_ssim_loss: 0.94258  (0.94592)\n",
            "     | > postnet_ssim_loss: 0.89214  (0.90104)\n",
            "     | > loss: 2.94907  (2.90978)\n",
            "     | > align_error: 0.98589  (0.97972)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.48869  (1.46288)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.17230  (0.95217)\n",
            "     | > loader_time: 0.01620  (0.01278)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 152/406 -- GLOBAL_STEP: 3400\u001b[0m\n",
            "     | > decoder_loss: 4.15573  (4.09515)\n",
            "     | > postnet_loss: 2.55885  (2.60674)\n",
            "     | > stopnet_loss: 0.57004  (0.57480)\n",
            "     | > ga_loss: 0.00380  (0.00603)\n",
            "     | > decoder_diff_spec_loss: 0.21855  (0.22058)\n",
            "     | > postnet_diff_spec_loss: 0.46164  (0.46606)\n",
            "     | > decoder_ssim_loss: 0.94388  (0.94560)\n",
            "     | > postnet_ssim_loss: 0.88980  (0.89941)\n",
            "     | > loss: 2.89616  (2.91333)\n",
            "     | > align_error: 0.98758  (0.98088)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.49640  (1.46862)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.33380  (1.00831)\n",
            "     | > loader_time: 0.02200  (0.01355)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 177/406 -- GLOBAL_STEP: 3425\u001b[0m\n",
            "     | > decoder_loss: 4.33890  (4.10812)\n",
            "     | > postnet_loss: 2.64714  (2.60905)\n",
            "     | > stopnet_loss: 0.56764  (0.57421)\n",
            "     | > ga_loss: 0.00362  (0.00570)\n",
            "     | > decoder_diff_spec_loss: 0.21795  (0.22063)\n",
            "     | > postnet_diff_spec_loss: 0.45896  (0.46578)\n",
            "     | > decoder_ssim_loss: 0.94479  (0.94526)\n",
            "     | > postnet_ssim_loss: 0.88952  (0.89817)\n",
            "     | > loss: 2.96004  (2.91446)\n",
            "     | > align_error: 0.98874  (0.98185)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.53786  (1.47363)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.51850  (1.06422)\n",
            "     | > loader_time: 0.01890  (0.01424)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 202/406 -- GLOBAL_STEP: 3450\u001b[0m\n",
            "     | > decoder_loss: 4.32769  (4.12165)\n",
            "     | > postnet_loss: 2.59415  (2.61155)\n",
            "     | > stopnet_loss: 0.57130  (0.57359)\n",
            "     | > ga_loss: 0.00335  (0.00542)\n",
            "     | > decoder_diff_spec_loss: 0.22240  (0.22065)\n",
            "     | > postnet_diff_spec_loss: 0.46294  (0.46540)\n",
            "     | > decoder_ssim_loss: 0.94198  (0.94490)\n",
            "     | > postnet_ssim_loss: 0.88996  (0.89709)\n",
            "     | > loss: 2.94781  (2.91602)\n",
            "     | > align_error: 0.98931  (0.98270)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.54026  (1.47878)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.56890  (1.11330)\n",
            "     | > loader_time: 0.01980  (0.01488)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 227/406 -- GLOBAL_STEP: 3475\u001b[0m\n",
            "     | > decoder_loss: 4.09251  (4.13558)\n",
            "     | > postnet_loss: 2.60628  (2.61395)\n",
            "     | > stopnet_loss: 0.56437  (0.57309)\n",
            "     | > ga_loss: 0.00314  (0.00518)\n",
            "     | > decoder_diff_spec_loss: 0.21993  (0.22072)\n",
            "     | > postnet_diff_spec_loss: 0.46284  (0.46523)\n",
            "     | > decoder_ssim_loss: 0.94338  (0.94458)\n",
            "     | > postnet_ssim_loss: 0.88792  (0.89619)\n",
            "     | > loss: 2.88330  (2.91807)\n",
            "     | > align_error: 0.98977  (0.98341)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.51746  (1.48405)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.73770  (1.16185)\n",
            "     | > loader_time: 0.02130  (0.01550)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 252/406 -- GLOBAL_STEP: 3500\u001b[0m\n",
            "     | > decoder_loss: 4.23261  (4.14638)\n",
            "     | > postnet_loss: 2.61837  (2.61686)\n",
            "     | > stopnet_loss: 0.56720  (0.57250)\n",
            "     | > ga_loss: 0.00307  (0.00498)\n",
            "     | > decoder_diff_spec_loss: 0.21707  (0.22075)\n",
            "     | > postnet_diff_spec_loss: 0.45834  (0.46501)\n",
            "     | > decoder_ssim_loss: 0.94018  (0.94422)\n",
            "     | > postnet_ssim_loss: 0.88766  (0.89542)\n",
            "     | > loss: 2.92112  (2.91955)\n",
            "     | > align_error: 0.99001  (0.98405)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.54369  (1.48920)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.79670  (1.21202)\n",
            "     | > loader_time: 0.02160  (0.01608)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 277/406 -- GLOBAL_STEP: 3525\u001b[0m\n",
            "     | > decoder_loss: 4.21835  (4.15412)\n",
            "     | > postnet_loss: 2.66086  (2.61885)\n",
            "     | > stopnet_loss: 0.56632  (0.57184)\n",
            "     | > ga_loss: 0.00286  (0.00479)\n",
            "     | > decoder_diff_spec_loss: 0.22239  (0.22077)\n",
            "     | > postnet_diff_spec_loss: 0.46223  (0.46480)\n",
            "     | > decoder_ssim_loss: 0.94070  (0.94386)\n",
            "     | > postnet_ssim_loss: 0.88799  (0.89472)\n",
            "     | > loss: 2.92873  (2.92009)\n",
            "     | > align_error: 0.99012  (0.98463)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.52062  (1.49366)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.84710  (1.25880)\n",
            "     | > loader_time: 0.02240  (0.01666)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 302/406 -- GLOBAL_STEP: 3550\u001b[0m\n",
            "     | > decoder_loss: 4.26845  (4.16178)\n",
            "     | > postnet_loss: 2.66268  (2.62075)\n",
            "     | > stopnet_loss: 0.56353  (0.57125)\n",
            "     | > ga_loss: 0.00276  (0.00463)\n",
            "     | > decoder_diff_spec_loss: 0.22301  (0.22078)\n",
            "     | > postnet_diff_spec_loss: 0.46615  (0.46462)\n",
            "     | > decoder_ssim_loss: 0.94021  (0.94352)\n",
            "     | > postnet_ssim_loss: 0.88642  (0.89410)\n",
            "     | > loss: 2.93907  (2.92079)\n",
            "     | > align_error: 0.99086  (0.98513)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.55637  (1.49823)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.99450  (1.30869)\n",
            "     | > loader_time: 0.02440  (0.01725)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 327/406 -- GLOBAL_STEP: 3575\u001b[0m\n",
            "     | > decoder_loss: 4.34465  (4.16724)\n",
            "     | > postnet_loss: 2.68038  (2.62168)\n",
            "     | > stopnet_loss: 0.56529  (0.57073)\n",
            "     | > ga_loss: 0.00262  (0.00448)\n",
            "     | > decoder_diff_spec_loss: 0.22144  (0.22087)\n",
            "     | > postnet_diff_spec_loss: 0.46183  (0.46455)\n",
            "     | > decoder_ssim_loss: 0.93885  (0.94315)\n",
            "     | > postnet_ssim_loss: 0.88780  (0.89356)\n",
            "     | > loss: 2.96211  (2.92090)\n",
            "     | > align_error: 0.99143  (0.98559)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.57953  (1.50263)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.05820  (1.35319)\n",
            "     | > loader_time: 0.02460  (0.01780)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 352/406 -- GLOBAL_STEP: 3600\u001b[0m\n",
            "     | > decoder_loss: 4.11410  (4.17418)\n",
            "     | > postnet_loss: 2.60384  (2.62325)\n",
            "     | > stopnet_loss: 0.56279  (0.57016)\n",
            "     | > ga_loss: 0.00250  (0.00435)\n",
            "     | > decoder_diff_spec_loss: 0.22307  (0.22084)\n",
            "     | > postnet_diff_spec_loss: 0.46533  (0.46433)\n",
            "     | > decoder_ssim_loss: 0.93681  (0.94282)\n",
            "     | > postnet_ssim_loss: 0.88717  (0.89300)\n",
            "     | > loss: 2.88286  (2.92149)\n",
            "     | > align_error: 0.99160  (0.98600)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.54830  (1.50727)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.86280  (1.40119)\n",
            "     | > loader_time: 0.02680  (0.01840)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 377/406 -- GLOBAL_STEP: 3625\u001b[0m\n",
            "     | > decoder_loss: 4.31657  (4.18094)\n",
            "     | > postnet_loss: 2.61575  (2.62464)\n",
            "     | > stopnet_loss: 0.55931  (0.56961)\n",
            "     | > ga_loss: 0.00244  (0.00422)\n",
            "     | > decoder_diff_spec_loss: 0.22088  (0.22082)\n",
            "     | > postnet_diff_spec_loss: 0.45986  (0.46414)\n",
            "     | > decoder_ssim_loss: 0.93558  (0.94249)\n",
            "     | > postnet_ssim_loss: 0.88466  (0.89251)\n",
            "     | > loss: 2.92982  (2.92209)\n",
            "     | > align_error: 0.99205  (0.98639)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.57994  (1.51157)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.94450  (1.44195)\n",
            "     | > loader_time: 0.02790  (0.01899)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 402/406 -- GLOBAL_STEP: 3650\u001b[0m\n",
            "     | > decoder_loss: 4.27879  (4.18746)\n",
            "     | > postnet_loss: 2.67904  (2.62596)\n",
            "     | > stopnet_loss: 0.55844  (0.56900)\n",
            "     | > ga_loss: 0.00229  (0.00410)\n",
            "     | > decoder_diff_spec_loss: 0.21984  (0.22084)\n",
            "     | > postnet_diff_spec_loss: 0.46082  (0.46400)\n",
            "     | > decoder_ssim_loss: 0.93654  (0.94219)\n",
            "     | > postnet_ssim_loss: 0.88361  (0.89206)\n",
            "     | > loss: 2.93453  (2.92264)\n",
            "     | > align_error: 0.99236  (0.98675)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.57204  (1.51579)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.88080  (1.48278)\n",
            "     | > loader_time: 0.02850  (0.01961)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01412 \u001b[0m(+0.00089)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.16590 \u001b[0m(-0.05458)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.60620 \u001b[0m(-0.00549)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.53785 \u001b[0m(-0.01541)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00332 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.21680 \u001b[0m(+0.00122)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46468 \u001b[0m(-0.00006)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.90211 \u001b[0m(-0.00946)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.84203 \u001b[0m(-0.00669)\n",
            "     | > avg_loss:\u001b[92m 2.85390 \u001b[0m(-0.03421)\n",
            "     | > avg_align_error:\u001b[91m 0.98978 \u001b[0m(+0.00001)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_3654.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 9/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 08:22:51) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 21/406 -- GLOBAL_STEP: 3675\u001b[0m\n",
            "     | > decoder_loss: 4.04384  (3.88267)\n",
            "     | > postnet_loss: 2.59701  (2.59705)\n",
            "     | > stopnet_loss: 0.55890  (0.55988)\n",
            "     | > ga_loss: 0.00805  (0.01137)\n",
            "     | > decoder_diff_spec_loss: 0.22189  (0.21922)\n",
            "     | > postnet_diff_spec_loss: 0.46424  (0.46763)\n",
            "     | > decoder_ssim_loss: 0.93785  (0.93808)\n",
            "     | > postnet_ssim_loss: 0.90348  (0.89779)\n",
            "     | > loss: 2.89123  (2.86733)\n",
            "     | > align_error: 0.97509  (0.96560)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.57695  (1.52622)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.70690  (0.62557)\n",
            "     | > loader_time: 0.00950  (0.00865)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 46/406 -- GLOBAL_STEP: 3700\u001b[0m\n",
            "     | > decoder_loss: 4.09679  (3.89948)\n",
            "     | > postnet_loss: 2.57692  (2.58668)\n",
            "     | > stopnet_loss: 0.55694  (0.55914)\n",
            "     | > ga_loss: 0.00627  (0.00900)\n",
            "     | > decoder_diff_spec_loss: 0.22085  (0.22079)\n",
            "     | > postnet_diff_spec_loss: 0.46499  (0.46752)\n",
            "     | > decoder_ssim_loss: 0.93846  (0.93822)\n",
            "     | > postnet_ssim_loss: 0.89824  (0.89989)\n",
            "     | > loss: 2.88736  (2.85731)\n",
            "     | > align_error: 0.97959  (0.97219)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.57672  (1.54427)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.90070  (0.72372)\n",
            "     | > loader_time: 0.01200  (0.00992)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 71/406 -- GLOBAL_STEP: 3725\u001b[0m\n",
            "     | > decoder_loss: 4.06660  (3.94797)\n",
            "     | > postnet_loss: 2.61900  (2.59145)\n",
            "     | > stopnet_loss: 0.55238  (0.55813)\n",
            "     | > ga_loss: 0.00526  (0.00784)\n",
            "     | > decoder_diff_spec_loss: 0.22631  (0.22132)\n",
            "     | > postnet_diff_spec_loss: 0.47105  (0.46695)\n",
            "     | > decoder_ssim_loss: 0.93979  (0.93833)\n",
            "     | > postnet_ssim_loss: 0.89831  (0.89970)\n",
            "     | > loss: 2.88395  (2.86374)\n",
            "     | > align_error: 0.98348  (0.97551)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.59642  (1.55628)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.01000  (0.80464)\n",
            "     | > loader_time: 0.01330  (0.01104)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 96/406 -- GLOBAL_STEP: 3750\u001b[0m\n",
            "     | > decoder_loss: 4.09712  (3.98334)\n",
            "     | > postnet_loss: 2.64044  (2.59745)\n",
            "     | > stopnet_loss: 0.55178  (0.55721)\n",
            "     | > ga_loss: 0.00469  (0.00707)\n",
            "     | > decoder_diff_spec_loss: 0.22287  (0.22169)\n",
            "     | > postnet_diff_spec_loss: 0.46525  (0.46636)\n",
            "     | > decoder_ssim_loss: 0.93585  (0.93826)\n",
            "     | > postnet_ssim_loss: 0.88467  (0.89703)\n",
            "     | > loss: 2.88675  (2.86856)\n",
            "     | > align_error: 0.98537  (0.97779)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.60306  (1.56708)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.13110  (0.87434)\n",
            "     | > loader_time: 0.01530  (0.01216)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 121/406 -- GLOBAL_STEP: 3775\u001b[0m\n",
            "     | > decoder_loss: 4.12271  (4.00687)\n",
            "     | > postnet_loss: 2.57459  (2.59942)\n",
            "     | > stopnet_loss: 0.55159  (0.55648)\n",
            "     | > ga_loss: 0.00423  (0.00651)\n",
            "     | > decoder_diff_spec_loss: 0.22191  (0.22199)\n",
            "     | > postnet_diff_spec_loss: 0.46424  (0.46619)\n",
            "     | > decoder_ssim_loss: 0.93647  (0.93797)\n",
            "     | > postnet_ssim_loss: 0.88671  (0.89481)\n",
            "     | > loss: 2.87440  (2.87082)\n",
            "     | > align_error: 0.98665  (0.97946)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.62811  (1.57587)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.26490  (0.93530)\n",
            "     | > loader_time: 0.01590  (0.01292)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 146/406 -- GLOBAL_STEP: 3800\u001b[0m\n",
            "     | > decoder_loss: 4.04856  (4.03127)\n",
            "     | > postnet_loss: 2.57865  (2.60166)\n",
            "     | > stopnet_loss: 0.55211  (0.55575)\n",
            "     | > ga_loss: 0.00384  (0.00608)\n",
            "     | > decoder_diff_spec_loss: 0.22788  (0.22219)\n",
            "     | > postnet_diff_spec_loss: 0.46984  (0.46594)\n",
            "     | > decoder_ssim_loss: 0.93494  (0.93763)\n",
            "     | > postnet_ssim_loss: 0.88640  (0.89314)\n",
            "     | > loss: 2.85788  (2.87412)\n",
            "     | > align_error: 0.98724  (0.98069)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.61121  (1.58283)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.26550  (0.99352)\n",
            "     | > loader_time: 0.01680  (0.01365)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 171/406 -- GLOBAL_STEP: 3825\u001b[0m\n",
            "     | > decoder_loss: 4.02812  (4.04414)\n",
            "     | > postnet_loss: 2.61976  (2.60357)\n",
            "     | > stopnet_loss: 0.55026  (0.55506)\n",
            "     | > ga_loss: 0.00355  (0.00574)\n",
            "     | > decoder_diff_spec_loss: 0.22900  (0.22236)\n",
            "     | > postnet_diff_spec_loss: 0.47097  (0.46576)\n",
            "     | > decoder_ssim_loss: 0.93283  (0.93729)\n",
            "     | > postnet_ssim_loss: 0.88467  (0.89188)\n",
            "     | > loss: 2.85935  (2.87501)\n",
            "     | > align_error: 0.98800  (0.98169)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.60954  (1.58876)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.34690  (1.04568)\n",
            "     | > loader_time: 0.01830  (0.01434)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 196/406 -- GLOBAL_STEP: 3850\u001b[0m\n",
            "     | > decoder_loss: 4.18938  (4.05789)\n",
            "     | > postnet_loss: 2.61736  (2.60604)\n",
            "     | > stopnet_loss: 0.54617  (0.55423)\n",
            "     | > ga_loss: 0.00339  (0.00546)\n",
            "     | > decoder_diff_spec_loss: 0.22422  (0.22235)\n",
            "     | > postnet_diff_spec_loss: 0.46196  (0.46535)\n",
            "     | > decoder_ssim_loss: 0.93390  (0.93688)\n",
            "     | > postnet_ssim_loss: 0.88412  (0.89082)\n",
            "     | > loss: 2.89084  (2.87634)\n",
            "     | > align_error: 0.98981  (0.98257)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.68137  (1.59597)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.53680  (1.09683)\n",
            "     | > loader_time: 0.01920  (0.01497)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 221/406 -- GLOBAL_STEP: 3875\u001b[0m\n",
            "     | > decoder_loss: 4.15155  (4.07198)\n",
            "     | > postnet_loss: 2.58675  (2.60848)\n",
            "     | > stopnet_loss: 0.54937  (0.55352)\n",
            "     | > ga_loss: 0.00322  (0.00521)\n",
            "     | > decoder_diff_spec_loss: 0.22166  (0.22243)\n",
            "     | > postnet_diff_spec_loss: 0.46444  (0.46512)\n",
            "     | > decoder_ssim_loss: 0.93485  (0.93655)\n",
            "     | > postnet_ssim_loss: 0.88302  (0.88992)\n",
            "     | > loss: 2.87605  (2.87819)\n",
            "     | > align_error: 0.98873  (0.98332)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.63952  (1.60254)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.52540  (1.14431)\n",
            "     | > loader_time: 0.02050  (0.01565)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 246/406 -- GLOBAL_STEP: 3900\u001b[0m\n",
            "     | > decoder_loss: 4.10288  (4.08330)\n",
            "     | > postnet_loss: 2.58771  (2.61136)\n",
            "     | > stopnet_loss: 0.54694  (0.55274)\n",
            "     | > ga_loss: 0.00299  (0.00500)\n",
            "     | > decoder_diff_spec_loss: 0.22422  (0.22252)\n",
            "     | > postnet_diff_spec_loss: 0.46417  (0.46493)\n",
            "     | > decoder_ssim_loss: 0.93311  (0.93624)\n",
            "     | > postnet_ssim_loss: 0.88284  (0.88917)\n",
            "     | > loss: 2.86062  (2.87962)\n",
            "     | > align_error: 0.98971  (0.98397)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.64501  (1.60893)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.83520  (1.19488)\n",
            "     | > loader_time: 0.02160  (0.01626)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 271/406 -- GLOBAL_STEP: 3925\u001b[0m\n",
            "     | > decoder_loss: 4.24313  (4.08950)\n",
            "     | > postnet_loss: 2.65738  (2.61285)\n",
            "     | > stopnet_loss: 0.54351  (0.55192)\n",
            "     | > ga_loss: 0.00294  (0.00481)\n",
            "     | > decoder_diff_spec_loss: 0.22041  (0.22255)\n",
            "     | > postnet_diff_spec_loss: 0.45915  (0.46471)\n",
            "     | > decoder_ssim_loss: 0.93116  (0.93586)\n",
            "     | > postnet_ssim_loss: 0.88048  (0.88849)\n",
            "     | > loss: 2.90614  (2.87946)\n",
            "     | > align_error: 0.99038  (0.98456)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.68441  (1.61502)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.86530  (1.24389)\n",
            "     | > loader_time: 0.02300  (0.01682)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 296/406 -- GLOBAL_STEP: 3950\u001b[0m\n",
            "     | > decoder_loss: 4.17875  (4.09695)\n",
            "     | > postnet_loss: 2.66545  (2.61485)\n",
            "     | > stopnet_loss: 0.53931  (0.55117)\n",
            "     | > ga_loss: 0.00282  (0.00464)\n",
            "     | > decoder_diff_spec_loss: 0.22300  (0.22260)\n",
            "     | > postnet_diff_spec_loss: 0.46273  (0.46456)\n",
            "     | > decoder_ssim_loss: 0.93009  (0.93546)\n",
            "     | > postnet_ssim_loss: 0.88051  (0.88791)\n",
            "     | > loss: 2.88854  (2.87997)\n",
            "     | > align_error: 0.99136  (0.98507)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.71672  (1.62084)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.93420  (1.29274)\n",
            "     | > loader_time: 0.03020  (0.01745)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 321/406 -- GLOBAL_STEP: 3975\u001b[0m\n",
            "     | > decoder_loss: 4.10418  (4.10191)\n",
            "     | > postnet_loss: 2.59373  (2.61585)\n",
            "     | > stopnet_loss: 0.54355  (0.55039)\n",
            "     | > ga_loss: 0.00261  (0.00449)\n",
            "     | > decoder_diff_spec_loss: 0.22378  (0.22269)\n",
            "     | > postnet_diff_spec_loss: 0.46240  (0.46445)\n",
            "     | > decoder_ssim_loss: 0.93143  (0.93514)\n",
            "     | > postnet_ssim_loss: 0.88028  (0.88738)\n",
            "     | > loss: 2.85557  (2.87970)\n",
            "     | > align_error: 0.99110  (0.98554)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.68851  (1.62659)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.92410  (1.33878)\n",
            "     | > loader_time: 0.02450  (0.01798)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 346/406 -- GLOBAL_STEP: 4000\u001b[0m\n",
            "     | > decoder_loss: 4.10760  (4.10846)\n",
            "     | > postnet_loss: 2.59819  (2.61746)\n",
            "     | > stopnet_loss: 0.53671  (0.54958)\n",
            "     | > ga_loss: 0.00250  (0.00435)\n",
            "     | > decoder_diff_spec_loss: 0.22257  (0.22272)\n",
            "     | > postnet_diff_spec_loss: 0.46154  (0.46425)\n",
            "     | > decoder_ssim_loss: 0.92938  (0.93480)\n",
            "     | > postnet_ssim_loss: 0.87865  (0.88685)\n",
            "     | > loss: 2.84871  (2.87999)\n",
            "     | > align_error: 0.99262  (0.98596)\n",
            "     | > amp_scaler: 131072.00000  (131450.82081)\n",
            "     | > grad_norm: 0.00000  (1.62716)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.01320  (1.38581)\n",
            "     | > loader_time: 0.02530  (0.01857)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_4000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 371/406 -- GLOBAL_STEP: 4025\u001b[0m\n",
            "     | > decoder_loss: 4.17421  (4.11517)\n",
            "     | > postnet_loss: 2.65204  (2.61908)\n",
            "     | > stopnet_loss: 0.53963  (0.54879)\n",
            "     | > ga_loss: 0.00242  (0.00423)\n",
            "     | > decoder_diff_spec_loss: 0.21979  (0.22273)\n",
            "     | > postnet_diff_spec_loss: 0.45904  (0.46406)\n",
            "     | > decoder_ssim_loss: 0.93041  (0.93451)\n",
            "     | > postnet_ssim_loss: 0.87801  (0.88637)\n",
            "     | > loss: 2.88010  (2.88041)\n",
            "     | > align_error: 0.99183  (0.98636)\n",
            "     | > amp_scaler: 131072.00000  (131425.29380)\n",
            "     | > grad_norm: 1.71285  (1.63312)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.06450  (1.43144)\n",
            "     | > loader_time: 0.02690  (0.01921)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 396/406 -- GLOBAL_STEP: 4050\u001b[0m\n",
            "     | > decoder_loss: 4.30801  (4.12040)\n",
            "     | > postnet_loss: 2.68630  (2.62004)\n",
            "     | > stopnet_loss: 0.53477  (0.54799)\n",
            "     | > ga_loss: 0.00233  (0.00411)\n",
            "     | > decoder_diff_spec_loss: 0.22344  (0.22276)\n",
            "     | > postnet_diff_spec_loss: 0.45831  (0.46391)\n",
            "     | > decoder_ssim_loss: 0.92987  (0.93418)\n",
            "     | > postnet_ssim_loss: 0.87865  (0.88595)\n",
            "     | > loss: 2.91756  (2.88034)\n",
            "     | > align_error: 0.99258  (0.98673)\n",
            "     | > amp_scaler: 131072.00000  (131402.98990)\n",
            "     | > grad_norm: 1.76111  (1.63875)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.18770  (1.47662)\n",
            "     | > loader_time: 0.02750  (0.01975)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01546 \u001b[0m(+0.00135)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.09293 \u001b[0m(-0.07298)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.59938 \u001b[0m(-0.00682)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.51236 \u001b[0m(-0.02549)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00331 \u001b[0m(-0.00002)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.21862 \u001b[0m(+0.00182)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46456 \u001b[0m(-0.00013)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.89215 \u001b[0m(-0.00996)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.83562 \u001b[0m(-0.00642)\n",
            "     | > avg_loss:\u001b[92m 2.80472 \u001b[0m(-0.04918)\n",
            "     | > avg_align_error:\u001b[91m 0.98978 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_4060.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 10/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 08:43:58) \u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 15/406 -- GLOBAL_STEP: 4075\u001b[0m\n",
            "     | > decoder_loss: 3.85402  (3.82193)\n",
            "     | > postnet_loss: 2.56995  (2.59820)\n",
            "     | > stopnet_loss: 0.53905  (0.53632)\n",
            "     | > ga_loss: 0.00932  (0.01241)\n",
            "     | > decoder_diff_spec_loss: 0.22476  (0.21985)\n",
            "     | > postnet_diff_spec_loss: 0.46976  (0.46607)\n",
            "     | > decoder_ssim_loss: 0.92854  (0.92830)\n",
            "     | > postnet_ssim_loss: 0.89391  (0.89160)\n",
            "     | > loss: 2.82087  (2.82986)\n",
            "     | > align_error: 0.96933  (0.96277)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.67137  (1.66612)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.63110  (0.58877)\n",
            "     | > loader_time: 0.00950  (0.00918)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 40/406 -- GLOBAL_STEP: 4100\u001b[0m\n",
            "     | > decoder_loss: 3.74182  (3.82599)\n",
            "     | > postnet_loss: 2.54715  (2.58370)\n",
            "     | > stopnet_loss: 0.53280  (0.53451)\n",
            "     | > ga_loss: 0.00632  (0.00935)\n",
            "     | > decoder_diff_spec_loss: 0.22257  (0.22285)\n",
            "     | > postnet_diff_spec_loss: 0.46538  (0.46743)\n",
            "     | > decoder_ssim_loss: 0.92661  (0.92985)\n",
            "     | > postnet_ssim_loss: 0.89478  (0.89522)\n",
            "     | > loss: 2.76395  (2.81254)\n",
            "     | > align_error: 0.97982  (0.97112)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.69616  (1.69056)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.83940  (0.69945)\n",
            "     | > loader_time: 0.01070  (0.00984)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 65/406 -- GLOBAL_STEP: 4125\u001b[0m\n",
            "     | > decoder_loss: 4.06756  (3.86481)\n",
            "     | > postnet_loss: 2.60151  (2.58273)\n",
            "     | > stopnet_loss: 0.52748  (0.53324)\n",
            "     | > ga_loss: 0.00547  (0.00802)\n",
            "     | > decoder_diff_spec_loss: 0.22187  (0.22357)\n",
            "     | > postnet_diff_spec_loss: 0.46077  (0.46695)\n",
            "     | > decoder_ssim_loss: 0.93320  (0.92997)\n",
            "     | > postnet_ssim_loss: 0.89498  (0.89501)\n",
            "     | > loss: 2.84982  (2.81408)\n",
            "     | > align_error: 0.98229  (0.97497)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.74915  (1.70645)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.94840  (0.78159)\n",
            "     | > loader_time: 0.01330  (0.01072)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 90/406 -- GLOBAL_STEP: 4150\u001b[0m\n",
            "     | > decoder_loss: 3.98873  (3.90161)\n",
            "     | > postnet_loss: 2.57599  (2.58808)\n",
            "     | > stopnet_loss: 0.52842  (0.53215)\n",
            "     | > ga_loss: 0.00472  (0.00718)\n",
            "     | > decoder_diff_spec_loss: 0.22912  (0.22410)\n",
            "     | > postnet_diff_spec_loss: 0.46882  (0.46643)\n",
            "     | > decoder_ssim_loss: 0.92968  (0.93004)\n",
            "     | > postnet_ssim_loss: 0.88053  (0.89276)\n",
            "     | > loss: 2.82022  (2.81882)\n",
            "     | > align_error: 0.98521  (0.97739)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.78097  (1.71887)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.09830  (0.85274)\n",
            "     | > loader_time: 0.01440  (0.01155)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 115/406 -- GLOBAL_STEP: 4175\u001b[0m\n",
            "     | > decoder_loss: 3.91824  (3.92782)\n",
            "     | > postnet_loss: 2.60376  (2.59309)\n",
            "     | > stopnet_loss: 0.52865  (0.53087)\n",
            "     | > ga_loss: 0.00428  (0.00659)\n",
            "     | > decoder_diff_spec_loss: 0.22486  (0.22445)\n",
            "     | > postnet_diff_spec_loss: 0.46326  (0.46612)\n",
            "     | > decoder_ssim_loss: 0.92862  (0.92978)\n",
            "     | > postnet_ssim_loss: 0.87893  (0.89000)\n",
            "     | > loss: 2.80448  (2.82161)\n",
            "     | > align_error: 0.98612  (0.97919)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.76648  (1.72896)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.27180  (0.92291)\n",
            "     | > loader_time: 0.01590  (0.01240)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 140/406 -- GLOBAL_STEP: 4200\u001b[0m\n",
            "     | > decoder_loss: 4.12307  (3.95447)\n",
            "     | > postnet_loss: 2.58528  (2.59540)\n",
            "     | > stopnet_loss: 0.52761  (0.52989)\n",
            "     | > ga_loss: 0.00391  (0.00614)\n",
            "     | > decoder_diff_spec_loss: 0.22286  (0.22458)\n",
            "     | > postnet_diff_spec_loss: 0.46187  (0.46571)\n",
            "     | > decoder_ssim_loss: 0.92641  (0.92948)\n",
            "     | > postnet_ssim_loss: 0.87751  (0.88800)\n",
            "     | > loss: 2.84641  (2.82499)\n",
            "     | > align_error: 0.98652  (0.98049)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.77188  (1.73792)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.21600  (0.98243)\n",
            "     | > loader_time: 0.01650  (0.01318)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 165/406 -- GLOBAL_STEP: 4225\u001b[0m\n",
            "     | > decoder_loss: 4.04800  (3.96720)\n",
            "     | > postnet_loss: 2.66121  (2.59669)\n",
            "     | > stopnet_loss: 0.52462  (0.52902)\n",
            "     | > ga_loss: 0.00367  (0.00578)\n",
            "     | > decoder_diff_spec_loss: 0.22553  (0.22481)\n",
            "     | > postnet_diff_spec_loss: 0.46303  (0.46561)\n",
            "     | > decoder_ssim_loss: 0.92620  (0.92919)\n",
            "     | > postnet_ssim_loss: 0.87723  (0.88658)\n",
            "     | > loss: 2.84327  (2.82544)\n",
            "     | > align_error: 0.98778  (0.98154)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.78440  (1.74464)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.39470  (1.03335)\n",
            "     | > loader_time: 0.02320  (0.01392)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 190/406 -- GLOBAL_STEP: 4250\u001b[0m\n",
            "     | > decoder_loss: 4.15268  (3.98016)\n",
            "     | > postnet_loss: 2.63707  (2.59932)\n",
            "     | > stopnet_loss: 0.51886  (0.52797)\n",
            "     | > ga_loss: 0.00348  (0.00549)\n",
            "     | > decoder_diff_spec_loss: 0.22292  (0.22488)\n",
            "     | > postnet_diff_spec_loss: 0.45875  (0.46525)\n",
            "     | > decoder_ssim_loss: 0.92671  (0.92884)\n",
            "     | > postnet_ssim_loss: 0.87700  (0.88543)\n",
            "     | > loss: 2.85506  (2.82638)\n",
            "     | > align_error: 0.98859  (0.98244)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.82312  (1.75271)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.49760  (1.08283)\n",
            "     | > loader_time: 0.01940  (0.01460)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 215/406 -- GLOBAL_STEP: 4275\u001b[0m\n",
            "     | > decoder_loss: 4.09002  (3.99220)\n",
            "     | > postnet_loss: 2.64499  (2.60146)\n",
            "     | > stopnet_loss: 0.51818  (0.52693)\n",
            "     | > ga_loss: 0.00321  (0.00523)\n",
            "     | > decoder_diff_spec_loss: 0.22440  (0.22504)\n",
            "     | > postnet_diff_spec_loss: 0.46133  (0.46498)\n",
            "     | > decoder_ssim_loss: 0.92773  (0.92857)\n",
            "     | > postnet_ssim_loss: 0.87724  (0.88448)\n",
            "     | > loss: 2.84068  (2.82729)\n",
            "     | > align_error: 0.98891  (0.98322)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.79750  (1.76067)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.52640  (1.12962)\n",
            "     | > loader_time: 0.02000  (0.01519)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 240/406 -- GLOBAL_STEP: 4300\u001b[0m\n",
            "     | > decoder_loss: 4.12016  (4.00341)\n",
            "     | > postnet_loss: 2.67329  (2.60444)\n",
            "     | > stopnet_loss: 0.51627  (0.52584)\n",
            "     | > ga_loss: 0.00303  (0.00502)\n",
            "     | > decoder_diff_spec_loss: 0.22467  (0.22513)\n",
            "     | > postnet_diff_spec_loss: 0.46050  (0.46478)\n",
            "     | > decoder_ssim_loss: 0.92452  (0.92829)\n",
            "     | > postnet_ssim_loss: 0.87669  (0.88369)\n",
            "     | > loss: 2.85139  (2.82836)\n",
            "     | > align_error: 0.99004  (0.98389)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.83737  (1.76813)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.66210  (1.17973)\n",
            "     | > loader_time: 0.02120  (0.01577)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 265/406 -- GLOBAL_STEP: 4325\u001b[0m\n",
            "     | > decoder_loss: 4.10991  (4.00993)\n",
            "     | > postnet_loss: 2.61971  (2.60559)\n",
            "     | > stopnet_loss: 0.51587  (0.52479)\n",
            "     | > ga_loss: 0.00294  (0.00483)\n",
            "     | > decoder_diff_spec_loss: 0.22723  (0.22523)\n",
            "     | > postnet_diff_spec_loss: 0.46253  (0.46462)\n",
            "     | > decoder_ssim_loss: 0.92354  (0.92796)\n",
            "     | > postnet_ssim_loss: 0.87503  (0.88299)\n",
            "     | > loss: 2.83507  (2.82800)\n",
            "     | > align_error: 0.99052  (0.98449)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.86616  (1.77545)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.77710  (1.23154)\n",
            "     | > loader_time: 0.02410  (0.01639)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 290/406 -- GLOBAL_STEP: 4350\u001b[0m\n",
            "     | > decoder_loss: 4.14960  (4.01622)\n",
            "     | > postnet_loss: 2.63679  (2.60743)\n",
            "     | > stopnet_loss: 0.51437  (0.52372)\n",
            "     | > ga_loss: 0.00278  (0.00466)\n",
            "     | > decoder_diff_spec_loss: 0.22529  (0.22531)\n",
            "     | > postnet_diff_spec_loss: 0.46202  (0.46446)\n",
            "     | > decoder_ssim_loss: 0.92169  (0.92762)\n",
            "     | > postnet_ssim_loss: 0.87368  (0.88235)\n",
            "     | > loss: 2.84556  (2.82784)\n",
            "     | > align_error: 0.99056  (0.98502)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.86234  (1.78220)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.75120  (1.28067)\n",
            "     | > loader_time: 0.02330  (0.01699)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 315/406 -- GLOBAL_STEP: 4375\u001b[0m\n",
            "     | > decoder_loss: 4.10179  (4.02162)\n",
            "     | > postnet_loss: 2.61251  (2.60900)\n",
            "     | > stopnet_loss: 0.50582  (0.52265)\n",
            "     | > ga_loss: 0.00263  (0.00450)\n",
            "     | > decoder_diff_spec_loss: 0.23090  (0.22538)\n",
            "     | > postnet_diff_spec_loss: 0.46610  (0.46429)\n",
            "     | > decoder_ssim_loss: 0.92441  (0.92733)\n",
            "     | > postnet_ssim_loss: 0.87564  (0.88180)\n",
            "     | > loss: 2.82182  (2.82752)\n",
            "     | > align_error: 0.99190  (0.98549)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.91329  (1.78903)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91480  (1.32767)\n",
            "     | > loader_time: 0.02460  (0.01763)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 340/406 -- GLOBAL_STEP: 4400\u001b[0m\n",
            "     | > decoder_loss: 4.06937  (4.02643)\n",
            "     | > postnet_loss: 2.59926  (2.61034)\n",
            "     | > stopnet_loss: 0.50718  (0.52159)\n",
            "     | > ga_loss: 0.00260  (0.00436)\n",
            "     | > decoder_diff_spec_loss: 0.22597  (0.22549)\n",
            "     | > postnet_diff_spec_loss: 0.45900  (0.46413)\n",
            "     | > decoder_ssim_loss: 0.92210  (0.92703)\n",
            "     | > postnet_ssim_loss: 0.87170  (0.88124)\n",
            "     | > loss: 2.80701  (2.82707)\n",
            "     | > align_error: 0.99133  (0.98592)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.87308  (1.79526)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.80480  (1.37205)\n",
            "     | > loader_time: 0.02600  (0.01824)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 365/406 -- GLOBAL_STEP: 4425\u001b[0m\n",
            "     | > decoder_loss: 3.96622  (4.03261)\n",
            "     | > postnet_loss: 2.63750  (2.61171)\n",
            "     | > stopnet_loss: 0.50323  (0.52049)\n",
            "     | > ga_loss: 0.00234  (0.00423)\n",
            "     | > decoder_diff_spec_loss: 0.22600  (0.22550)\n",
            "     | > postnet_diff_spec_loss: 0.46449  (0.46393)\n",
            "     | > decoder_ssim_loss: 0.92224  (0.92678)\n",
            "     | > postnet_ssim_loss: 0.87605  (0.88073)\n",
            "     | > loss: 2.78807  (2.82698)\n",
            "     | > align_error: 0.99252  (0.98632)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.89453  (1.80190)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.20460  (1.41796)\n",
            "     | > loader_time: 0.02690  (0.01883)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 390/406 -- GLOBAL_STEP: 4450\u001b[0m\n",
            "     | > decoder_loss: 4.09656  (4.03714)\n",
            "     | > postnet_loss: 2.62072  (2.61254)\n",
            "     | > stopnet_loss: 0.50147  (0.51935)\n",
            "     | > ga_loss: 0.00231  (0.00412)\n",
            "     | > decoder_diff_spec_loss: 0.22620  (0.22557)\n",
            "     | > postnet_diff_spec_loss: 0.45957  (0.46378)\n",
            "     | > decoder_ssim_loss: 0.92388  (0.92650)\n",
            "     | > postnet_ssim_loss: 0.87335  (0.88026)\n",
            "     | > loss: 2.81312  (2.82637)\n",
            "     | > align_error: 0.99242  (0.98670)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.92599  (1.80843)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.07320  (1.46193)\n",
            "     | > loader_time: 0.02820  (0.01944)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01645 \u001b[0m(+0.00099)\n",
            "     | > avg_decoder_loss:\u001b[92m 4.00847 \u001b[0m(-0.08446)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.59147 \u001b[0m(-0.00791)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.48391 \u001b[0m(-0.02845)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00329 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.22091 \u001b[0m(+0.00229)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46433 \u001b[0m(-0.00023)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.88401 \u001b[0m(-0.00814)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.82895 \u001b[0m(-0.00667)\n",
            "     | > avg_loss:\u001b[92m 2.74992 \u001b[0m(-0.05480)\n",
            "     | > avg_align_error:\u001b[91m 0.98978 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_4466.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 11/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 09:04:58) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 9/406 -- GLOBAL_STEP: 4475\u001b[0m\n",
            "     | > decoder_loss: 3.83602  (3.71241)\n",
            "     | > postnet_loss: 2.54694  (2.59411)\n",
            "     | > stopnet_loss: 0.51383  (0.50663)\n",
            "     | > ga_loss: 0.01121  (0.01397)\n",
            "     | > decoder_diff_spec_loss: 0.22030  (0.22075)\n",
            "     | > postnet_diff_spec_loss: 0.46505  (0.46391)\n",
            "     | > decoder_ssim_loss: 0.92206  (0.91853)\n",
            "     | > postnet_ssim_loss: 0.88738  (0.88628)\n",
            "     | > loss: 2.78931  (2.77546)\n",
            "     | > align_error: 0.96413  (0.95910)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.86515  (1.85180)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.53880  (0.57413)\n",
            "     | > loader_time: 0.00720  (0.00756)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 34/406 -- GLOBAL_STEP: 4500\u001b[0m\n",
            "     | > decoder_loss: 3.74137  (3.73945)\n",
            "     | > postnet_loss: 2.55085  (2.57826)\n",
            "     | > stopnet_loss: 0.49516  (0.50208)\n",
            "     | > ga_loss: 0.00683  (0.00975)\n",
            "     | > decoder_diff_spec_loss: 0.22945  (0.22623)\n",
            "     | > postnet_diff_spec_loss: 0.46875  (0.46738)\n",
            "     | > decoder_ssim_loss: 0.92544  (0.92277)\n",
            "     | > postnet_ssim_loss: 0.89591  (0.89090)\n",
            "     | > loss: 2.73227  (2.75708)\n",
            "     | > align_error: 0.97941  (0.96993)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.93511  (1.87469)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.80120  (0.67000)\n",
            "     | > loader_time: 0.01040  (0.00901)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 59/406 -- GLOBAL_STEP: 4525\u001b[0m\n",
            "     | > decoder_loss: 3.96043  (3.76572)\n",
            "     | > postnet_loss: 2.59136  (2.57546)\n",
            "     | > stopnet_loss: 0.50215  (0.50007)\n",
            "     | > ga_loss: 0.00557  (0.00822)\n",
            "     | > decoder_diff_spec_loss: 0.22392  (0.22691)\n",
            "     | > postnet_diff_spec_loss: 0.46081  (0.46676)\n",
            "     | > decoder_ssim_loss: 0.92317  (0.92275)\n",
            "     | > postnet_ssim_loss: 0.88844  (0.89110)\n",
            "     | > loss: 2.79202  (2.75333)\n",
            "     | > align_error: 0.98162  (0.97432)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.93417  (1.89170)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.94420  (0.75616)\n",
            "     | > loader_time: 0.01260  (0.01011)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 84/406 -- GLOBAL_STEP: 4550\u001b[0m\n",
            "     | > decoder_loss: 4.00048  (3.80399)\n",
            "     | > postnet_loss: 2.61548  (2.58026)\n",
            "     | > stopnet_loss: 0.49326  (0.49858)\n",
            "     | > ga_loss: 0.00479  (0.00730)\n",
            "     | > decoder_diff_spec_loss: 0.22589  (0.22753)\n",
            "     | > postnet_diff_spec_loss: 0.45770  (0.46631)\n",
            "     | > decoder_ssim_loss: 0.92716  (0.92294)\n",
            "     | > postnet_ssim_loss: 0.87213  (0.88943)\n",
            "     | > loss: 2.79192  (2.75769)\n",
            "     | > align_error: 0.98364  (0.97693)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.92429  (1.90397)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.10240  (0.84065)\n",
            "     | > loader_time: 0.01430  (0.01118)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 109/406 -- GLOBAL_STEP: 4575\u001b[0m\n",
            "     | > decoder_loss: 3.89187  (3.82828)\n",
            "     | > postnet_loss: 2.59325  (2.58351)\n",
            "     | > stopnet_loss: 0.49163  (0.49673)\n",
            "     | > ga_loss: 0.00430  (0.00666)\n",
            "     | > decoder_diff_spec_loss: 0.23086  (0.22803)\n",
            "     | > postnet_diff_spec_loss: 0.46516  (0.46603)\n",
            "     | > decoder_ssim_loss: 0.92235  (0.92286)\n",
            "     | > postnet_ssim_loss: 0.87233  (0.88574)\n",
            "     | > loss: 2.75707  (2.75864)\n",
            "     | > align_error: 0.98543  (0.97887)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.93544  (1.91519)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.13800  (0.90408)\n",
            "     | > loader_time: 0.01560  (0.01212)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 134/406 -- GLOBAL_STEP: 4600\u001b[0m\n",
            "     | > decoder_loss: 4.03689  (3.85293)\n",
            "     | > postnet_loss: 2.62144  (2.58657)\n",
            "     | > stopnet_loss: 0.48673  (0.49525)\n",
            "     | > ga_loss: 0.00402  (0.00619)\n",
            "     | > decoder_diff_spec_loss: 0.22887  (0.22819)\n",
            "     | > postnet_diff_spec_loss: 0.46107  (0.46568)\n",
            "     | > decoder_ssim_loss: 0.92274  (0.92268)\n",
            "     | > postnet_ssim_loss: 0.87201  (0.88331)\n",
            "     | > loss: 2.79256  (2.76103)\n",
            "     | > align_error: 0.98622  (0.98028)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.95291  (1.92516)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.20890  (0.96301)\n",
            "     | > loader_time: 0.01720  (0.01297)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 159/406 -- GLOBAL_STEP: 4625\u001b[0m\n",
            "     | > decoder_loss: 3.85183  (3.86894)\n",
            "     | > postnet_loss: 2.58599  (2.58787)\n",
            "     | > stopnet_loss: 0.48745  (0.49387)\n",
            "     | > ga_loss: 0.00366  (0.00582)\n",
            "     | > decoder_diff_spec_loss: 0.22551  (0.22848)\n",
            "     | > postnet_diff_spec_loss: 0.46264  (0.46554)\n",
            "     | > decoder_ssim_loss: 0.92146  (0.92240)\n",
            "     | > postnet_ssim_loss: 0.87216  (0.88152)\n",
            "     | > loss: 2.73564  (2.76165)\n",
            "     | > align_error: 0.98739  (0.98137)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.94319  (1.93259)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.29910  (1.01457)\n",
            "     | > loader_time: 0.01830  (0.01377)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 184/406 -- GLOBAL_STEP: 4650\u001b[0m\n",
            "     | > decoder_loss: 4.08688  (3.88048)\n",
            "     | > postnet_loss: 2.62165  (2.59007)\n",
            "     | > stopnet_loss: 0.47819  (0.49247)\n",
            "     | > ga_loss: 0.00363  (0.00551)\n",
            "     | > decoder_diff_spec_loss: 0.22561  (0.22856)\n",
            "     | > postnet_diff_spec_loss: 0.45767  (0.46517)\n",
            "     | > decoder_ssim_loss: 0.91689  (0.92208)\n",
            "     | > postnet_ssim_loss: 0.86965  (0.88012)\n",
            "     | > loss: 2.79095  (2.76166)\n",
            "     | > align_error: 0.98844  (0.98230)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.04047  (1.94068)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.36230  (1.06401)\n",
            "     | > loader_time: 0.01890  (0.01444)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 209/406 -- GLOBAL_STEP: 4675\u001b[0m\n",
            "     | > decoder_loss: 3.94623  (3.89269)\n",
            "     | > postnet_loss: 2.65052  (2.59269)\n",
            "     | > stopnet_loss: 0.47621  (0.49101)\n",
            "     | > ga_loss: 0.00335  (0.00526)\n",
            "     | > decoder_diff_spec_loss: 0.23204  (0.22874)\n",
            "     | > postnet_diff_spec_loss: 0.46529  (0.46486)\n",
            "     | > decoder_ssim_loss: 0.91887  (0.92180)\n",
            "     | > postnet_ssim_loss: 0.86966  (0.87898)\n",
            "     | > loss: 2.76361  (2.76223)\n",
            "     | > align_error: 0.98932  (0.98310)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.02716  (1.94942)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.50170  (1.11692)\n",
            "     | > loader_time: 0.02010  (0.01515)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 234/406 -- GLOBAL_STEP: 4700\u001b[0m\n",
            "     | > decoder_loss: 3.99318  (3.90293)\n",
            "     | > postnet_loss: 2.64581  (2.59528)\n",
            "     | > stopnet_loss: 0.47845  (0.48960)\n",
            "     | > ga_loss: 0.00315  (0.00503)\n",
            "     | > decoder_diff_spec_loss: 0.22823  (0.22887)\n",
            "     | > postnet_diff_spec_loss: 0.46134  (0.46466)\n",
            "     | > decoder_ssim_loss: 0.91825  (0.92157)\n",
            "     | > postnet_ssim_loss: 0.86903  (0.87803)\n",
            "     | > loss: 2.77316  (2.76260)\n",
            "     | > align_error: 0.98932  (0.98379)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.01409  (1.95745)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.68760  (1.16699)\n",
            "     | > loader_time: 0.02090  (0.01582)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 259/406 -- GLOBAL_STEP: 4725\u001b[0m\n",
            "     | > decoder_loss: 4.07764  (3.91065)\n",
            "     | > postnet_loss: 2.65064  (2.59713)\n",
            "     | > stopnet_loss: 0.47605  (0.48822)\n",
            "     | > ga_loss: 0.00296  (0.00484)\n",
            "     | > decoder_diff_spec_loss: 0.22478  (0.22899)\n",
            "     | > postnet_diff_spec_loss: 0.45618  (0.46444)\n",
            "     | > decoder_ssim_loss: 0.91967  (0.92135)\n",
            "     | > postnet_ssim_loss: 0.86855  (0.87719)\n",
            "     | > loss: 2.79024  (2.76234)\n",
            "     | > align_error: 0.98981  (0.98440)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.03340  (1.96584)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.79770  (1.21741)\n",
            "     | > loader_time: 0.02250  (0.01642)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 284/406 -- GLOBAL_STEP: 4750\u001b[0m\n",
            "     | > decoder_loss: 4.05410  (3.91622)\n",
            "     | > postnet_loss: 2.61129  (2.59902)\n",
            "     | > stopnet_loss: 0.46762  (0.48679)\n",
            "     | > ga_loss: 0.00286  (0.00466)\n",
            "     | > decoder_diff_spec_loss: 0.22955  (0.22912)\n",
            "     | > postnet_diff_spec_loss: 0.46030  (0.46427)\n",
            "     | > decoder_ssim_loss: 0.91580  (0.92106)\n",
            "     | > postnet_ssim_loss: 0.86547  (0.87645)\n",
            "     | > loss: 2.76603  (2.76165)\n",
            "     | > align_error: 0.99081  (0.98494)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.08302  (1.97301)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.76490  (1.26724)\n",
            "     | > loader_time: 0.02290  (0.01703)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 309/406 -- GLOBAL_STEP: 4775\u001b[0m\n",
            "     | > decoder_loss: 3.93912  (3.92078)\n",
            "     | > postnet_loss: 2.63027  (2.60075)\n",
            "     | > stopnet_loss: 0.46565  (0.48536)\n",
            "     | > ga_loss: 0.00263  (0.00451)\n",
            "     | > decoder_diff_spec_loss: 0.23085  (0.22921)\n",
            "     | > postnet_diff_spec_loss: 0.46170  (0.46408)\n",
            "     | > decoder_ssim_loss: 0.91883  (0.92080)\n",
            "     | > postnet_ssim_loss: 0.86756  (0.87580)\n",
            "     | > loss: 2.74090  (2.76077)\n",
            "     | > align_error: 0.99129  (0.98542)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.06267  (1.98036)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.01130  (1.31615)\n",
            "     | > loader_time: 0.02410  (0.01761)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 334/406 -- GLOBAL_STEP: 4800\u001b[0m\n",
            "     | > decoder_loss: 3.97306  (3.92452)\n",
            "     | > postnet_loss: 2.66074  (2.60171)\n",
            "     | > stopnet_loss: 0.46549  (0.48404)\n",
            "     | > ga_loss: 0.00265  (0.00437)\n",
            "     | > decoder_diff_spec_loss: 0.22930  (0.22937)\n",
            "     | > postnet_diff_spec_loss: 0.46099  (0.46397)\n",
            "     | > decoder_ssim_loss: 0.91574  (0.92054)\n",
            "     | > postnet_ssim_loss: 0.86880  (0.87518)\n",
            "     | > loss: 2.75591  (2.75970)\n",
            "     | > align_error: 0.99131  (0.98586)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.08595  (1.98708)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91820  (1.36219)\n",
            "     | > loader_time: 0.02480  (0.01815)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 359/406 -- GLOBAL_STEP: 4825\u001b[0m\n",
            "     | > decoder_loss: 3.89418  (3.92987)\n",
            "     | > postnet_loss: 2.59397  (2.60266)\n",
            "     | > stopnet_loss: 0.46117  (0.48261)\n",
            "     | > ga_loss: 0.00241  (0.00424)\n",
            "     | > decoder_diff_spec_loss: 0.23386  (0.22943)\n",
            "     | > postnet_diff_spec_loss: 0.46693  (0.46374)\n",
            "     | > decoder_ssim_loss: 0.91667  (0.92031)\n",
            "     | > postnet_ssim_loss: 0.86740  (0.87457)\n",
            "     | > loss: 2.71648  (2.75895)\n",
            "     | > align_error: 0.99210  (0.98626)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.09228  (1.99456)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.93880  (1.40746)\n",
            "     | > loader_time: 0.03420  (0.01874)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 384/406 -- GLOBAL_STEP: 4850\u001b[0m\n",
            "     | > decoder_loss: 3.94928  (3.93313)\n",
            "     | > postnet_loss: 2.59117  (2.60378)\n",
            "     | > stopnet_loss: 0.46158  (0.48120)\n",
            "     | > ga_loss: 0.00228  (0.00412)\n",
            "     | > decoder_diff_spec_loss: 0.23507  (0.22954)\n",
            "     | > postnet_diff_spec_loss: 0.46741  (0.46360)\n",
            "     | > decoder_ssim_loss: 0.91900  (0.92010)\n",
            "     | > postnet_ssim_loss: 0.86803  (0.87404)\n",
            "     | > loss: 2.73049  (2.75784)\n",
            "     | > align_error: 0.99192  (0.98664)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.05919  (2.00138)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.20380  (1.45181)\n",
            "     | > loader_time: 0.02710  (0.01930)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01404 \u001b[0m(-0.00241)\n",
            "     | > avg_decoder_loss:\u001b[92m 3.89891 \u001b[0m(-0.10956)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.58194 \u001b[0m(-0.00953)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.44373 \u001b[0m(-0.04018)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00328 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.22437 \u001b[0m(+0.00346)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46404 \u001b[0m(-0.00029)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.87711 \u001b[0m(-0.00690)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.82036 \u001b[0m(-0.00859)\n",
            "     | > avg_loss:\u001b[92m 2.67682 \u001b[0m(-0.07310)\n",
            "     | > avg_align_error:\u001b[92m 0.98977 \u001b[0m(-0.00001)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_4872.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 12/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 09:25:56) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 3/406 -- GLOBAL_STEP: 4875\u001b[0m\n",
            "     | > decoder_loss: 3.56180  (3.68409)\n",
            "     | > postnet_loss: 2.57601  (2.62392)\n",
            "     | > stopnet_loss: 0.46166  (0.45998)\n",
            "     | > ga_loss: 0.01570  (0.01691)\n",
            "     | > decoder_diff_spec_loss: 0.21962  (0.22270)\n",
            "     | > postnet_diff_spec_loss: 0.45635  (0.46012)\n",
            "     | > decoder_ssim_loss: 0.91322  (0.90995)\n",
            "     | > postnet_ssim_loss: 0.88176  (0.87658)\n",
            "     | > loss: 2.69235  (2.73886)\n",
            "     | > align_error: 0.95416  (0.95143)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.03413  (2.04194)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.52010  (0.63037)\n",
            "     | > loader_time: 0.00630  (0.01097)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 28/406 -- GLOBAL_STEP: 4900\u001b[0m\n",
            "     | > decoder_loss: 3.68325  (3.62610)\n",
            "     | > postnet_loss: 2.57953  (2.57423)\n",
            "     | > stopnet_loss: 0.45372  (0.45790)\n",
            "     | > ga_loss: 0.00732  (0.01025)\n",
            "     | > decoder_diff_spec_loss: 0.23288  (0.23085)\n",
            "     | > postnet_diff_spec_loss: 0.46661  (0.46715)\n",
            "     | > decoder_ssim_loss: 0.91863  (0.91656)\n",
            "     | > postnet_ssim_loss: 0.89227  (0.88742)\n",
            "     | > loss: 2.68363  (2.68475)\n",
            "     | > align_error: 0.97643  (0.96827)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.10157  (2.07307)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.86570  (0.68029)\n",
            "     | > loader_time: 0.01050  (0.00903)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 53/406 -- GLOBAL_STEP: 4925\u001b[0m\n",
            "     | > decoder_loss: 3.69589  (3.64176)\n",
            "     | > postnet_loss: 2.55864  (2.56605)\n",
            "     | > stopnet_loss: 0.45272  (0.45538)\n",
            "     | > ga_loss: 0.00571  (0.00844)\n",
            "     | > decoder_diff_spec_loss: 0.23723  (0.23170)\n",
            "     | > postnet_diff_spec_loss: 0.46705  (0.46647)\n",
            "     | > decoder_ssim_loss: 0.91500  (0.91682)\n",
            "     | > postnet_ssim_loss: 0.89114  (0.88827)\n",
            "     | > loss: 2.67250  (2.67533)\n",
            "     | > align_error: 0.98137  (0.97350)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.12193  (2.09222)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.85480  (0.76897)\n",
            "     | > loader_time: 0.01200  (0.01013)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 78/406 -- GLOBAL_STEP: 4950\u001b[0m\n",
            "     | > decoder_loss: 3.68600  (3.68057)\n",
            "     | > postnet_loss: 2.59414  (2.56999)\n",
            "     | > stopnet_loss: 0.44837  (0.45369)\n",
            "     | > ga_loss: 0.00477  (0.00743)\n",
            "     | > decoder_diff_spec_loss: 0.23338  (0.23245)\n",
            "     | > postnet_diff_spec_loss: 0.46333  (0.46624)\n",
            "     | > decoder_ssim_loss: 0.91796  (0.91697)\n",
            "     | > postnet_ssim_loss: 0.86662  (0.88769)\n",
            "     | > loss: 2.66259  (2.67930)\n",
            "     | > align_error: 0.98497  (0.97640)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.15811  (2.10504)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.05150  (0.83926)\n",
            "     | > loader_time: 0.01360  (0.01107)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 103/406 -- GLOBAL_STEP: 4975\u001b[0m\n",
            "     | > decoder_loss: 3.99448  (3.70944)\n",
            "     | > postnet_loss: 2.63350  (2.57514)\n",
            "     | > stopnet_loss: 0.44398  (0.45160)\n",
            "     | > ga_loss: 0.00444  (0.00675)\n",
            "     | > decoder_diff_spec_loss: 0.23568  (0.23287)\n",
            "     | > postnet_diff_spec_loss: 0.46507  (0.46562)\n",
            "     | > decoder_ssim_loss: 0.91426  (0.91706)\n",
            "     | > postnet_ssim_loss: 0.86411  (0.88224)\n",
            "     | > loss: 2.74294  (2.68093)\n",
            "     | > align_error: 0.98498  (0.97848)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.15555  (2.11807)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.14200  (0.90228)\n",
            "     | > loader_time: 0.01500  (0.01203)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 128/406 -- GLOBAL_STEP: 5000\u001b[0m\n",
            "     | > decoder_loss: 3.98893  (3.72886)\n",
            "     | > postnet_loss: 2.61503  (2.57669)\n",
            "     | > stopnet_loss: 0.44133  (0.44979)\n",
            "     | > ga_loss: 0.00415  (0.00624)\n",
            "     | > decoder_diff_spec_loss: 0.23105  (0.23328)\n",
            "     | > postnet_diff_spec_loss: 0.46011  (0.46552)\n",
            "     | > decoder_ssim_loss: 0.91964  (0.91691)\n",
            "     | > postnet_ssim_loss: 0.86264  (0.87886)\n",
            "     | > loss: 2.73142  (2.68104)\n",
            "     | > align_error: 0.98566  (0.98001)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.15714  (2.12857)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.27940  (0.96037)\n",
            "     | > loader_time: 0.01730  (0.01283)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_5000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 153/406 -- GLOBAL_STEP: 5025\u001b[0m\n",
            "     | > decoder_loss: 3.77054  (3.74723)\n",
            "     | > postnet_loss: 2.58393  (2.57803)\n",
            "     | > stopnet_loss: 0.43732  (0.44825)\n",
            "     | > ga_loss: 0.00373  (0.00586)\n",
            "     | > decoder_diff_spec_loss: 0.23549  (0.23353)\n",
            "     | > postnet_diff_spec_loss: 0.46431  (0.46530)\n",
            "     | > decoder_ssim_loss: 0.91226  (0.91671)\n",
            "     | > postnet_ssim_loss: 0.86300  (0.87642)\n",
            "     | > loss: 2.66335  (2.68184)\n",
            "     | > align_error: 0.98743  (0.98114)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.17274  (2.13608)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.33840  (1.01508)\n",
            "     | > loader_time: 0.01730  (0.01368)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 178/406 -- GLOBAL_STEP: 5050\u001b[0m\n",
            "     | > decoder_loss: 3.77591  (3.75706)\n",
            "     | > postnet_loss: 2.56412  (2.57985)\n",
            "     | > stopnet_loss: 0.43793  (0.44665)\n",
            "     | > ga_loss: 0.00346  (0.00554)\n",
            "     | > decoder_diff_spec_loss: 0.23573  (0.23368)\n",
            "     | > postnet_diff_spec_loss: 0.46170  (0.46500)\n",
            "     | > decoder_ssim_loss: 0.91346  (0.91644)\n",
            "     | > postnet_ssim_loss: 0.86272  (0.87458)\n",
            "     | > loss: 2.65862  (2.68101)\n",
            "     | > align_error: 0.98811  (0.98210)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.18317  (2.14323)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.35460  (1.06436)\n",
            "     | > loader_time: 0.01820  (0.01428)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 203/406 -- GLOBAL_STEP: 5075\u001b[0m\n",
            "     | > decoder_loss: 3.82032  (3.76704)\n",
            "     | > postnet_loss: 2.58036  (2.58209)\n",
            "     | > stopnet_loss: 0.42973  (0.44484)\n",
            "     | > ga_loss: 0.00330  (0.00528)\n",
            "     | > decoder_diff_spec_loss: 0.23777  (0.23385)\n",
            "     | > postnet_diff_spec_loss: 0.46450  (0.46463)\n",
            "     | > decoder_ssim_loss: 0.91337  (0.91620)\n",
            "     | > postnet_ssim_loss: 0.86126  (0.87308)\n",
            "     | > loss: 2.66564  (2.68044)\n",
            "     | > align_error: 0.98954  (0.98293)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.25538  (2.15259)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.57820  (1.11320)\n",
            "     | > loader_time: 0.01950  (0.01485)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 228/406 -- GLOBAL_STEP: 5100\u001b[0m\n",
            "     | > decoder_loss: 3.96500  (3.77806)\n",
            "     | > postnet_loss: 2.61776  (2.58430)\n",
            "     | > stopnet_loss: 0.42730  (0.44318)\n",
            "     | > ga_loss: 0.00322  (0.00505)\n",
            "     | > decoder_diff_spec_loss: 0.23700  (0.23404)\n",
            "     | > postnet_diff_spec_loss: 0.46180  (0.46444)\n",
            "     | > decoder_ssim_loss: 0.91448  (0.91602)\n",
            "     | > postnet_ssim_loss: 0.86029  (0.87184)\n",
            "     | > loss: 2.70746  (2.68059)\n",
            "     | > align_error: 0.98924  (0.98363)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.24371  (2.15998)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.60390  (1.16045)\n",
            "     | > loader_time: 0.02070  (0.01549)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 253/406 -- GLOBAL_STEP: 5125\u001b[0m\n",
            "     | > decoder_loss: 3.87728  (3.78483)\n",
            "     | > postnet_loss: 2.64094  (2.58696)\n",
            "     | > stopnet_loss: 0.42041  (0.44140)\n",
            "     | > ga_loss: 0.00302  (0.00485)\n",
            "     | > decoder_diff_spec_loss: 0.23573  (0.23421)\n",
            "     | > postnet_diff_spec_loss: 0.46139  (0.46421)\n",
            "     | > decoder_ssim_loss: 0.91485  (0.91583)\n",
            "     | > postnet_ssim_loss: 0.86052  (0.87076)\n",
            "     | > loss: 2.68319  (2.67985)\n",
            "     | > align_error: 0.99034  (0.98426)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.25978  (2.16845)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.56010  (1.21182)\n",
            "     | > loader_time: 0.02170  (0.01608)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 278/406 -- GLOBAL_STEP: 5150\u001b[0m\n",
            "     | > decoder_loss: 3.66706  (3.78841)\n",
            "     | > postnet_loss: 2.54339  (2.58824)\n",
            "     | > stopnet_loss: 0.42391  (0.43963)\n",
            "     | > ga_loss: 0.00275  (0.00467)\n",
            "     | > decoder_diff_spec_loss: 0.23808  (0.23439)\n",
            "     | > postnet_diff_spec_loss: 0.46823  (0.46403)\n",
            "     | > decoder_ssim_loss: 0.91074  (0.91558)\n",
            "     | > postnet_ssim_loss: 0.86094  (0.86982)\n",
            "     | > loss: 2.60977  (2.67810)\n",
            "     | > align_error: 0.99058  (0.98482)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.22072  (2.17591)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.84010  (1.26019)\n",
            "     | > loader_time: 0.02250  (0.01665)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 303/406 -- GLOBAL_STEP: 5175\u001b[0m\n",
            "     | > decoder_loss: 3.89232  (3.79354)\n",
            "     | > postnet_loss: 2.63212  (2.59014)\n",
            "     | > stopnet_loss: 0.41745  (0.43788)\n",
            "     | > ga_loss: 0.00271  (0.00451)\n",
            "     | > decoder_diff_spec_loss: 0.23650  (0.23453)\n",
            "     | > postnet_diff_spec_loss: 0.46116  (0.46381)\n",
            "     | > decoder_ssim_loss: 0.91287  (0.91536)\n",
            "     | > postnet_ssim_loss: 0.85910  (0.86898)\n",
            "     | > loss: 2.67954  (2.67704)\n",
            "     | > align_error: 0.99077  (0.98531)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.26082  (2.18329)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91760  (1.30618)\n",
            "     | > loader_time: 0.02360  (0.01719)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 328/406 -- GLOBAL_STEP: 5200\u001b[0m\n",
            "     | > decoder_loss: 3.87197  (3.79590)\n",
            "     | > postnet_loss: 2.63206  (2.59077)\n",
            "     | > stopnet_loss: 0.41368  (0.43621)\n",
            "     | > ga_loss: 0.00266  (0.00437)\n",
            "     | > decoder_diff_spec_loss: 0.23220  (0.23475)\n",
            "     | > postnet_diff_spec_loss: 0.45571  (0.46372)\n",
            "     | > decoder_ssim_loss: 0.91126  (0.91513)\n",
            "     | > postnet_ssim_loss: 0.85657  (0.86819)\n",
            "     | > loss: 2.66690  (2.67517)\n",
            "     | > align_error: 0.99103  (0.98576)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.28014  (2.18972)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.81600  (1.35035)\n",
            "     | > loader_time: 0.02510  (0.01773)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 353/406 -- GLOBAL_STEP: 5225\u001b[0m\n",
            "     | > decoder_loss: 3.90390  (3.79959)\n",
            "     | > postnet_loss: 2.61421  (2.59197)\n",
            "     | > stopnet_loss: 0.40911  (0.43445)\n",
            "     | > ga_loss: 0.00250  (0.00424)\n",
            "     | > decoder_diff_spec_loss: 0.23550  (0.23487)\n",
            "     | > postnet_diff_spec_loss: 0.45864  (0.46350)\n",
            "     | > decoder_ssim_loss: 0.91537  (0.91495)\n",
            "     | > postnet_ssim_loss: 0.85625  (0.86744)\n",
            "     | > loss: 2.66758  (2.67373)\n",
            "     | > align_error: 0.99174  (0.98617)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.31218  (2.19689)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.94500  (1.39441)\n",
            "     | > loader_time: 0.02540  (0.01827)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 378/406 -- GLOBAL_STEP: 5250\u001b[0m\n",
            "     | > decoder_loss: 3.83128  (3.80288)\n",
            "     | > postnet_loss: 2.63332  (2.59312)\n",
            "     | > stopnet_loss: 0.40703  (0.43275)\n",
            "     | > ga_loss: 0.00236  (0.00412)\n",
            "     | > decoder_diff_spec_loss: 0.23650  (0.23499)\n",
            "     | > postnet_diff_spec_loss: 0.45971  (0.46331)\n",
            "     | > decoder_ssim_loss: 0.91276  (0.91478)\n",
            "     | > postnet_ssim_loss: 0.85616  (0.86674)\n",
            "     | > loss: 2.65125  (2.67229)\n",
            "     | > align_error: 0.99193  (0.98655)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.27146  (2.20340)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.11750  (1.43844)\n",
            "     | > loader_time: 0.02640  (0.01879)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 403/406 -- GLOBAL_STEP: 5275\u001b[0m\n",
            "     | > decoder_loss: 3.70470  (3.80576)\n",
            "     | > postnet_loss: 2.55188  (2.59395)\n",
            "     | > stopnet_loss: 0.40744  (0.43100)\n",
            "     | > ga_loss: 0.00221  (0.00401)\n",
            "     | > decoder_diff_spec_loss: 0.24046  (0.23517)\n",
            "     | > postnet_diff_spec_loss: 0.46591  (0.46318)\n",
            "     | > decoder_ssim_loss: 0.91022  (0.91461)\n",
            "     | > postnet_ssim_loss: 0.85612  (0.86610)\n",
            "     | > loss: 2.60080  (2.67072)\n",
            "     | > align_error: 0.99241  (0.98690)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.28074  (2.20986)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.89900  (1.47797)\n",
            "     | > loader_time: 0.02770  (0.01937)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01773 \u001b[0m(+0.00369)\n",
            "     | > avg_decoder_loss:\u001b[92m 3.76446 \u001b[0m(-0.13445)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.57141 \u001b[0m(-0.01053)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.39779 \u001b[0m(-0.04594)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00327 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.22901 \u001b[0m(+0.00464)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46364 \u001b[0m(-0.00040)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.87183 \u001b[0m(-0.00528)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.80865 \u001b[0m(-0.01171)\n",
            "     | > avg_loss:\u001b[92m 2.59139 \u001b[0m(-0.08543)\n",
            "     | > avg_align_error:\u001b[92m 0.98973 \u001b[0m(-0.00004)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_5278.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 13/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 09:46:59) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 22/406 -- GLOBAL_STEP: 5300\u001b[0m\n",
            "     | > decoder_loss: 3.39966  (3.47098)\n",
            "     | > postnet_loss: 2.53315  (2.56264)\n",
            "     | > stopnet_loss: 0.40178  (0.40615)\n",
            "     | > ga_loss: 0.00759  (0.01086)\n",
            "     | > decoder_diff_spec_loss: 0.24425  (0.23681)\n",
            "     | > postnet_diff_spec_loss: 0.47466  (0.46709)\n",
            "     | > decoder_ssim_loss: 0.91547  (0.91082)\n",
            "     | > postnet_ssim_loss: 0.89263  (0.88577)\n",
            "     | > loss: 2.55471  (2.59397)\n",
            "     | > align_error: 0.97529  (0.96635)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.27240  (2.26756)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.71830  (0.61859)\n",
            "     | > loader_time: 0.00960  (0.00848)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 47/406 -- GLOBAL_STEP: 5325\u001b[0m\n",
            "     | > decoder_loss: 3.63540  (3.48841)\n",
            "     | > postnet_loss: 2.58897  (2.55397)\n",
            "     | > stopnet_loss: 0.39928  (0.40252)\n",
            "     | > ga_loss: 0.00622  (0.00866)\n",
            "     | > decoder_diff_spec_loss: 0.23924  (0.23827)\n",
            "     | > postnet_diff_spec_loss: 0.46678  (0.46659)\n",
            "     | > decoder_ssim_loss: 0.91345  (0.91145)\n",
            "     | > postnet_ssim_loss: 0.88723  (0.88700)\n",
            "     | > loss: 2.61316  (2.58226)\n",
            "     | > align_error: 0.97893  (0.97257)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.31522  (2.28784)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.82700  (0.72321)\n",
            "     | > loader_time: 0.01120  (0.00997)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 72/406 -- GLOBAL_STEP: 5350\u001b[0m\n",
            "     | > decoder_loss: 3.53349  (3.52663)\n",
            "     | > postnet_loss: 2.54150  (2.55714)\n",
            "     | > stopnet_loss: 0.39160  (0.39987)\n",
            "     | > ga_loss: 0.00492  (0.00755)\n",
            "     | > decoder_diff_spec_loss: 0.24557  (0.23902)\n",
            "     | > postnet_diff_spec_loss: 0.47087  (0.46607)\n",
            "     | > decoder_ssim_loss: 0.91052  (0.91171)\n",
            "     | > postnet_ssim_loss: 0.88409  (0.88644)\n",
            "     | > loss: 2.56273  (2.58436)\n",
            "     | > align_error: 0.98358  (0.97582)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.32449  (2.30051)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.99060  (0.80522)\n",
            "     | > loader_time: 0.01450  (0.01111)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 97/406 -- GLOBAL_STEP: 5375\u001b[0m\n",
            "     | > decoder_loss: 3.56424  (3.55516)\n",
            "     | > postnet_loss: 2.54030  (2.56261)\n",
            "     | > stopnet_loss: 0.38608  (0.39734)\n",
            "     | > ga_loss: 0.00442  (0.00682)\n",
            "     | > decoder_diff_spec_loss: 0.24295  (0.23950)\n",
            "     | > postnet_diff_spec_loss: 0.46360  (0.46538)\n",
            "     | > decoder_ssim_loss: 0.91216  (0.91202)\n",
            "     | > postnet_ssim_loss: 0.85447  (0.87986)\n",
            "     | > loss: 2.55263  (2.58506)\n",
            "     | > align_error: 0.98576  (0.97804)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.36708  (2.31284)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.18150  (0.87525)\n",
            "     | > loader_time: 0.01500  (0.01198)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 122/406 -- GLOBAL_STEP: 5400\u001b[0m\n",
            "     | > decoder_loss: 3.46988  (3.57240)\n",
            "     | > postnet_loss: 2.49756  (2.56386)\n",
            "     | > stopnet_loss: 0.38359  (0.39509)\n",
            "     | > ga_loss: 0.00393  (0.00629)\n",
            "     | > decoder_diff_spec_loss: 0.24600  (0.23994)\n",
            "     | > postnet_diff_spec_loss: 0.47241  (0.46528)\n",
            "     | > decoder_ssim_loss: 0.91270  (0.91197)\n",
            "     | > postnet_ssim_loss: 0.85411  (0.87463)\n",
            "     | > loss: 2.51642  (2.58355)\n",
            "     | > align_error: 0.98709  (0.97967)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.33977  (2.32175)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.21410  (0.93959)\n",
            "     | > loader_time: 0.01660  (0.01280)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 147/406 -- GLOBAL_STEP: 5425\u001b[0m\n",
            "     | > decoder_loss: 3.72640  (3.59372)\n",
            "     | > postnet_loss: 2.57189  (2.56629)\n",
            "     | > stopnet_loss: 0.38265  (0.39315)\n",
            "     | > ga_loss: 0.00377  (0.00589)\n",
            "     | > decoder_diff_spec_loss: 0.24479  (0.24019)\n",
            "     | > postnet_diff_spec_loss: 0.46651  (0.46497)\n",
            "     | > decoder_ssim_loss: 0.91182  (0.91186)\n",
            "     | > postnet_ssim_loss: 0.85124  (0.87092)\n",
            "     | > loss: 2.59467  (2.58457)\n",
            "     | > align_error: 0.98694  (0.98086)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.36250  (2.32851)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.25750  (1.00048)\n",
            "     | > loader_time: 0.01740  (0.01359)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 172/406 -- GLOBAL_STEP: 5450\u001b[0m\n",
            "     | > decoder_loss: 3.68070  (3.60235)\n",
            "     | > postnet_loss: 2.58301  (2.56784)\n",
            "     | > stopnet_loss: 0.37802  (0.39123)\n",
            "     | > ga_loss: 0.00349  (0.00556)\n",
            "     | > decoder_diff_spec_loss: 0.23944  (0.24041)\n",
            "     | > postnet_diff_spec_loss: 0.46304  (0.46476)\n",
            "     | > decoder_ssim_loss: 0.91021  (0.91161)\n",
            "     | > postnet_ssim_loss: 0.85181  (0.86825)\n",
            "     | > loss: 2.57753  (2.58282)\n",
            "     | > align_error: 0.98788  (0.98184)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.36276  (2.33365)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.38750  (1.05018)\n",
            "     | > loader_time: 0.01850  (0.01433)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 197/406 -- GLOBAL_STEP: 5475\u001b[0m\n",
            "     | > decoder_loss: 3.63460  (3.61099)\n",
            "     | > postnet_loss: 2.60029  (2.56998)\n",
            "     | > stopnet_loss: 0.37286  (0.38890)\n",
            "     | > ga_loss: 0.00331  (0.00529)\n",
            "     | > decoder_diff_spec_loss: 0.23899  (0.24057)\n",
            "     | > postnet_diff_spec_loss: 0.45940  (0.46432)\n",
            "     | > decoder_ssim_loss: 0.91505  (0.91148)\n",
            "     | > postnet_ssim_loss: 0.85192  (0.86610)\n",
            "     | > loss: 2.56448  (2.58120)\n",
            "     | > align_error: 0.98890  (0.98271)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.37873  (2.34123)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.47530  (1.09927)\n",
            "     | > loader_time: 0.01950  (0.01494)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 222/406 -- GLOBAL_STEP: 5500\u001b[0m\n",
            "     | > decoder_loss: 3.73664  (3.62109)\n",
            "     | > postnet_loss: 2.59558  (2.57202)\n",
            "     | > stopnet_loss: 0.37419  (0.38692)\n",
            "     | > ga_loss: 0.00311  (0.00505)\n",
            "     | > decoder_diff_spec_loss: 0.24251  (0.24080)\n",
            "     | > postnet_diff_spec_loss: 0.46394  (0.46411)\n",
            "     | > decoder_ssim_loss: 0.91185  (0.91136)\n",
            "     | > postnet_ssim_loss: 0.85022  (0.86435)\n",
            "     | > loss: 2.58995  (2.58062)\n",
            "     | > align_error: 0.98916  (0.98344)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.39317  (2.34750)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.53650  (1.14804)\n",
            "     | > loader_time: 0.02100  (0.01561)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 247/406 -- GLOBAL_STEP: 5525\u001b[0m\n",
            "     | > decoder_loss: 3.49630  (3.62702)\n",
            "     | > postnet_loss: 2.56281  (2.57438)\n",
            "     | > stopnet_loss: 0.35326  (0.38477)\n",
            "     | > ga_loss: 0.00285  (0.00485)\n",
            "     | > decoder_diff_spec_loss: 0.24877  (0.24107)\n",
            "     | > postnet_diff_spec_loss: 0.46570  (0.46391)\n",
            "     | > decoder_ssim_loss: 0.91134  (0.91127)\n",
            "     | > postnet_ssim_loss: 0.84919  (0.86284)\n",
            "     | > loss: 2.50102  (2.57914)\n",
            "     | > align_error: 0.99157  (0.98408)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.45876  (2.35412)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.78330  (1.20042)\n",
            "     | > loader_time: 0.02230  (0.01623)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 272/406 -- GLOBAL_STEP: 5550\u001b[0m\n",
            "     | > decoder_loss: 3.69661  (3.62985)\n",
            "     | > postnet_loss: 2.60818  (2.57568)\n",
            "     | > stopnet_loss: 0.36351  (0.38271)\n",
            "     | > ga_loss: 0.00282  (0.00467)\n",
            "     | > decoder_diff_spec_loss: 0.24284  (0.24125)\n",
            "     | > postnet_diff_spec_loss: 0.46176  (0.46367)\n",
            "     | > decoder_ssim_loss: 0.90789  (0.91107)\n",
            "     | > postnet_ssim_loss: 0.84793  (0.86148)\n",
            "     | > loss: 2.56890  (2.57682)\n",
            "     | > align_error: 0.99025  (0.98465)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.40647  (2.36035)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.09060  (1.25006)\n",
            "     | > loader_time: 0.02230  (0.01682)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 297/406 -- GLOBAL_STEP: 5575\u001b[0m\n",
            "     | > decoder_loss: 3.66568  (3.63317)\n",
            "     | > postnet_loss: 2.57874  (2.57723)\n",
            "     | > stopnet_loss: 0.35252  (0.38069)\n",
            "     | > ga_loss: 0.00269  (0.00451)\n",
            "     | > decoder_diff_spec_loss: 0.24480  (0.24145)\n",
            "     | > postnet_diff_spec_loss: 0.46229  (0.46352)\n",
            "     | > decoder_ssim_loss: 0.91059  (0.91092)\n",
            "     | > postnet_ssim_loss: 0.84551  (0.86029)\n",
            "     | > loss: 2.54285  (2.57489)\n",
            "     | > align_error: 0.99121  (0.98516)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.44351  (2.36587)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.79590  (1.30137)\n",
            "     | > loader_time: 0.02350  (0.01742)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 322/406 -- GLOBAL_STEP: 5600\u001b[0m\n",
            "     | > decoder_loss: 3.73524  (3.63448)\n",
            "     | > postnet_loss: 2.61415  (2.57804)\n",
            "     | > stopnet_loss: 0.35507  (0.37872)\n",
            "     | > ga_loss: 0.00267  (0.00437)\n",
            "     | > decoder_diff_spec_loss: 0.24139  (0.24167)\n",
            "     | > postnet_diff_spec_loss: 0.45789  (0.46338)\n",
            "     | > decoder_ssim_loss: 0.90697  (0.91076)\n",
            "     | > postnet_ssim_loss: 0.84429  (0.85916)\n",
            "     | > loss: 2.56841  (2.57242)\n",
            "     | > align_error: 0.99064  (0.98561)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.43600  (2.37092)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.03500  (1.34593)\n",
            "     | > loader_time: 0.02520  (0.01795)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 347/406 -- GLOBAL_STEP: 5625\u001b[0m\n",
            "     | > decoder_loss: 3.73618  (3.63692)\n",
            "     | > postnet_loss: 2.61867  (2.57933)\n",
            "     | > stopnet_loss: 0.34252  (0.37667)\n",
            "     | > ga_loss: 0.00254  (0.00424)\n",
            "     | > decoder_diff_spec_loss: 0.24492  (0.24188)\n",
            "     | > postnet_diff_spec_loss: 0.45827  (0.46318)\n",
            "     | > decoder_ssim_loss: 0.90779  (0.91061)\n",
            "     | > postnet_ssim_loss: 0.84296  (0.85810)\n",
            "     | > loss: 2.55742  (2.57035)\n",
            "     | > align_error: 0.99180  (0.98603)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.47070  (2.37627)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.00280  (1.39140)\n",
            "     | > loader_time: 0.02510  (0.01847)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 372/406 -- GLOBAL_STEP: 5650\u001b[0m\n",
            "     | > decoder_loss: 3.59656  (3.63907)\n",
            "     | > postnet_loss: 2.58400  (2.58053)\n",
            "     | > stopnet_loss: 0.35174  (0.37465)\n",
            "     | > ga_loss: 0.00233  (0.00411)\n",
            "     | > decoder_diff_spec_loss: 0.24466  (0.24204)\n",
            "     | > postnet_diff_spec_loss: 0.46247  (0.46298)\n",
            "     | > decoder_ssim_loss: 0.90706  (0.91050)\n",
            "     | > postnet_ssim_loss: 0.84272  (0.85712)\n",
            "     | > loss: 2.52275  (2.56828)\n",
            "     | > align_error: 0.99164  (0.98641)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.41887  (2.38108)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.12210  (1.43432)\n",
            "     | > loader_time: 0.02740  (0.01901)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 397/406 -- GLOBAL_STEP: 5675\u001b[0m\n",
            "     | > decoder_loss: 3.66283  (3.64047)\n",
            "     | > postnet_loss: 2.58678  (2.58118)\n",
            "     | > stopnet_loss: 0.34097  (0.37263)\n",
            "     | > ga_loss: 0.00225  (0.00400)\n",
            "     | > decoder_diff_spec_loss: 0.24805  (0.24224)\n",
            "     | > postnet_diff_spec_loss: 0.46224  (0.46282)\n",
            "     | > decoder_ssim_loss: 0.90939  (0.91037)\n",
            "     | > postnet_ssim_loss: 0.84264  (0.85620)\n",
            "     | > loss: 2.53023  (2.56595)\n",
            "     | > align_error: 0.99227  (0.98677)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.46278  (2.38579)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.92040  (1.47742)\n",
            "     | > loader_time: 0.02810  (0.01956)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01135 \u001b[0m(-0.00638)\n",
            "     | > avg_decoder_loss:\u001b[92m 3.61981 \u001b[0m(-0.14465)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.56158 \u001b[0m(-0.00983)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.35350 \u001b[0m(-0.04429)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00327 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.23358 \u001b[0m(+0.00457)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46316 \u001b[0m(-0.00048)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.86818 \u001b[0m(-0.00364)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.79034 \u001b[0m(-0.01831)\n",
            "     | > avg_loss:\u001b[92m 2.50401 \u001b[0m(-0.08737)\n",
            "     | > avg_align_error:\u001b[92m 0.98963 \u001b[0m(-0.00010)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_5684.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 14/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 10:07:58) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 16/406 -- GLOBAL_STEP: 5700\u001b[0m\n",
            "     | > decoder_loss: 3.32384  (3.30827)\n",
            "     | > postnet_loss: 2.56518  (2.55940)\n",
            "     | > stopnet_loss: 0.33648  (0.34364)\n",
            "     | > ga_loss: 0.00883  (0.01179)\n",
            "     | > decoder_diff_spec_loss: 0.24567  (0.24330)\n",
            "     | > postnet_diff_spec_loss: 0.46414  (0.46490)\n",
            "     | > decoder_ssim_loss: 0.91265  (0.90589)\n",
            "     | > postnet_ssim_loss: 0.89070  (0.88031)\n",
            "     | > loss: 2.48120  (2.49310)\n",
            "     | > align_error: 0.97243  (0.96345)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.45381  (2.40980)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.72600  (0.60802)\n",
            "     | > loader_time: 0.00840  (0.00766)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 41/406 -- GLOBAL_STEP: 5725\u001b[0m\n",
            "     | > decoder_loss: 3.26027  (3.30429)\n",
            "     | > postnet_loss: 2.51750  (2.54320)\n",
            "     | > stopnet_loss: 0.33552  (0.33917)\n",
            "     | > ga_loss: 0.00608  (0.00893)\n",
            "     | > decoder_diff_spec_loss: 0.24894  (0.24615)\n",
            "     | > postnet_diff_spec_loss: 0.46721  (0.46626)\n",
            "     | > decoder_ssim_loss: 0.90531  (0.90745)\n",
            "     | > postnet_ssim_loss: 0.88667  (0.88276)\n",
            "     | > loss: 2.43741  (2.47134)\n",
            "     | > align_error: 0.97977  (0.97141)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.44848  (2.42647)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.82350  (0.72610)\n",
            "     | > loader_time: 0.01080  (0.00904)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 66/406 -- GLOBAL_STEP: 5750\u001b[0m\n",
            "     | > decoder_loss: 3.48148  (3.33758)\n",
            "     | > postnet_loss: 2.59158  (2.54286)\n",
            "     | > stopnet_loss: 0.33154  (0.33572)\n",
            "     | > ga_loss: 0.00527  (0.00767)\n",
            "     | > decoder_diff_spec_loss: 0.24565  (0.24692)\n",
            "     | > postnet_diff_spec_loss: 0.46267  (0.46567)\n",
            "     | > decoder_ssim_loss: 0.90747  (0.90792)\n",
            "     | > postnet_ssim_loss: 0.88263  (0.88206)\n",
            "     | > loss: 2.50075  (2.46985)\n",
            "     | > align_error: 0.98166  (0.97509)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.43169  (2.43717)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.06190  (0.80614)\n",
            "     | > loader_time: 0.01350  (0.01016)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 91/406 -- GLOBAL_STEP: 5775\u001b[0m\n",
            "     | > decoder_loss: 3.50438  (3.36585)\n",
            "     | > postnet_loss: 2.62961  (2.54766)\n",
            "     | > stopnet_loss: 0.32479  (0.33309)\n",
            "     | > ga_loss: 0.00451  (0.00689)\n",
            "     | > decoder_diff_spec_loss: 0.24697  (0.24753)\n",
            "     | > postnet_diff_spec_loss: 0.45743  (0.46509)\n",
            "     | > decoder_ssim_loss: 0.90557  (0.90829)\n",
            "     | > postnet_ssim_loss: 0.84017  (0.87561)\n",
            "     | > loss: 2.49337  (2.47003)\n",
            "     | > align_error: 0.98473  (0.97747)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.47985  (2.44624)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.12870  (0.87304)\n",
            "     | > loader_time: 0.01470  (0.01121)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 116/406 -- GLOBAL_STEP: 5800\u001b[0m\n",
            "     | > decoder_loss: 3.31156  (3.38287)\n",
            "     | > postnet_loss: 2.51148  (2.55080)\n",
            "     | > stopnet_loss: 0.32117  (0.33042)\n",
            "     | > ga_loss: 0.00406  (0.00632)\n",
            "     | > decoder_diff_spec_loss: 0.25090  (0.24803)\n",
            "     | > postnet_diff_spec_loss: 0.46655  (0.46487)\n",
            "     | > decoder_ssim_loss: 0.90580  (0.90831)\n",
            "     | > postnet_ssim_loss: 0.83974  (0.86819)\n",
            "     | > loss: 2.41299  (2.46781)\n",
            "     | > align_error: 0.98596  (0.97922)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.44316  (2.45193)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.21800  (0.93422)\n",
            "     | > loader_time: 0.02000  (0.01221)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 141/406 -- GLOBAL_STEP: 5825\u001b[0m\n",
            "     | > decoder_loss: 3.52436  (3.40450)\n",
            "     | > postnet_loss: 2.56899  (2.55305)\n",
            "     | > stopnet_loss: 0.31816  (0.32815)\n",
            "     | > ga_loss: 0.00386  (0.00590)\n",
            "     | > decoder_diff_spec_loss: 0.24992  (0.24820)\n",
            "     | > postnet_diff_spec_loss: 0.46636  (0.46444)\n",
            "     | > decoder_ssim_loss: 0.90804  (0.90829)\n",
            "     | > postnet_ssim_loss: 0.83962  (0.86306)\n",
            "     | > loss: 2.47680  (2.46806)\n",
            "     | > align_error: 0.98638  (0.98049)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.47656  (2.45655)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.42720  (0.99004)\n",
            "     | > loader_time: 0.01700  (0.01306)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 166/406 -- GLOBAL_STEP: 5850\u001b[0m\n",
            "     | > decoder_loss: 3.53082  (3.41251)\n",
            "     | > postnet_loss: 2.58020  (2.55394)\n",
            "     | > stopnet_loss: 0.31044  (0.32610)\n",
            "     | > ga_loss: 0.00355  (0.00557)\n",
            "     | > decoder_diff_spec_loss: 0.25047  (0.24849)\n",
            "     | > postnet_diff_spec_loss: 0.46274  (0.46431)\n",
            "     | > decoder_ssim_loss: 0.90738  (0.90810)\n",
            "     | > postnet_ssim_loss: 0.83620  (0.85927)\n",
            "     | > loss: 2.47012  (2.46558)\n",
            "     | > align_error: 0.98756  (0.98151)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.47693  (2.45916)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.40710  (1.04368)\n",
            "     | > loader_time: 0.01900  (0.01379)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 191/406 -- GLOBAL_STEP: 5875\u001b[0m\n",
            "     | > decoder_loss: 3.51420  (3.41980)\n",
            "     | > postnet_loss: 2.55571  (2.55593)\n",
            "     | > stopnet_loss: 0.30958  (0.32373)\n",
            "     | > ga_loss: 0.00330  (0.00529)\n",
            "     | > decoder_diff_spec_loss: 0.24881  (0.24867)\n",
            "     | > postnet_diff_spec_loss: 0.46014  (0.46392)\n",
            "     | > decoder_ssim_loss: 0.90841  (0.90796)\n",
            "     | > postnet_ssim_loss: 0.83685  (0.85632)\n",
            "     | > loss: 2.45709  (2.46332)\n",
            "     | > align_error: 0.98818  (0.98239)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.46065  (2.46280)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.40720  (1.09152)\n",
            "     | > loader_time: 0.01930  (0.01445)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 216/406 -- GLOBAL_STEP: 5900\u001b[0m\n",
            "     | > decoder_loss: 3.47849  (3.42623)\n",
            "     | > postnet_loss: 2.58326  (2.55778)\n",
            "     | > stopnet_loss: 0.30631  (0.32143)\n",
            "     | > ga_loss: 0.00316  (0.00505)\n",
            "     | > decoder_diff_spec_loss: 0.24892  (0.24895)\n",
            "     | > postnet_diff_spec_loss: 0.46214  (0.46365)\n",
            "     | > decoder_ssim_loss: 0.90639  (0.90788)\n",
            "     | > postnet_ssim_loss: 0.83353  (0.85392)\n",
            "     | > loss: 2.45030  (2.46128)\n",
            "     | > align_error: 0.98888  (0.98315)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.48092  (2.46600)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.61350  (1.13868)\n",
            "     | > loader_time: 0.01960  (0.01512)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 241/406 -- GLOBAL_STEP: 5925\u001b[0m\n",
            "     | > decoder_loss: 3.35198  (3.43149)\n",
            "     | > postnet_loss: 2.53266  (2.56010)\n",
            "     | > stopnet_loss: 0.29486  (0.31905)\n",
            "     | > ga_loss: 0.00292  (0.00484)\n",
            "     | > decoder_diff_spec_loss: 0.25324  (0.24921)\n",
            "     | > postnet_diff_spec_loss: 0.46607  (0.46346)\n",
            "     | > decoder_ssim_loss: 0.90721  (0.90784)\n",
            "     | > postnet_ssim_loss: 0.83273  (0.85189)\n",
            "     | > loss: 2.39545  (2.45926)\n",
            "     | > align_error: 0.99018  (0.98382)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.49928  (2.46895)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.73520  (1.18791)\n",
            "     | > loader_time: 0.02110  (0.01576)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 266/406 -- GLOBAL_STEP: 5950\u001b[0m\n",
            "     | > decoder_loss: 3.42865  (3.43336)\n",
            "     | > postnet_loss: 2.58697  (2.56110)\n",
            "     | > stopnet_loss: 0.29228  (0.31669)\n",
            "     | > ga_loss: 0.00286  (0.00466)\n",
            "     | > decoder_diff_spec_loss: 0.24943  (0.24944)\n",
            "     | > postnet_diff_spec_loss: 0.46067  (0.46326)\n",
            "     | > decoder_ssim_loss: 0.90714  (0.90772)\n",
            "     | > postnet_ssim_loss: 0.83075  (0.85005)\n",
            "     | > loss: 2.42247  (2.45623)\n",
            "     | > align_error: 0.99006  (0.98440)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.47422  (2.47120)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.61180  (1.23930)\n",
            "     | > loader_time: 0.02210  (0.01639)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 291/406 -- GLOBAL_STEP: 5975\u001b[0m\n",
            "     | > decoder_loss: 3.34712  (3.43469)\n",
            "     | > postnet_loss: 2.57596  (2.56252)\n",
            "     | > stopnet_loss: 0.28578  (0.31448)\n",
            "     | > ga_loss: 0.00273  (0.00450)\n",
            "     | > decoder_diff_spec_loss: 0.25409  (0.24965)\n",
            "     | > postnet_diff_spec_loss: 0.46381  (0.46310)\n",
            "     | > decoder_ssim_loss: 0.90600  (0.90756)\n",
            "     | > postnet_ssim_loss: 0.83081  (0.84842)\n",
            "     | > loss: 2.39386  (2.45346)\n",
            "     | > align_error: 0.99085  (0.98492)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.48396  (2.47300)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.80450  (1.28737)\n",
            "     | > loader_time: 0.02360  (0.01702)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 316/406 -- GLOBAL_STEP: 6000\u001b[0m\n",
            "     | > decoder_loss: 3.46124  (3.43566)\n",
            "     | > postnet_loss: 2.59894  (2.56383)\n",
            "     | > stopnet_loss: 0.28449  (0.31225)\n",
            "     | > ga_loss: 0.00257  (0.00435)\n",
            "     | > decoder_diff_spec_loss: 0.25260  (0.24987)\n",
            "     | > postnet_diff_spec_loss: 0.46183  (0.46292)\n",
            "     | > decoder_ssim_loss: 0.90623  (0.90745)\n",
            "     | > postnet_ssim_loss: 0.82906  (0.84697)\n",
            "     | > loss: 2.42480  (2.45068)\n",
            "     | > align_error: 0.99108  (0.98538)\n",
            "     | > amp_scaler: 262144.00000  (131486.78481)\n",
            "     | > grad_norm: 2.50047  (2.47490)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.80690  (1.33314)\n",
            "     | > loader_time: 0.02420  (0.01763)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_6000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 341/406 -- GLOBAL_STEP: 6025\u001b[0m\n",
            "     | > decoder_loss: 3.54328  (3.43613)\n",
            "     | > postnet_loss: 2.62504  (2.56491)\n",
            "     | > stopnet_loss: 0.27701  (0.31009)\n",
            "     | > ga_loss: 0.00253  (0.00422)\n",
            "     | > decoder_diff_spec_loss: 0.25560  (0.25011)\n",
            "     | > postnet_diff_spec_loss: 0.46370  (0.46275)\n",
            "     | > decoder_ssim_loss: 0.90585  (0.90733)\n",
            "     | > postnet_ssim_loss: 0.83022  (0.84556)\n",
            "     | > loss: 2.44556  (2.44789)\n",
            "     | > align_error: 0.99139  (0.98580)\n",
            "     | > amp_scaler: 131072.00000  (131456.37537)\n",
            "     | > grad_norm: 2.50402  (2.46904)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.97610  (1.37767)\n",
            "     | > loader_time: 0.02570  (0.01837)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 366/406 -- GLOBAL_STEP: 6050\u001b[0m\n",
            "     | > decoder_loss: 3.52471  (3.43729)\n",
            "     | > postnet_loss: 2.59374  (2.56588)\n",
            "     | > stopnet_loss: 0.27256  (0.30787)\n",
            "     | > ga_loss: 0.00237  (0.00410)\n",
            "     | > decoder_diff_spec_loss: 0.25564  (0.25027)\n",
            "     | > postnet_diff_spec_loss: 0.46106  (0.46253)\n",
            "     | > decoder_ssim_loss: 0.90850  (0.90727)\n",
            "     | > postnet_ssim_loss: 0.82702  (0.84430)\n",
            "     | > loss: 2.42707  (2.44524)\n",
            "     | > align_error: 0.99178  (0.98619)\n",
            "     | > amp_scaler: 131072.00000  (131430.12022)\n",
            "     | > grad_norm: 2.49929  (2.47092)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91490  (1.41917)\n",
            "     | > loader_time: 0.02630  (0.01897)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 391/406 -- GLOBAL_STEP: 6075\u001b[0m\n",
            "     | > decoder_loss: 3.51229  (3.43703)\n",
            "     | > postnet_loss: 2.63118  (2.56650)\n",
            "     | > stopnet_loss: 0.27543  (0.30568)\n",
            "     | > ga_loss: 0.00229  (0.00398)\n",
            "     | > decoder_diff_spec_loss: 0.25292  (0.25047)\n",
            "     | > postnet_diff_spec_loss: 0.45863  (0.46236)\n",
            "     | > decoder_ssim_loss: 0.90549  (0.90717)\n",
            "     | > postnet_ssim_loss: 0.82496  (0.84310)\n",
            "     | > loss: 2.43327  (2.44225)\n",
            "     | > align_error: 0.99170  (0.98655)\n",
            "     | > amp_scaler: 131072.00000  (131407.22251)\n",
            "     | > grad_norm: 2.49414  (2.47239)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.16780  (1.46350)\n",
            "     | > loader_time: 0.02760  (0.01949)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01316 \u001b[0m(+0.00181)\n",
            "     | > avg_decoder_loss:\u001b[92m 3.43933 \u001b[0m(-0.18048)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.54635 \u001b[0m(-0.01523)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.30161 \u001b[0m(-0.05188)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00326 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.23897 \u001b[0m(+0.00539)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46250 \u001b[0m(-0.00066)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.86509 \u001b[0m(-0.00309)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.76805 \u001b[0m(-0.02229)\n",
            "     | > avg_loss:\u001b[92m 2.39801 \u001b[0m(-0.10601)\n",
            "     | > avg_align_error:\u001b[92m 0.98950 \u001b[0m(-0.00013)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_6090.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 15/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 10:29:02) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 10/406 -- GLOBAL_STEP: 6100\u001b[0m\n",
            "     | > decoder_loss: 3.04841  (3.07275)\n",
            "     | > postnet_loss: 2.54243  (2.54895)\n",
            "     | > stopnet_loss: 0.27760  (0.27554)\n",
            "     | > ga_loss: 0.01020  (0.01312)\n",
            "     | > decoder_diff_spec_loss: 0.25369  (0.25044)\n",
            "     | > postnet_diff_spec_loss: 0.46699  (0.46298)\n",
            "     | > decoder_ssim_loss: 0.90293  (0.90095)\n",
            "     | > postnet_ssim_loss: 0.87619  (0.87288)\n",
            "     | > loss: 2.35128  (2.36840)\n",
            "     | > align_error: 0.96508  (0.95924)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.42023  (2.42843)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.66170  (0.55913)\n",
            "     | > loader_time: 0.00810  (0.00809)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 35/406 -- GLOBAL_STEP: 6125\u001b[0m\n",
            "     | > decoder_loss: 3.19230  (3.09479)\n",
            "     | > postnet_loss: 2.56202  (2.53300)\n",
            "     | > stopnet_loss: 0.25610  (0.26922)\n",
            "     | > ga_loss: 0.00653  (0.00924)\n",
            "     | > decoder_diff_spec_loss: 0.25686  (0.25535)\n",
            "     | > postnet_diff_spec_loss: 0.46189  (0.46574)\n",
            "     | > decoder_ssim_loss: 0.90758  (0.90455)\n",
            "     | > postnet_ssim_loss: 0.87893  (0.87791)\n",
            "     | > loss: 2.35366  (2.34827)\n",
            "     | > align_error: 0.97889  (0.96995)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.47658  (2.44799)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.84200  (0.68987)\n",
            "     | > loader_time: 0.01080  (0.00920)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 60/406 -- GLOBAL_STEP: 6150\u001b[0m\n",
            "     | > decoder_loss: 3.22900  (3.11151)\n",
            "     | > postnet_loss: 2.52101  (2.52805)\n",
            "     | > stopnet_loss: 0.26594  (0.26579)\n",
            "     | > ga_loss: 0.00520  (0.00780)\n",
            "     | > decoder_diff_spec_loss: 0.26048  (0.25591)\n",
            "     | > postnet_diff_spec_loss: 0.47108  (0.46528)\n",
            "     | > decoder_ssim_loss: 0.90621  (0.90469)\n",
            "     | > postnet_ssim_loss: 0.87329  (0.87754)\n",
            "     | > loss: 2.35720  (2.34055)\n",
            "     | > align_error: 0.98090  (0.97417)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.44781  (2.45195)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.99210  (0.78213)\n",
            "     | > loader_time: 0.01650  (0.01041)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 85/406 -- GLOBAL_STEP: 6175\u001b[0m\n",
            "     | > decoder_loss: 3.34094  (3.14143)\n",
            "     | > postnet_loss: 2.57663  (2.53266)\n",
            "     | > stopnet_loss: 0.25282  (0.26314)\n",
            "     | > ga_loss: 0.00456  (0.00695)\n",
            "     | > decoder_diff_spec_loss: 0.25994  (0.25629)\n",
            "     | > postnet_diff_spec_loss: 0.46190  (0.46468)\n",
            "     | > decoder_ssim_loss: 0.90824  (0.90519)\n",
            "     | > postnet_ssim_loss: 0.82799  (0.87254)\n",
            "     | > loss: 2.36955  (2.34108)\n",
            "     | > align_error: 0.98443  (0.97673)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.47947  (2.45599)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.11680  (0.85704)\n",
            "     | > loader_time: 0.01470  (0.01157)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 110/406 -- GLOBAL_STEP: 6200\u001b[0m\n",
            "     | > decoder_loss: 3.25735  (3.15596)\n",
            "     | > postnet_loss: 2.59997  (2.53525)\n",
            "     | > stopnet_loss: 0.24345  (0.26023)\n",
            "     | > ga_loss: 0.00417  (0.00635)\n",
            "     | > decoder_diff_spec_loss: 0.25797  (0.25674)\n",
            "     | > postnet_diff_spec_loss: 0.46227  (0.46439)\n",
            "     | > decoder_ssim_loss: 0.90422  (0.90530)\n",
            "     | > postnet_ssim_loss: 0.82675  (0.86189)\n",
            "     | > loss: 2.34144  (2.33687)\n",
            "     | > align_error: 0.98588  (0.97863)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.46476  (2.45700)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.16830  (0.92399)\n",
            "     | > loader_time: 0.01610  (0.01248)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 135/406 -- GLOBAL_STEP: 6225\u001b[0m\n",
            "     | > decoder_loss: 3.32922  (3.17286)\n",
            "     | > postnet_loss: 2.59170  (2.53747)\n",
            "     | > stopnet_loss: 0.24085  (0.25776)\n",
            "     | > ga_loss: 0.00387  (0.00591)\n",
            "     | > decoder_diff_spec_loss: 0.25539  (0.25687)\n",
            "     | > postnet_diff_spec_loss: 0.45738  (0.46399)\n",
            "     | > decoder_ssim_loss: 0.90725  (0.90530)\n",
            "     | > postnet_ssim_loss: 0.82119  (0.85476)\n",
            "     | > loss: 2.35076  (2.33512)\n",
            "     | > align_error: 0.98664  (0.98000)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.45134  (2.45742)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.24810  (0.97588)\n",
            "     | > loader_time: 0.01730  (0.01325)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 160/406 -- GLOBAL_STEP: 6250\u001b[0m\n",
            "     | > decoder_loss: 3.24086  (3.18187)\n",
            "     | > postnet_loss: 2.56191  (2.53795)\n",
            "     | > stopnet_loss: 0.24485  (0.25561)\n",
            "     | > ga_loss: 0.00354  (0.00556)\n",
            "     | > decoder_diff_spec_loss: 0.25793  (0.25714)\n",
            "     | > postnet_diff_spec_loss: 0.46451  (0.46388)\n",
            "     | > decoder_ssim_loss: 0.90578  (0.90520)\n",
            "     | > postnet_ssim_loss: 0.82149  (0.84947)\n",
            "     | > loss: 2.32567  (2.33229)\n",
            "     | > align_error: 0.98703  (0.98107)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.44809  (2.45632)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.37600  (1.03047)\n",
            "     | > loader_time: 0.01860  (0.01402)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 185/406 -- GLOBAL_STEP: 6275\u001b[0m\n",
            "     | > decoder_loss: 3.22184  (3.18751)\n",
            "     | > postnet_loss: 2.58103  (2.53975)\n",
            "     | > stopnet_loss: 0.22974  (0.25322)\n",
            "     | > ga_loss: 0.00329  (0.00528)\n",
            "     | > decoder_diff_spec_loss: 0.26107  (0.25724)\n",
            "     | > postnet_diff_spec_loss: 0.46223  (0.46348)\n",
            "     | > decoder_ssim_loss: 0.90612  (0.90506)\n",
            "     | > postnet_ssim_loss: 0.82169  (0.84540)\n",
            "     | > loss: 2.30970  (2.32921)\n",
            "     | > align_error: 0.98913  (0.98197)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.44708  (2.45461)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.42320  (1.08117)\n",
            "     | > loader_time: 0.01920  (0.01478)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 210/406 -- GLOBAL_STEP: 6300\u001b[0m\n",
            "     | > decoder_loss: 3.22503  (3.19304)\n",
            "     | > postnet_loss: 2.55996  (2.54173)\n",
            "     | > stopnet_loss: 0.23297  (0.25075)\n",
            "     | > ga_loss: 0.00309  (0.00504)\n",
            "     | > decoder_diff_spec_loss: 0.25972  (0.25750)\n",
            "     | > postnet_diff_spec_loss: 0.46415  (0.46317)\n",
            "     | > decoder_ssim_loss: 0.90684  (0.90502)\n",
            "     | > postnet_ssim_loss: 0.81939  (0.84209)\n",
            "     | > loss: 2.30717  (2.32656)\n",
            "     | > align_error: 0.98883  (0.98276)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.42477  (2.45292)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.68520  (1.12791)\n",
            "     | > loader_time: 0.02080  (0.01542)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 235/406 -- GLOBAL_STEP: 6325\u001b[0m\n",
            "     | > decoder_loss: 3.25271  (3.19738)\n",
            "     | > postnet_loss: 2.56105  (2.54390)\n",
            "     | > stopnet_loss: 0.22508  (0.24837)\n",
            "     | > ga_loss: 0.00302  (0.00483)\n",
            "     | > decoder_diff_spec_loss: 0.26210  (0.25769)\n",
            "     | > postnet_diff_spec_loss: 0.46416  (0.46295)\n",
            "     | > decoder_ssim_loss: 0.90556  (0.90499)\n",
            "     | > postnet_ssim_loss: 0.81646  (0.83931)\n",
            "     | > loss: 2.30567  (2.32406)\n",
            "     | > align_error: 0.98946  (0.98343)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.43747  (2.45075)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.58530  (1.17766)\n",
            "     | > loader_time: 0.02180  (0.01606)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 260/406 -- GLOBAL_STEP: 6350\u001b[0m\n",
            "     | > decoder_loss: 3.18941  (3.19904)\n",
            "     | > postnet_loss: 2.55060  (2.54531)\n",
            "     | > stopnet_loss: 0.22301  (0.24602)\n",
            "     | > ga_loss: 0.00280  (0.00464)\n",
            "     | > decoder_diff_spec_loss: 0.25676  (0.25785)\n",
            "     | > postnet_diff_spec_loss: 0.45802  (0.46269)\n",
            "     | > decoder_ssim_loss: 0.90187  (0.90493)\n",
            "     | > postnet_ssim_loss: 0.81115  (0.83685)\n",
            "     | > loss: 2.27896  (2.32090)\n",
            "     | > align_error: 0.98981  (0.98403)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.41644  (2.44845)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.58400  (1.22873)\n",
            "     | > loader_time: 0.02260  (0.01667)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 285/406 -- GLOBAL_STEP: 6375\u001b[0m\n",
            "     | > decoder_loss: 3.15225  (3.19908)\n",
            "     | > postnet_loss: 2.54002  (2.54677)\n",
            "     | > stopnet_loss: 0.22249  (0.24376)\n",
            "     | > ga_loss: 0.00274  (0.00448)\n",
            "     | > decoder_diff_spec_loss: 0.26049  (0.25804)\n",
            "     | > postnet_diff_spec_loss: 0.46446  (0.46254)\n",
            "     | > decoder_ssim_loss: 0.90313  (0.90480)\n",
            "     | > postnet_ssim_loss: 0.81107  (0.83474)\n",
            "     | > loss: 2.26905  (2.31765)\n",
            "     | > align_error: 0.98980  (0.98455)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.40674  (2.44545)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.88720  (1.27642)\n",
            "     | > loader_time: 0.03000  (0.01733)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 310/406 -- GLOBAL_STEP: 6400\u001b[0m\n",
            "     | > decoder_loss: 3.05810  (3.19799)\n",
            "     | > postnet_loss: 2.52119  (2.54812)\n",
            "     | > stopnet_loss: 0.21289  (0.24149)\n",
            "     | > ga_loss: 0.00249  (0.00433)\n",
            "     | > decoder_diff_spec_loss: 0.26677  (0.25822)\n",
            "     | > postnet_diff_spec_loss: 0.46742  (0.46234)\n",
            "     | > decoder_ssim_loss: 0.90220  (0.90469)\n",
            "     | > postnet_ssim_loss: 0.81206  (0.83287)\n",
            "     | > loss: 2.23229  (2.31421)\n",
            "     | > align_error: 0.99104  (0.98503)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.39494  (2.44259)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.87340  (1.32058)\n",
            "     | > loader_time: 0.02460  (0.01792)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 335/406 -- GLOBAL_STEP: 6425\u001b[0m\n",
            "     | > decoder_loss: 3.27162  (3.19731)\n",
            "     | > postnet_loss: 2.55555  (2.54887)\n",
            "     | > stopnet_loss: 0.21556  (0.23937)\n",
            "     | > ga_loss: 0.00256  (0.00420)\n",
            "     | > decoder_diff_spec_loss: 0.25571  (0.25839)\n",
            "     | > postnet_diff_spec_loss: 0.45588  (0.46218)\n",
            "     | > decoder_ssim_loss: 0.90137  (0.90459)\n",
            "     | > postnet_ssim_loss: 0.80404  (0.83107)\n",
            "     | > loss: 2.28939  (2.31097)\n",
            "     | > align_error: 0.99005  (0.98545)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.40363  (2.43941)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.97370  (1.36473)\n",
            "     | > loader_time: 0.02550  (0.01849)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 360/406 -- GLOBAL_STEP: 6450\u001b[0m\n",
            "     | > decoder_loss: 3.09940  (3.19638)\n",
            "     | > postnet_loss: 2.54807  (2.54949)\n",
            "     | > stopnet_loss: 0.20475  (0.23708)\n",
            "     | > ga_loss: 0.00239  (0.00408)\n",
            "     | > decoder_diff_spec_loss: 0.26085  (0.25854)\n",
            "     | > postnet_diff_spec_loss: 0.45997  (0.46195)\n",
            "     | > decoder_ssim_loss: 0.90183  (0.90452)\n",
            "     | > postnet_ssim_loss: 0.80634  (0.82950)\n",
            "     | > loss: 2.23583  (2.30757)\n",
            "     | > align_error: 0.99155  (0.98585)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.38975  (2.43605)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.09150  (1.40964)\n",
            "     | > loader_time: 0.02980  (0.01906)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 385/406 -- GLOBAL_STEP: 6475\u001b[0m\n",
            "     | > decoder_loss: 3.15041  (3.19462)\n",
            "     | > postnet_loss: 2.57134  (2.55037)\n",
            "     | > stopnet_loss: 0.19868  (0.23491)\n",
            "     | > ga_loss: 0.00224  (0.00396)\n",
            "     | > decoder_diff_spec_loss: 0.26316  (0.25871)\n",
            "     | > postnet_diff_spec_loss: 0.45907  (0.46179)\n",
            "     | > decoder_ssim_loss: 0.90401  (0.90446)\n",
            "     | > postnet_ssim_loss: 0.80631  (0.82801)\n",
            "     | > loss: 2.24846  (2.30422)\n",
            "     | > align_error: 0.99208  (0.98621)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.37854  (2.43237)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.99940  (1.45133)\n",
            "     | > loader_time: 0.02750  (0.01964)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01352 \u001b[0m(+0.00036)\n",
            "     | > avg_decoder_loss:\u001b[92m 3.25328 \u001b[0m(-0.18605)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.52945 \u001b[0m(-0.01691)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.25267 \u001b[0m(-0.04894)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00328 \u001b[0m(+0.00002)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.24305 \u001b[0m(+0.00408)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46190 \u001b[0m(-0.00060)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.86250 \u001b[0m(-0.00260)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.74984 \u001b[0m(-0.01821)\n",
            "     | > avg_loss:\u001b[92m 2.29409 \u001b[0m(-0.10392)\n",
            "     | > avg_align_error:\u001b[92m 0.98938 \u001b[0m(-0.00012)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_6496.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 16/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 10:49:59) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 4/406 -- GLOBAL_STEP: 6500\u001b[0m\n",
            "     | > decoder_loss: 2.70946  (2.85173)\n",
            "     | > postnet_loss: 2.48045  (2.55011)\n",
            "     | > stopnet_loss: 0.19934  (0.20608)\n",
            "     | > ga_loss: 0.01412  (0.01568)\n",
            "     | > decoder_diff_spec_loss: 0.25835  (0.25598)\n",
            "     | > postnet_diff_spec_loss: 0.46326  (0.45969)\n",
            "     | > decoder_ssim_loss: 0.89454  (0.89508)\n",
            "     | > postnet_ssim_loss: 0.87109  (0.86585)\n",
            "     | > loss: 2.18920  (2.25410)\n",
            "     | > align_error: 0.95816  (0.95209)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.26058  (2.27707)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.54570  (0.61321)\n",
            "     | > loader_time: 0.00670  (0.00941)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 29/406 -- GLOBAL_STEP: 6525\u001b[0m\n",
            "     | > decoder_loss: 2.82934  (2.84133)\n",
            "     | > postnet_loss: 2.51873  (2.52177)\n",
            "     | > stopnet_loss: 0.19106  (0.20000)\n",
            "     | > ga_loss: 0.00681  (0.00961)\n",
            "     | > decoder_diff_spec_loss: 0.27401  (0.26347)\n",
            "     | > postnet_diff_spec_loss: 0.47048  (0.46542)\n",
            "     | > decoder_ssim_loss: 0.90439  (0.90147)\n",
            "     | > postnet_ssim_loss: 0.86853  (0.87317)\n",
            "     | > loss: 2.19151  (2.21469)\n",
            "     | > align_error: 0.97697  (0.96793)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.30384  (2.30020)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.80430  (0.67366)\n",
            "     | > loader_time: 0.01010  (0.00899)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 54/406 -- GLOBAL_STEP: 6550\u001b[0m\n",
            "     | > decoder_loss: 2.88482  (2.84949)\n",
            "     | > postnet_loss: 2.49937  (2.51203)\n",
            "     | > stopnet_loss: 0.19145  (0.19661)\n",
            "     | > ga_loss: 0.00534  (0.00793)\n",
            "     | > decoder_diff_spec_loss: 0.26543  (0.26358)\n",
            "     | > postnet_diff_spec_loss: 0.46661  (0.46453)\n",
            "     | > decoder_ssim_loss: 0.89849  (0.90184)\n",
            "     | > postnet_ssim_loss: 0.86998  (0.87329)\n",
            "     | > loss: 2.18931  (2.20246)\n",
            "     | > align_error: 0.98026  (0.97298)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.31396  (2.30509)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.94070  (0.75876)\n",
            "     | > loader_time: 0.01520  (0.01017)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 79/406 -- GLOBAL_STEP: 6575\u001b[0m\n",
            "     | > decoder_loss: 2.97019  (2.87763)\n",
            "     | > postnet_loss: 2.50644  (2.51494)\n",
            "     | > stopnet_loss: 0.18964  (0.19391)\n",
            "     | > ga_loss: 0.00474  (0.00700)\n",
            "     | > decoder_diff_spec_loss: 0.26370  (0.26386)\n",
            "     | > postnet_diff_spec_loss: 0.46531  (0.46424)\n",
            "     | > decoder_ssim_loss: 0.90009  (0.90221)\n",
            "     | > postnet_ssim_loss: 0.80797  (0.87116)\n",
            "     | > loss: 2.19177  (2.20240)\n",
            "     | > align_error: 0.98233  (0.97580)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.31031  (2.30398)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.03170  (0.83862)\n",
            "     | > loader_time: 0.01780  (0.01140)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 104/406 -- GLOBAL_STEP: 6600\u001b[0m\n",
            "     | > decoder_loss: 2.92185  (2.89522)\n",
            "     | > postnet_loss: 2.50626  (2.51910)\n",
            "     | > stopnet_loss: 0.17685  (0.19099)\n",
            "     | > ga_loss: 0.00410  (0.00637)\n",
            "     | > decoder_diff_spec_loss: 0.26886  (0.26409)\n",
            "     | > postnet_diff_spec_loss: 0.46186  (0.46356)\n",
            "     | > decoder_ssim_loss: 0.90316  (0.90260)\n",
            "     | > postnet_ssim_loss: 0.80962  (0.85617)\n",
            "     | > loss: 2.16526  (2.19801)\n",
            "     | > align_error: 0.98603  (0.97786)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.29094  (2.30081)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.12040  (0.90597)\n",
            "     | > loader_time: 0.01590  (0.01234)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 129/406 -- GLOBAL_STEP: 6625\u001b[0m\n",
            "     | > decoder_loss: 2.93355  (2.90623)\n",
            "     | > postnet_loss: 2.51728  (2.52010)\n",
            "     | > stopnet_loss: 0.18299  (0.18862)\n",
            "     | > ga_loss: 0.00386  (0.00590)\n",
            "     | > decoder_diff_spec_loss: 0.26230  (0.26424)\n",
            "     | > postnet_diff_spec_loss: 0.46373  (0.46345)\n",
            "     | > decoder_ssim_loss: 0.90281  (0.90264)\n",
            "     | > postnet_ssim_loss: 0.80202  (0.84628)\n",
            "     | > loss: 2.17273  (2.19388)\n",
            "     | > align_error: 0.98485  (0.97934)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.27833  (2.29632)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.22150  (0.96701)\n",
            "     | > loader_time: 0.01660  (0.01314)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 154/406 -- GLOBAL_STEP: 6650\u001b[0m\n",
            "     | > decoder_loss: 2.89759  (2.91698)\n",
            "     | > postnet_loss: 2.51283  (2.52081)\n",
            "     | > stopnet_loss: 0.17810  (0.18657)\n",
            "     | > ga_loss: 0.00342  (0.00555)\n",
            "     | > decoder_diff_spec_loss: 0.26647  (0.26428)\n",
            "     | > postnet_diff_spec_loss: 0.46637  (0.46323)\n",
            "     | > decoder_ssim_loss: 0.89971  (0.90261)\n",
            "     | > postnet_ssim_loss: 0.80252  (0.83911)\n",
            "     | > loss: 2.15658  (2.19106)\n",
            "     | > align_error: 0.98667  (0.98045)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.25770  (2.29119)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.33370  (1.01932)\n",
            "     | > loader_time: 0.01730  (0.01382)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 179/406 -- GLOBAL_STEP: 6675\u001b[0m\n",
            "     | > decoder_loss: 3.02602  (2.92167)\n",
            "     | > postnet_loss: 2.55868  (2.52233)\n",
            "     | > stopnet_loss: 0.17172  (0.18452)\n",
            "     | > ga_loss: 0.00328  (0.00525)\n",
            "     | > decoder_diff_spec_loss: 0.26250  (0.26425)\n",
            "     | > postnet_diff_spec_loss: 0.45736  (0.46286)\n",
            "     | > decoder_ssim_loss: 0.90360  (0.90252)\n",
            "     | > postnet_ssim_loss: 0.79975  (0.83364)\n",
            "     | > loss: 2.19012  (2.18760)\n",
            "     | > align_error: 0.98734  (0.98137)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.24682  (2.28570)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.48980  (1.07259)\n",
            "     | > loader_time: 0.01870  (0.01445)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 204/406 -- GLOBAL_STEP: 6700\u001b[0m\n",
            "     | > decoder_loss: 2.93647  (2.92428)\n",
            "     | > postnet_loss: 2.51071  (2.52378)\n",
            "     | > stopnet_loss: 0.16702  (0.18217)\n",
            "     | > ga_loss: 0.00312  (0.00501)\n",
            "     | > decoder_diff_spec_loss: 0.26249  (0.26434)\n",
            "     | > postnet_diff_spec_loss: 0.46017  (0.46249)\n",
            "     | > decoder_ssim_loss: 0.90168  (0.90246)\n",
            "     | > postnet_ssim_loss: 0.79916  (0.82932)\n",
            "     | > loss: 2.15028  (2.18388)\n",
            "     | > align_error: 0.98818  (0.98219)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.22726  (2.27897)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.42040  (1.11706)\n",
            "     | > loader_time: 0.01980  (0.01511)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 229/406 -- GLOBAL_STEP: 6725\u001b[0m\n",
            "     | > decoder_loss: 2.90589  (2.92858)\n",
            "     | > postnet_loss: 2.53803  (2.52566)\n",
            "     | > stopnet_loss: 0.16696  (0.18009)\n",
            "     | > ga_loss: 0.00296  (0.00480)\n",
            "     | > decoder_diff_spec_loss: 0.26326  (0.26440)\n",
            "     | > postnet_diff_spec_loss: 0.46095  (0.46228)\n",
            "     | > decoder_ssim_loss: 0.90131  (0.90243)\n",
            "     | > postnet_ssim_loss: 0.79666  (0.82580)\n",
            "     | > loss: 2.14828  (2.18137)\n",
            "     | > align_error: 0.98836  (0.98287)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.22245  (2.27240)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.66780  (1.16378)\n",
            "     | > loader_time: 0.02120  (0.01582)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 254/406 -- GLOBAL_STEP: 6750\u001b[0m\n",
            "     | > decoder_loss: 2.90406  (2.92915)\n",
            "     | > postnet_loss: 2.49992  (2.52774)\n",
            "     | > stopnet_loss: 0.15948  (0.17787)\n",
            "     | > ga_loss: 0.00282  (0.00461)\n",
            "     | > decoder_diff_spec_loss: 0.26864  (0.26452)\n",
            "     | > postnet_diff_spec_loss: 0.46463  (0.46205)\n",
            "     | > decoder_ssim_loss: 0.90242  (0.90243)\n",
            "     | > postnet_ssim_loss: 0.79566  (0.82278)\n",
            "     | > loss: 2.13240  (2.17810)\n",
            "     | > align_error: 0.98900  (0.98349)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.20537  (2.26544)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.77890  (1.21535)\n",
            "     | > loader_time: 0.02220  (0.01641)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 279/406 -- GLOBAL_STEP: 6775\u001b[0m\n",
            "     | > decoder_loss: 2.89068  (2.92698)\n",
            "     | > postnet_loss: 2.51842  (2.52870)\n",
            "     | > stopnet_loss: 0.15858  (0.17576)\n",
            "     | > ga_loss: 0.00279  (0.00445)\n",
            "     | > decoder_diff_spec_loss: 0.26429  (0.26458)\n",
            "     | > postnet_diff_spec_loss: 0.46093  (0.46184)\n",
            "     | > decoder_ssim_loss: 0.90269  (0.90230)\n",
            "     | > postnet_ssim_loss: 0.78994  (0.82018)\n",
            "     | > loss: 2.12927  (2.17414)\n",
            "     | > align_error: 0.98907  (0.98404)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.19153  (2.25812)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.70890  (1.26183)\n",
            "     | > loader_time: 0.02250  (0.01698)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 304/406 -- GLOBAL_STEP: 6800\u001b[0m\n",
            "     | > decoder_loss: 2.89660  (2.92625)\n",
            "     | > postnet_loss: 2.54502  (2.53032)\n",
            "     | > stopnet_loss: 0.15396  (0.17371)\n",
            "     | > ga_loss: 0.00258  (0.00430)\n",
            "     | > decoder_diff_spec_loss: 0.26474  (0.26463)\n",
            "     | > postnet_diff_spec_loss: 0.46422  (0.46162)\n",
            "     | > decoder_ssim_loss: 0.90107  (0.90222)\n",
            "     | > postnet_ssim_loss: 0.79331  (0.81789)\n",
            "     | > loss: 2.13308  (2.17095)\n",
            "     | > align_error: 0.98969  (0.98453)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.16961  (2.25095)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.73800  (1.30841)\n",
            "     | > loader_time: 0.02370  (0.01758)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 329/406 -- GLOBAL_STEP: 6825\u001b[0m\n",
            "     | > decoder_loss: 2.87434  (2.92325)\n",
            "     | > postnet_loss: 2.54653  (2.53064)\n",
            "     | > stopnet_loss: 0.14926  (0.17179)\n",
            "     | > ga_loss: 0.00246  (0.00417)\n",
            "     | > decoder_diff_spec_loss: 0.26243  (0.26473)\n",
            "     | > postnet_diff_spec_loss: 0.45626  (0.46148)\n",
            "     | > decoder_ssim_loss: 0.90569  (0.90212)\n",
            "     | > postnet_ssim_loss: 0.79203  (0.81577)\n",
            "     | > loss: 2.12089  (2.16712)\n",
            "     | > align_error: 0.99022  (0.98496)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.15049  (2.24380)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.01580  (1.35546)\n",
            "     | > loader_time: 0.02440  (0.01812)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 354/406 -- GLOBAL_STEP: 6850\u001b[0m\n",
            "     | > decoder_loss: 2.83796  (2.92108)\n",
            "     | > postnet_loss: 2.53645  (2.53146)\n",
            "     | > stopnet_loss: 0.14445  (0.16980)\n",
            "     | > ga_loss: 0.00238  (0.00405)\n",
            "     | > decoder_diff_spec_loss: 0.26179  (0.26477)\n",
            "     | > postnet_diff_spec_loss: 0.45755  (0.46126)\n",
            "     | > decoder_ssim_loss: 0.89856  (0.90203)\n",
            "     | > postnet_ssim_loss: 0.79103  (0.81390)\n",
            "     | > loss: 2.10220  (2.16365)\n",
            "     | > align_error: 0.99058  (0.98536)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.12100  (2.23640)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.02300  (1.40128)\n",
            "     | > loader_time: 0.02580  (0.01867)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 379/406 -- GLOBAL_STEP: 6875\u001b[0m\n",
            "     | > decoder_loss: 2.83575  (2.91879)\n",
            "     | > postnet_loss: 2.52213  (2.53224)\n",
            "     | > stopnet_loss: 0.13704  (0.16786)\n",
            "     | > ga_loss: 0.00228  (0.00393)\n",
            "     | > decoder_diff_spec_loss: 0.26374  (0.26479)\n",
            "     | > postnet_diff_spec_loss: 0.46067  (0.46106)\n",
            "     | > decoder_ssim_loss: 0.89981  (0.90197)\n",
            "     | > postnet_ssim_loss: 0.78846  (0.81227)\n",
            "     | > loss: 2.09109  (2.16030)\n",
            "     | > align_error: 0.99133  (0.98573)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.10158  (2.22881)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.09080  (1.44511)\n",
            "     | > loader_time: 0.02680  (0.01918)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 404/406 -- GLOBAL_STEP: 6900\u001b[0m\n",
            "     | > decoder_loss: 2.88260  (2.91614)\n",
            "     | > postnet_loss: 2.56924  (2.53286)\n",
            "     | > stopnet_loss: 0.13965  (0.16596)\n",
            "     | > ga_loss: 0.00223  (0.00383)\n",
            "     | > decoder_diff_spec_loss: 0.26470  (0.26487)\n",
            "     | > postnet_diff_spec_loss: 0.45708  (0.46090)\n",
            "     | > decoder_ssim_loss: 0.90211  (0.90193)\n",
            "     | > postnet_ssim_loss: 0.78305  (0.81069)\n",
            "     | > loss: 2.11548  (2.15694)\n",
            "     | > align_error: 0.99088  (0.98608)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.11522  (2.22133)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.88320  (1.48310)\n",
            "     | > loader_time: 0.02820  (0.01974)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01245 \u001b[0m(-0.00107)\n",
            "     | > avg_decoder_loss:\u001b[92m 3.08955 \u001b[0m(-0.16374)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.51189 \u001b[0m(-0.01756)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.21284 \u001b[0m(-0.03984)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00331 \u001b[0m(+0.00003)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.24430 \u001b[0m(+0.00125)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46172 \u001b[0m(-0.00019)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.86039 \u001b[0m(-0.00210)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.74911 \u001b[0m(-0.00073)\n",
            "     | > avg_loss:\u001b[92m 2.20863 \u001b[0m(-0.08546)\n",
            "     | > avg_align_error:\u001b[92m 0.98932 \u001b[0m(-0.00006)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_6902.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 17/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 11:10:55) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 23/406 -- GLOBAL_STEP: 6925\u001b[0m\n",
            "     | > decoder_loss: 2.57178  (2.56087)\n",
            "     | > postnet_loss: 2.49693  (2.50314)\n",
            "     | > stopnet_loss: 0.13084  (0.13981)\n",
            "     | > ga_loss: 0.00726  (0.01005)\n",
            "     | > decoder_diff_spec_loss: 0.26936  (0.26727)\n",
            "     | > postnet_diff_spec_loss: 0.46223  (0.46466)\n",
            "     | > decoder_ssim_loss: 0.89771  (0.89816)\n",
            "     | > postnet_ssim_loss: 0.86952  (0.86786)\n",
            "     | > loss: 2.05904  (2.08054)\n",
            "     | > align_error: 0.97438  (0.96535)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.98456  (2.00623)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.73580  (0.59794)\n",
            "     | > loader_time: 0.00970  (0.00824)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 48/406 -- GLOBAL_STEP: 6950\u001b[0m\n",
            "     | > decoder_loss: 2.63703  (2.56936)\n",
            "     | > postnet_loss: 2.47377  (2.49274)\n",
            "     | > stopnet_loss: 0.13500  (0.13627)\n",
            "     | > ga_loss: 0.00557  (0.00804)\n",
            "     | > decoder_diff_spec_loss: 0.26375  (0.26768)\n",
            "     | > postnet_diff_spec_loss: 0.46136  (0.46411)\n",
            "     | > decoder_ssim_loss: 0.89719  (0.89902)\n",
            "     | > postnet_ssim_loss: 0.87157  (0.86801)\n",
            "     | > loss: 2.06400  (2.06672)\n",
            "     | > align_error: 0.97796  (0.97144)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.02743  (2.00902)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.89860  (0.71845)\n",
            "     | > loader_time: 0.01150  (0.00950)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 73/406 -- GLOBAL_STEP: 6975\u001b[0m\n",
            "     | > decoder_loss: 2.66940  (2.59406)\n",
            "     | > postnet_loss: 2.49508  (2.49487)\n",
            "     | > stopnet_loss: 0.12718  (0.13359)\n",
            "     | > ga_loss: 0.00460  (0.00703)\n",
            "     | > decoder_diff_spec_loss: 0.26413  (0.26769)\n",
            "     | > postnet_diff_spec_loss: 0.45983  (0.46356)\n",
            "     | > decoder_ssim_loss: 0.90120  (0.89934)\n",
            "     | > postnet_ssim_loss: 0.86847  (0.86730)\n",
            "     | > loss: 2.06472  (2.06543)\n",
            "     | > align_error: 0.98229  (0.97466)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 2.01075  (2.00784)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.02140  (0.81133)\n",
            "     | > loader_time: 0.01380  (0.01067)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 98/406 -- GLOBAL_STEP: 7000\u001b[0m\n",
            "     | > decoder_loss: 2.62623  (2.60973)\n",
            "     | > postnet_loss: 2.49227  (2.49917)\n",
            "     | > stopnet_loss: 0.12050  (0.13111)\n",
            "     | > ga_loss: 0.00413  (0.00636)\n",
            "     | > decoder_diff_spec_loss: 0.26813  (0.26763)\n",
            "     | > postnet_diff_spec_loss: 0.45906  (0.46286)\n",
            "     | > decoder_ssim_loss: 0.90212  (0.89979)\n",
            "     | > postnet_ssim_loss: 0.78811  (0.85102)\n",
            "     | > loss: 2.02514  (2.06048)\n",
            "     | > align_error: 0.98483  (0.97686)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.97479  (2.00343)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.14070  (0.88049)\n",
            "     | > loader_time: 0.01530  (0.01180)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_7000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 123/406 -- GLOBAL_STEP: 7025\u001b[0m\n",
            "     | > decoder_loss: 2.73800  (2.61927)\n",
            "     | > postnet_loss: 2.51182  (2.49978)\n",
            "     | > stopnet_loss: 0.11571  (0.12900)\n",
            "     | > ga_loss: 0.00393  (0.00588)\n",
            "     | > decoder_diff_spec_loss: 0.26881  (0.26761)\n",
            "     | > postnet_diff_spec_loss: 0.46007  (0.46274)\n",
            "     | > decoder_ssim_loss: 0.90136  (0.89983)\n",
            "     | > postnet_ssim_loss: 0.78284  (0.83804)\n",
            "     | > loss: 2.05107  (2.05523)\n",
            "     | > align_error: 0.98557  (0.97846)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.96187  (1.99686)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.25100  (0.93948)\n",
            "     | > loader_time: 0.01620  (0.01282)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 148/406 -- GLOBAL_STEP: 7050\u001b[0m\n",
            "     | > decoder_loss: 2.70781  (2.63136)\n",
            "     | > postnet_loss: 2.52769  (2.50155)\n",
            "     | > stopnet_loss: 0.11412  (0.12730)\n",
            "     | > ga_loss: 0.00366  (0.00552)\n",
            "     | > decoder_diff_spec_loss: 0.26762  (0.26740)\n",
            "     | > postnet_diff_spec_loss: 0.45988  (0.46240)\n",
            "     | > decoder_ssim_loss: 0.90229  (0.89986)\n",
            "     | > postnet_ssim_loss: 0.78487  (0.82872)\n",
            "     | > loss: 2.04494  (2.05270)\n",
            "     | > align_error: 0.98579  (0.97962)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.93930  (1.99119)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.33520  (0.99476)\n",
            "     | > loader_time: 0.02150  (0.01354)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 173/406 -- GLOBAL_STEP: 7075\u001b[0m\n",
            "     | > decoder_loss: 2.66722  (2.63401)\n",
            "     | > postnet_loss: 2.51696  (2.50237)\n",
            "     | > stopnet_loss: 0.10888  (0.12558)\n",
            "     | > ga_loss: 0.00343  (0.00522)\n",
            "     | > decoder_diff_spec_loss: 0.26829  (0.26722)\n",
            "     | > postnet_diff_spec_loss: 0.46096  (0.46218)\n",
            "     | > decoder_ssim_loss: 0.90233  (0.89968)\n",
            "     | > postnet_ssim_loss: 0.78375  (0.82188)\n",
            "     | > loss: 2.02592  (2.04850)\n",
            "     | > align_error: 0.98707  (0.98059)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.90267  (1.98301)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.33260  (1.04504)\n",
            "     | > loader_time: 0.01860  (0.01418)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 198/406 -- GLOBAL_STEP: 7100\u001b[0m\n",
            "     | > decoder_loss: 2.69985  (2.63590)\n",
            "     | > postnet_loss: 2.53379  (2.50401)\n",
            "     | > stopnet_loss: 0.11079  (0.12366)\n",
            "     | > ga_loss: 0.00317  (0.00497)\n",
            "     | > decoder_diff_spec_loss: 0.26450  (0.26705)\n",
            "     | > postnet_diff_spec_loss: 0.45589  (0.46170)\n",
            "     | > decoder_ssim_loss: 0.89953  (0.89964)\n",
            "     | > postnet_ssim_loss: 0.78248  (0.81663)\n",
            "     | > loss: 2.03564  (2.04475)\n",
            "     | > align_error: 0.98741  (0.98145)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.92179  (1.97432)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.50590  (1.09487)\n",
            "     | > loader_time: 0.02010  (0.01482)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 223/406 -- GLOBAL_STEP: 7125\u001b[0m\n",
            "     | > decoder_loss: 2.60809  (2.63860)\n",
            "     | > postnet_loss: 2.51624  (2.50542)\n",
            "     | > stopnet_loss: 0.10787  (0.12193)\n",
            "     | > ga_loss: 0.00297  (0.00476)\n",
            "     | > decoder_diff_spec_loss: 0.27158  (0.26699)\n",
            "     | > postnet_diff_spec_loss: 0.46623  (0.46152)\n",
            "     | > decoder_ssim_loss: 0.89984  (0.89960)\n",
            "     | > postnet_ssim_loss: 0.77602  (0.81243)\n",
            "     | > loss: 2.00721  (2.04185)\n",
            "     | > align_error: 0.98804  (0.98217)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.89298  (1.96609)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.53190  (1.14400)\n",
            "     | > loader_time: 0.02690  (0.01544)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 248/406 -- GLOBAL_STEP: 7150\u001b[0m\n",
            "     | > decoder_loss: 2.58173  (2.63834)\n",
            "     | > postnet_loss: 2.51080  (2.50726)\n",
            "     | > stopnet_loss: 0.10522  (0.12017)\n",
            "     | > ga_loss: 0.00286  (0.00457)\n",
            "     | > decoder_diff_spec_loss: 0.26478  (0.26691)\n",
            "     | > postnet_diff_spec_loss: 0.46137  (0.46129)\n",
            "     | > decoder_ssim_loss: 0.89912  (0.89959)\n",
            "     | > postnet_ssim_loss: 0.77960  (0.80892)\n",
            "     | > loss: 1.99385  (2.03860)\n",
            "     | > align_error: 0.98862  (0.98281)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.87325  (1.95725)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.90030  (1.19587)\n",
            "     | > loader_time: 0.02090  (0.01607)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 273/406 -- GLOBAL_STEP: 7175\u001b[0m\n",
            "     | > decoder_loss: 2.61393  (2.63602)\n",
            "     | > postnet_loss: 2.51848  (2.50808)\n",
            "     | > stopnet_loss: 0.10012  (0.11847)\n",
            "     | > ga_loss: 0.00268  (0.00441)\n",
            "     | > decoder_diff_spec_loss: 0.26834  (0.26679)\n",
            "     | > postnet_diff_spec_loss: 0.46116  (0.46103)\n",
            "     | > decoder_ssim_loss: 0.89714  (0.89945)\n",
            "     | > postnet_ssim_loss: 0.77518  (0.80589)\n",
            "     | > loss: 1.99708  (2.03482)\n",
            "     | > align_error: 0.98944  (0.98337)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.85848  (1.94829)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.76020  (1.24340)\n",
            "     | > loader_time: 0.02290  (0.01668)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 298/406 -- GLOBAL_STEP: 7200\u001b[0m\n",
            "     | > decoder_loss: 2.55028  (2.63386)\n",
            "     | > postnet_loss: 2.51283  (2.50920)\n",
            "     | > stopnet_loss: 0.09707  (0.11686)\n",
            "     | > ga_loss: 0.00257  (0.00426)\n",
            "     | > decoder_diff_spec_loss: 0.26799  (0.26667)\n",
            "     | > postnet_diff_spec_loss: 0.45953  (0.46085)\n",
            "     | > decoder_ssim_loss: 0.89916  (0.89935)\n",
            "     | > postnet_ssim_loss: 0.77758  (0.80334)\n",
            "     | > loss: 1.97675  (2.03148)\n",
            "     | > align_error: 0.98972  (0.98387)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.82607  (1.93934)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.88360  (1.29183)\n",
            "     | > loader_time: 0.02380  (0.01731)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 323/406 -- GLOBAL_STEP: 7225\u001b[0m\n",
            "     | > decoder_loss: 2.63063  (2.63043)\n",
            "     | > postnet_loss: 2.54537  (2.50971)\n",
            "     | > stopnet_loss: 0.09657  (0.11529)\n",
            "     | > ga_loss: 0.00245  (0.00413)\n",
            "     | > decoder_diff_spec_loss: 0.26610  (0.26656)\n",
            "     | > postnet_diff_spec_loss: 0.45993  (0.46070)\n",
            "     | > decoder_ssim_loss: 0.89970  (0.89925)\n",
            "     | > postnet_ssim_loss: 0.77381  (0.80100)\n",
            "     | > loss: 2.00272  (2.02783)\n",
            "     | > align_error: 0.98963  (0.98432)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.82140  (1.93027)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.92840  (1.33564)\n",
            "     | > loader_time: 0.02430  (0.01787)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 348/406 -- GLOBAL_STEP: 7250\u001b[0m\n",
            "     | > decoder_loss: 2.53346  (2.62742)\n",
            "     | > postnet_loss: 2.52337  (2.51050)\n",
            "     | > stopnet_loss: 0.08864  (0.11371)\n",
            "     | > ga_loss: 0.00243  (0.00401)\n",
            "     | > decoder_diff_spec_loss: 0.26527  (0.26644)\n",
            "     | > postnet_diff_spec_loss: 0.45558  (0.46047)\n",
            "     | > decoder_ssim_loss: 0.89822  (0.89914)\n",
            "     | > postnet_ssim_loss: 0.77451  (0.79896)\n",
            "     | > loss: 1.96341  (2.02447)\n",
            "     | > align_error: 0.99086  (0.98473)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.77831  (1.92107)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.08390  (1.37879)\n",
            "     | > loader_time: 0.02620  (0.01841)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 373/406 -- GLOBAL_STEP: 7275\u001b[0m\n",
            "     | > decoder_loss: 2.61355  (2.62456)\n",
            "     | > postnet_loss: 2.51181  (2.51127)\n",
            "     | > stopnet_loss: 0.09020  (0.11220)\n",
            "     | > ga_loss: 0.00233  (0.00389)\n",
            "     | > decoder_diff_spec_loss: 0.26240  (0.26628)\n",
            "     | > postnet_diff_spec_loss: 0.45475  (0.46027)\n",
            "     | > decoder_ssim_loss: 0.89861  (0.89908)\n",
            "     | > postnet_ssim_loss: 0.76780  (0.79714)\n",
            "     | > loss: 1.97910  (2.02131)\n",
            "     | > align_error: 0.99030  (0.98511)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.78345  (1.91210)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.17860  (1.42338)\n",
            "     | > loader_time: 0.02700  (0.01892)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 398/406 -- GLOBAL_STEP: 7300\u001b[0m\n",
            "     | > decoder_loss: 2.59286  (2.62084)\n",
            "     | > postnet_loss: 2.55142  (2.51165)\n",
            "     | > stopnet_loss: 0.08582  (0.11068)\n",
            "     | > ga_loss: 0.00221  (0.00379)\n",
            "     | > decoder_diff_spec_loss: 0.26487  (0.26616)\n",
            "     | > postnet_diff_spec_loss: 0.45844  (0.46010)\n",
            "     | > decoder_ssim_loss: 0.89638  (0.89901)\n",
            "     | > postnet_ssim_loss: 0.77304  (0.79547)\n",
            "     | > loss: 1.98111  (2.01794)\n",
            "     | > align_error: 0.99109  (0.98546)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.75182  (1.90278)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.87110  (1.46744)\n",
            "     | > loader_time: 0.02800  (0.01944)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01225 \u001b[0m(-0.00019)\n",
            "     | > avg_decoder_loss:\u001b[92m 2.94628 \u001b[0m(-0.14327)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.49730 \u001b[0m(-0.01459)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.18205 \u001b[0m(-0.03078)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00335 \u001b[0m(+0.00004)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.24399 \u001b[0m(-0.00031)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[91m 0.46191 \u001b[0m(+0.00019)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.85940 \u001b[0m(-0.00099)\n",
            "     | > avg_postnet_ssim_loss:\u001b[91m 0.76082 \u001b[0m(+0.01171)\n",
            "     | > avg_loss:\u001b[92m 2.14125 \u001b[0m(-0.06738)\n",
            "     | > avg_align_error:\u001b[92m 0.98928 \u001b[0m(-0.00004)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_7308.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 18/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 11:31:58) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 17/406 -- GLOBAL_STEP: 7325\u001b[0m\n",
            "     | > decoder_loss: 2.27451  (2.30213)\n",
            "     | > postnet_loss: 2.41888  (2.48636)\n",
            "     | > stopnet_loss: 0.09303  (0.09580)\n",
            "     | > ga_loss: 0.00770  (0.01073)\n",
            "     | > decoder_diff_spec_loss: 0.26792  (0.26421)\n",
            "     | > postnet_diff_spec_loss: 0.47400  (0.46287)\n",
            "     | > decoder_ssim_loss: 0.89992  (0.89380)\n",
            "     | > postnet_ssim_loss: 0.86663  (0.86022)\n",
            "     | > loss: 1.93201  (1.96685)\n",
            "     | > align_error: 0.96988  (0.96158)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.66411  (1.66711)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.72130  (0.59772)\n",
            "     | > loader_time: 0.00880  (0.00852)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 42/406 -- GLOBAL_STEP: 7350\u001b[0m\n",
            "     | > decoder_loss: 2.31414  (2.29295)\n",
            "     | > postnet_loss: 2.46849  (2.47233)\n",
            "     | > stopnet_loss: 0.08231  (0.09128)\n",
            "     | > ga_loss: 0.00570  (0.00819)\n",
            "     | > decoder_diff_spec_loss: 0.26594  (0.26557)\n",
            "     | > postnet_diff_spec_loss: 0.45860  (0.46329)\n",
            "     | > decoder_ssim_loss: 0.89771  (0.89527)\n",
            "     | > postnet_ssim_loss: 0.86367  (0.86205)\n",
            "     | > loss: 1.92793  (1.94510)\n",
            "     | > align_error: 0.97888  (0.96962)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.63648  (1.66339)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.93410  (0.70859)\n",
            "     | > loader_time: 0.01190  (0.00963)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 67/406 -- GLOBAL_STEP: 7375\u001b[0m\n",
            "     | > decoder_loss: 2.39308  (2.31266)\n",
            "     | > postnet_loss: 2.51025  (2.47146)\n",
            "     | > stopnet_loss: 0.08337  (0.08863)\n",
            "     | > ga_loss: 0.00463  (0.00707)\n",
            "     | > decoder_diff_spec_loss: 0.26132  (0.26509)\n",
            "     | > postnet_diff_spec_loss: 0.45583  (0.46268)\n",
            "     | > decoder_ssim_loss: 0.89487  (0.89556)\n",
            "     | > postnet_ssim_loss: 0.86093  (0.86140)\n",
            "     | > loss: 1.95061  (1.94119)\n",
            "     | > align_error: 0.98085  (0.97328)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.66854  (1.66056)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.99140  (0.78634)\n",
            "     | > loader_time: 0.01360  (0.01071)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 92/406 -- GLOBAL_STEP: 7400\u001b[0m\n",
            "     | > decoder_loss: 2.36513  (2.32719)\n",
            "     | > postnet_loss: 2.52924  (2.47515)\n",
            "     | > stopnet_loss: 0.07568  (0.08650)\n",
            "     | > ga_loss: 0.00417  (0.00637)\n",
            "     | > decoder_diff_spec_loss: 0.26365  (0.26477)\n",
            "     | > postnet_diff_spec_loss: 0.45563  (0.46211)\n",
            "     | > decoder_ssim_loss: 0.89790  (0.89595)\n",
            "     | > postnet_ssim_loss: 0.77701  (0.84735)\n",
            "     | > loss: 1.91868  (1.93648)\n",
            "     | > align_error: 0.98432  (0.97566)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.62458  (1.65691)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.20050  (0.86691)\n",
            "     | > loader_time: 0.01500  (0.01172)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 117/406 -- GLOBAL_STEP: 7425\u001b[0m\n",
            "     | > decoder_loss: 2.46178  (2.33619)\n",
            "     | > postnet_loss: 2.49668  (2.47689)\n",
            "     | > stopnet_loss: 0.08029  (0.08478)\n",
            "     | > ga_loss: 0.00384  (0.00586)\n",
            "     | > decoder_diff_spec_loss: 0.26138  (0.26444)\n",
            "     | > postnet_diff_spec_loss: 0.45792  (0.46189)\n",
            "     | > decoder_ssim_loss: 0.89384  (0.89602)\n",
            "     | > postnet_ssim_loss: 0.76701  (0.83111)\n",
            "     | > loss: 1.93415  (1.93073)\n",
            "     | > align_error: 0.98362  (0.97740)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.65860  (1.65081)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.23510  (0.92850)\n",
            "     | > loader_time: 0.01610  (0.01270)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 142/406 -- GLOBAL_STEP: 7450\u001b[0m\n",
            "     | > decoder_loss: 2.37908  (2.34681)\n",
            "     | > postnet_loss: 2.49110  (2.47822)\n",
            "     | > stopnet_loss: 0.07853  (0.08327)\n",
            "     | > ga_loss: 0.00360  (0.00549)\n",
            "     | > decoder_diff_spec_loss: 0.26091  (0.26394)\n",
            "     | > postnet_diff_spec_loss: 0.46211  (0.46148)\n",
            "     | > decoder_ssim_loss: 0.89444  (0.89607)\n",
            "     | > postnet_ssim_loss: 0.76453  (0.81981)\n",
            "     | > loss: 1.90958  (1.92729)\n",
            "     | > align_error: 0.98396  (0.97865)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.62646  (1.64473)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.31520  (0.98490)\n",
            "     | > loader_time: 0.01770  (0.01349)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 167/406 -- GLOBAL_STEP: 7475\u001b[0m\n",
            "     | > decoder_loss: 2.34351  (2.34902)\n",
            "     | > postnet_loss: 2.47154  (2.47833)\n",
            "     | > stopnet_loss: 0.07246  (0.08188)\n",
            "     | > ga_loss: 0.00322  (0.00518)\n",
            "     | > decoder_diff_spec_loss: 0.26314  (0.26363)\n",
            "     | > postnet_diff_spec_loss: 0.46121  (0.46131)\n",
            "     | > decoder_ssim_loss: 0.89424  (0.89587)\n",
            "     | > postnet_ssim_loss: 0.76372  (0.81151)\n",
            "     | > loss: 1.88789  (1.92271)\n",
            "     | > align_error: 0.98643  (0.97968)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.58209  (1.63674)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.41160  (1.03586)\n",
            "     | > loader_time: 0.01820  (0.01420)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 192/406 -- GLOBAL_STEP: 7500\u001b[0m\n",
            "     | > decoder_loss: 2.31531  (2.35056)\n",
            "     | > postnet_loss: 2.47159  (2.47967)\n",
            "     | > stopnet_loss: 0.07298  (0.08047)\n",
            "     | > ga_loss: 0.00309  (0.00493)\n",
            "     | > decoder_diff_spec_loss: 0.26149  (0.26325)\n",
            "     | > postnet_diff_spec_loss: 0.46066  (0.46091)\n",
            "     | > decoder_ssim_loss: 0.89248  (0.89575)\n",
            "     | > postnet_ssim_loss: 0.76199  (0.80526)\n",
            "     | > loss: 1.87929  (1.91898)\n",
            "     | > align_error: 0.98648  (0.98057)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.56956  (1.62856)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.49710  (1.08825)\n",
            "     | > loader_time: 0.01950  (0.01486)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 217/406 -- GLOBAL_STEP: 7525\u001b[0m\n",
            "     | > decoder_loss: 2.35938  (2.35161)\n",
            "     | > postnet_loss: 2.47508  (2.48090)\n",
            "     | > stopnet_loss: 0.06743  (0.07912)\n",
            "     | > ga_loss: 0.00297  (0.00472)\n",
            "     | > decoder_diff_spec_loss: 0.25909  (0.26295)\n",
            "     | > postnet_diff_spec_loss: 0.45944  (0.46062)\n",
            "     | > decoder_ssim_loss: 0.89391  (0.89569)\n",
            "     | > postnet_ssim_loss: 0.76242  (0.80031)\n",
            "     | > loss: 1.88461  (1.91572)\n",
            "     | > align_error: 0.98772  (0.98134)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.55027  (1.62051)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.50770  (1.13545)\n",
            "     | > loader_time: 0.01990  (0.01553)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 242/406 -- GLOBAL_STEP: 7550\u001b[0m\n",
            "     | > decoder_loss: 2.42924  (2.35193)\n",
            "     | > postnet_loss: 2.53474  (2.48287)\n",
            "     | > stopnet_loss: 0.06643  (0.07778)\n",
            "     | > ga_loss: 0.00287  (0.00453)\n",
            "     | > decoder_diff_spec_loss: 0.25742  (0.26266)\n",
            "     | > postnet_diff_spec_loss: 0.45630  (0.46039)\n",
            "     | > decoder_ssim_loss: 0.89809  (0.89567)\n",
            "     | > postnet_ssim_loss: 0.76122  (0.79626)\n",
            "     | > loss: 1.91504  (1.91288)\n",
            "     | > align_error: 0.98742  (0.98201)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.55453  (1.61223)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.71140  (1.18772)\n",
            "     | > loader_time: 0.02210  (0.01619)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 267/406 -- GLOBAL_STEP: 7575\u001b[0m\n",
            "     | > decoder_loss: 2.28614  (2.34886)\n",
            "     | > postnet_loss: 2.48355  (2.48308)\n",
            "     | > stopnet_loss: 0.06464  (0.07651)\n",
            "     | > ga_loss: 0.00268  (0.00437)\n",
            "     | > decoder_diff_spec_loss: 0.25872  (0.26237)\n",
            "     | > postnet_diff_spec_loss: 0.45862  (0.46018)\n",
            "     | > decoder_ssim_loss: 0.89485  (0.89551)\n",
            "     | > postnet_ssim_loss: 0.75811  (0.79278)\n",
            "     | > loss: 1.86304  (1.90905)\n",
            "     | > align_error: 0.98809  (0.98260)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.51543  (1.60346)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.67440  (1.23826)\n",
            "     | > loader_time: 0.02240  (0.01675)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 292/406 -- GLOBAL_STEP: 7600\u001b[0m\n",
            "     | > decoder_loss: 2.36021  (2.34641)\n",
            "     | > postnet_loss: 2.49792  (2.48399)\n",
            "     | > stopnet_loss: 0.06233  (0.07530)\n",
            "     | > ga_loss: 0.00263  (0.00422)\n",
            "     | > decoder_diff_spec_loss: 0.25766  (0.26205)\n",
            "     | > postnet_diff_spec_loss: 0.45638  (0.46000)\n",
            "     | > decoder_ssim_loss: 0.89341  (0.89534)\n",
            "     | > postnet_ssim_loss: 0.76194  (0.78983)\n",
            "     | > loss: 1.88238  (1.90582)\n",
            "     | > align_error: 0.98783  (0.98311)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.51008  (1.59487)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.87020  (1.28473)\n",
            "     | > loader_time: 0.02360  (0.01736)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 317/406 -- GLOBAL_STEP: 7625\u001b[0m\n",
            "     | > decoder_loss: 2.22700  (2.34297)\n",
            "     | > postnet_loss: 2.45434  (2.48467)\n",
            "     | > stopnet_loss: 0.05939  (0.07411)\n",
            "     | > ga_loss: 0.00248  (0.00409)\n",
            "     | > decoder_diff_spec_loss: 0.25949  (0.26172)\n",
            "     | > postnet_diff_spec_loss: 0.46107  (0.45982)\n",
            "     | > decoder_ssim_loss: 0.89281  (0.89522)\n",
            "     | > postnet_ssim_loss: 0.75188  (0.78731)\n",
            "     | > loss: 1.83344  (1.90248)\n",
            "     | > align_error: 0.98979  (0.98359)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.46262  (1.58620)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.92560  (1.32995)\n",
            "     | > loader_time: 0.02400  (0.01791)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 342/406 -- GLOBAL_STEP: 7650\u001b[0m\n",
            "     | > decoder_loss: 2.30142  (2.33997)\n",
            "     | > postnet_loss: 2.47447  (2.48529)\n",
            "     | > stopnet_loss: 0.05673  (0.07296)\n",
            "     | > ga_loss: 0.00241  (0.00397)\n",
            "     | > decoder_diff_spec_loss: 0.25680  (0.26142)\n",
            "     | > postnet_diff_spec_loss: 0.45824  (0.45963)\n",
            "     | > decoder_ssim_loss: 0.89456  (0.89507)\n",
            "     | > postnet_ssim_loss: 0.75590  (0.78499)\n",
            "     | > loss: 1.85413  (1.89941)\n",
            "     | > align_error: 0.98944  (0.98400)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.45834  (1.57760)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.96550  (1.37432)\n",
            "     | > loader_time: 0.02660  (0.01845)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 367/406 -- GLOBAL_STEP: 7675\u001b[0m\n",
            "     | > decoder_loss: 2.29622  (2.33708)\n",
            "     | > postnet_loss: 2.49194  (2.48578)\n",
            "     | > stopnet_loss: 0.05593  (0.07186)\n",
            "     | > ga_loss: 0.00230  (0.00386)\n",
            "     | > decoder_diff_spec_loss: 0.26038  (0.26105)\n",
            "     | > postnet_diff_spec_loss: 0.46120  (0.45940)\n",
            "     | > decoder_ssim_loss: 0.89351  (0.89496)\n",
            "     | > postnet_ssim_loss: 0.75342  (0.78299)\n",
            "     | > loss: 1.85659  (1.89647)\n",
            "     | > align_error: 0.98966  (0.98440)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.44599  (1.56940)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.96730  (1.41610)\n",
            "     | > loader_time: 0.02580  (0.01896)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 392/406 -- GLOBAL_STEP: 7700\u001b[0m\n",
            "     | > decoder_loss: 2.29466  (2.33316)\n",
            "     | > postnet_loss: 2.48089  (2.48586)\n",
            "     | > stopnet_loss: 0.05430  (0.07075)\n",
            "     | > ga_loss: 0.00221  (0.00376)\n",
            "     | > decoder_diff_spec_loss: 0.25634  (0.26071)\n",
            "     | > postnet_diff_spec_loss: 0.45679  (0.45921)\n",
            "     | > decoder_ssim_loss: 0.89414  (0.89485)\n",
            "     | > postnet_ssim_loss: 0.75305  (0.78116)\n",
            "     | > loss: 1.84933  (1.89327)\n",
            "     | > align_error: 0.98998  (0.98477)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.44817  (1.56083)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.15850  (1.45944)\n",
            "     | > loader_time: 0.02750  (0.01949)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01399 \u001b[0m(+0.00174)\n",
            "     | > avg_decoder_loss:\u001b[92m 2.81342 \u001b[0m(-0.13287)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.47973 \u001b[0m(-0.01757)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.15485 \u001b[0m(-0.02720)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00341 \u001b[0m(+0.00006)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.24386 \u001b[0m(-0.00013)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[91m 0.46201 \u001b[0m(+0.00010)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.85893 \u001b[0m(-0.00047)\n",
            "     | > avg_postnet_ssim_loss:\u001b[91m 0.76693 \u001b[0m(+0.00611)\n",
            "     | > avg_loss:\u001b[92m 2.07813 \u001b[0m(-0.06312)\n",
            "     | > avg_align_error:\u001b[92m 0.98926 \u001b[0m(-0.00002)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_7714.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 19/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 11:52:54) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 11/406 -- GLOBAL_STEP: 7725\u001b[0m\n",
            "     | > decoder_loss: 2.05420  (2.05499)\n",
            "     | > postnet_loss: 2.43943  (2.46500)\n",
            "     | > stopnet_loss: 0.06612  (0.06791)\n",
            "     | > ga_loss: 0.00906  (0.01177)\n",
            "     | > decoder_diff_spec_loss: 0.25563  (0.25314)\n",
            "     | > postnet_diff_spec_loss: 0.46416  (0.46030)\n",
            "     | > decoder_ssim_loss: 0.88689  (0.88699)\n",
            "     | > postnet_ssim_loss: 0.85691  (0.85208)\n",
            "     | > loss: 1.85071  (1.86990)\n",
            "     | > align_error: 0.96353  (0.95686)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.35804  (1.34843)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.54340  (0.58159)\n",
            "     | > loader_time: 0.00810  (0.00793)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 36/406 -- GLOBAL_STEP: 7750\u001b[0m\n",
            "     | > decoder_loss: 1.92953  (2.05098)\n",
            "     | > postnet_loss: 2.42777  (2.44878)\n",
            "     | > stopnet_loss: 0.05634  (0.06148)\n",
            "     | > ga_loss: 0.00569  (0.00839)\n",
            "     | > decoder_diff_spec_loss: 0.25573  (0.25620)\n",
            "     | > postnet_diff_spec_loss: 0.46668  (0.46259)\n",
            "     | > decoder_ssim_loss: 0.88993  (0.89009)\n",
            "     | > postnet_ssim_loss: 0.85454  (0.85604)\n",
            "     | > loss: 1.79082  (1.84462)\n",
            "     | > align_error: 0.97722  (0.96771)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.31042  (1.34238)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.76940  (0.68909)\n",
            "     | > loader_time: 0.01090  (0.00926)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 61/406 -- GLOBAL_STEP: 7775\u001b[0m\n",
            "     | > decoder_loss: 2.12527  (2.06181)\n",
            "     | > postnet_loss: 2.45645  (2.44341)\n",
            "     | > stopnet_loss: 0.05371  (0.05889)\n",
            "     | > ga_loss: 0.00503  (0.00714)\n",
            "     | > decoder_diff_spec_loss: 0.25034  (0.25543)\n",
            "     | > postnet_diff_spec_loss: 0.45874  (0.46192)\n",
            "     | > decoder_ssim_loss: 0.89057  (0.89012)\n",
            "     | > postnet_ssim_loss: 0.85477  (0.85575)\n",
            "     | > loss: 1.83788  (1.83667)\n",
            "     | > align_error: 0.97923  (0.97187)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.33566  (1.34008)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.94170  (0.77474)\n",
            "     | > loader_time: 0.01270  (0.01046)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 86/406 -- GLOBAL_STEP: 7800\u001b[0m\n",
            "     | > decoder_loss: 2.02396  (2.07530)\n",
            "     | > postnet_loss: 2.42059  (2.44624)\n",
            "     | > stopnet_loss: 0.05081  (0.05701)\n",
            "     | > ga_loss: 0.00420  (0.00638)\n",
            "     | > decoder_diff_spec_loss: 0.25153  (0.25474)\n",
            "     | > postnet_diff_spec_loss: 0.46230  (0.46136)\n",
            "     | > decoder_ssim_loss: 0.88747  (0.89043)\n",
            "     | > postnet_ssim_loss: 0.75545  (0.84558)\n",
            "     | > loss: 1.77215  (1.83234)\n",
            "     | > align_error: 0.98212  (0.97443)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.31512  (1.33939)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.02770  (0.84568)\n",
            "     | > loader_time: 0.01420  (0.01138)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 111/406 -- GLOBAL_STEP: 7825\u001b[0m\n",
            "     | > decoder_loss: 2.09758  (2.08200)\n",
            "     | > postnet_loss: 2.45939  (2.44826)\n",
            "     | > stopnet_loss: 0.04681  (0.05544)\n",
            "     | > ga_loss: 0.00388  (0.00586)\n",
            "     | > decoder_diff_spec_loss: 0.25321  (0.25427)\n",
            "     | > postnet_diff_spec_loss: 0.46155  (0.46103)\n",
            "     | > decoder_ssim_loss: 0.89030  (0.89056)\n",
            "     | > postnet_ssim_loss: 0.75651  (0.82551)\n",
            "     | > loss: 1.79584  (1.82513)\n",
            "     | > align_error: 0.98512  (0.97637)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.30331  (1.33453)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.16990  (0.90925)\n",
            "     | > loader_time: 0.01550  (0.01239)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 136/406 -- GLOBAL_STEP: 7850\u001b[0m\n",
            "     | > decoder_loss: 2.16319  (2.09016)\n",
            "     | > postnet_loss: 2.47893  (2.44974)\n",
            "     | > stopnet_loss: 0.04496  (0.05418)\n",
            "     | > ga_loss: 0.00373  (0.00547)\n",
            "     | > decoder_diff_spec_loss: 0.25080  (0.25361)\n",
            "     | > postnet_diff_spec_loss: 0.45237  (0.46055)\n",
            "     | > decoder_ssim_loss: 0.89163  (0.89050)\n",
            "     | > postnet_ssim_loss: 0.75352  (0.81196)\n",
            "     | > loss: 1.81124  (1.82064)\n",
            "     | > align_error: 0.98537  (0.97773)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.30049  (1.32957)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.24460  (0.97124)\n",
            "     | > loader_time: 0.01700  (0.01328)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 161/406 -- GLOBAL_STEP: 7875\u001b[0m\n",
            "     | > decoder_loss: 2.04991  (2.09259)\n",
            "     | > postnet_loss: 2.42327  (2.44904)\n",
            "     | > stopnet_loss: 0.04672  (0.05310)\n",
            "     | > ga_loss: 0.00333  (0.00516)\n",
            "     | > decoder_diff_spec_loss: 0.25310  (0.25324)\n",
            "     | > postnet_diff_spec_loss: 0.46300  (0.46049)\n",
            "     | > decoder_ssim_loss: 0.88361  (0.89030)\n",
            "     | > postnet_ssim_loss: 0.74226  (0.80202)\n",
            "     | > loss: 1.76715  (1.81583)\n",
            "     | > align_error: 0.98470  (0.97880)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.28396  (1.32350)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.30690  (1.02412)\n",
            "     | > loader_time: 0.01800  (0.01413)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 186/406 -- GLOBAL_STEP: 7900\u001b[0m\n",
            "     | > decoder_loss: 2.10304  (2.09417)\n",
            "     | > postnet_loss: 2.47967  (2.45032)\n",
            "     | > stopnet_loss: 0.04237  (0.05201)\n",
            "     | > ga_loss: 0.00315  (0.00491)\n",
            "     | > decoder_diff_spec_loss: 0.24979  (0.25266)\n",
            "     | > postnet_diff_spec_loss: 0.45884  (0.46005)\n",
            "     | > decoder_ssim_loss: 0.88981  (0.89010)\n",
            "     | > postnet_ssim_loss: 0.75159  (0.79473)\n",
            "     | > loss: 1.79130  (1.81206)\n",
            "     | > align_error: 0.98743  (0.97973)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.26370  (1.31703)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.48680  (1.07408)\n",
            "     | > loader_time: 0.01940  (0.01474)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 211/406 -- GLOBAL_STEP: 7925\u001b[0m\n",
            "     | > decoder_loss: 2.08608  (2.09519)\n",
            "     | > postnet_loss: 2.46870  (2.45143)\n",
            "     | > stopnet_loss: 0.04240  (0.05100)\n",
            "     | > ga_loss: 0.00298  (0.00469)\n",
            "     | > decoder_diff_spec_loss: 0.24643  (0.25223)\n",
            "     | > postnet_diff_spec_loss: 0.45576  (0.45971)\n",
            "     | > decoder_ssim_loss: 0.88722  (0.88995)\n",
            "     | > postnet_ssim_loss: 0.74946  (0.78906)\n",
            "     | > loss: 1.78073  (1.80886)\n",
            "     | > align_error: 0.98698  (0.98054)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.24226  (1.31080)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.55220  (1.12251)\n",
            "     | > loader_time: 0.02000  (0.01533)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 236/406 -- GLOBAL_STEP: 7950\u001b[0m\n",
            "     | > decoder_loss: 2.06525  (2.09541)\n",
            "     | > postnet_loss: 2.42301  (2.45264)\n",
            "     | > stopnet_loss: 0.04309  (0.05005)\n",
            "     | > ga_loss: 0.00282  (0.00451)\n",
            "     | > decoder_diff_spec_loss: 0.24999  (0.25180)\n",
            "     | > postnet_diff_spec_loss: 0.45981  (0.45950)\n",
            "     | > decoder_ssim_loss: 0.89021  (0.88986)\n",
            "     | > postnet_ssim_loss: 0.74467  (0.78441)\n",
            "     | > loss: 1.76544  (1.80598)\n",
            "     | > align_error: 0.98685  (0.98122)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.24652  (1.30464)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.69210  (1.17240)\n",
            "     | > loader_time: 0.02180  (0.01598)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 261/406 -- GLOBAL_STEP: 7975\u001b[0m\n",
            "     | > decoder_loss: 2.03572  (2.09383)\n",
            "     | > postnet_loss: 2.48674  (2.45357)\n",
            "     | > stopnet_loss: 0.03851  (0.04910)\n",
            "     | > ga_loss: 0.00268  (0.00434)\n",
            "     | > decoder_diff_spec_loss: 0.25034  (0.25132)\n",
            "     | > postnet_diff_spec_loss: 0.45902  (0.45922)\n",
            "     | > decoder_ssim_loss: 0.88590  (0.88966)\n",
            "     | > postnet_ssim_loss: 0.74624  (0.78062)\n",
            "     | > loss: 1.76788  (1.80287)\n",
            "     | > align_error: 0.98900  (0.98184)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.21181  (1.29790)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.79380  (1.22205)\n",
            "     | > loader_time: 0.02170  (0.01656)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 286/406 -- GLOBAL_STEP: 8000\u001b[0m\n",
            "     | > decoder_loss: 2.03911  (2.09156)\n",
            "     | > postnet_loss: 2.47548  (2.45426)\n",
            "     | > stopnet_loss: 0.03909  (0.04825)\n",
            "     | > ga_loss: 0.00257  (0.00420)\n",
            "     | > decoder_diff_spec_loss: 0.24676  (0.25087)\n",
            "     | > postnet_diff_spec_loss: 0.45764  (0.45904)\n",
            "     | > decoder_ssim_loss: 0.88460  (0.88943)\n",
            "     | > postnet_ssim_loss: 0.74337  (0.77727)\n",
            "     | > loss: 1.76368  (1.79984)\n",
            "     | > align_error: 0.98781  (0.98238)\n",
            "     | > amp_scaler: 131072.00000  (131072.00000)\n",
            "     | > grad_norm: 1.20854  (1.29117)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.03940  (1.26926)\n",
            "     | > loader_time: 0.02350  (0.01716)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_8000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 311/406 -- GLOBAL_STEP: 8025\u001b[0m\n",
            "     | > decoder_loss: 2.05794  (2.08838)\n",
            "     | > postnet_loss: 2.44057  (2.45481)\n",
            "     | > stopnet_loss: 0.03752  (0.04739)\n",
            "     | > ga_loss: 0.00249  (0.00406)\n",
            "     | > decoder_diff_spec_loss: 0.24222  (0.25040)\n",
            "     | > postnet_diff_spec_loss: 0.45437  (0.45882)\n",
            "     | > decoder_ssim_loss: 0.88983  (0.88925)\n",
            "     | > postnet_ssim_loss: 0.74545  (0.77445)\n",
            "     | > loss: 1.75755  (1.79674)\n",
            "     | > align_error: 0.98827  (0.98288)\n",
            "     | > amp_scaler: 262144.00000  (141608.33441)\n",
            "     | > grad_norm: 1.21686  (1.28446)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.78360  (1.31506)\n",
            "     | > loader_time: 0.02390  (0.01783)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 336/406 -- GLOBAL_STEP: 8050\u001b[0m\n",
            "     | > decoder_loss: 1.96158  (2.08525)\n",
            "     | > postnet_loss: 2.42010  (2.45485)\n",
            "     | > stopnet_loss: 0.03435  (0.04659)\n",
            "     | > ga_loss: 0.00239  (0.00394)\n",
            "     | > decoder_diff_spec_loss: 0.24402  (0.24997)\n",
            "     | > postnet_diff_spec_loss: 0.45474  (0.45865)\n",
            "     | > decoder_ssim_loss: 0.88455  (0.88901)\n",
            "     | > postnet_ssim_loss: 0.73925  (0.77182)\n",
            "     | > loss: 1.72237  (1.79370)\n",
            "     | > align_error: 0.99011  (0.98332)\n",
            "     | > amp_scaler: 262144.00000  (150576.76190)\n",
            "     | > grad_norm: 1.15728  (1.27764)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.09260  (1.36218)\n",
            "     | > loader_time: 0.02560  (0.01838)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 361/406 -- GLOBAL_STEP: 8075\u001b[0m\n",
            "     | > decoder_loss: 2.04172  (2.08248)\n",
            "     | > postnet_loss: 2.45993  (2.45490)\n",
            "     | > stopnet_loss: 0.03600  (0.04582)\n",
            "     | > ga_loss: 0.00231  (0.00384)\n",
            "     | > decoder_diff_spec_loss: 0.24084  (0.24947)\n",
            "     | > postnet_diff_spec_loss: 0.45432  (0.45840)\n",
            "     | > decoder_ssim_loss: 0.88957  (0.88882)\n",
            "     | > postnet_ssim_loss: 0.74097  (0.76956)\n",
            "     | > loss: 1.75439  (1.79090)\n",
            "     | > align_error: 0.98895  (0.98373)\n",
            "     | > amp_scaler: 262144.00000  (158303.02493)\n",
            "     | > grad_norm: 1.17567  (1.27128)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.09570  (1.40754)\n",
            "     | > loader_time: 0.02620  (0.01888)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 386/406 -- GLOBAL_STEP: 8100\u001b[0m\n",
            "     | > decoder_loss: 2.02765  (2.07909)\n",
            "     | > postnet_loss: 2.45054  (2.45510)\n",
            "     | > stopnet_loss: 0.03226  (0.04506)\n",
            "     | > ga_loss: 0.00225  (0.00373)\n",
            "     | > decoder_diff_spec_loss: 0.24149  (0.24902)\n",
            "     | > postnet_diff_spec_loss: 0.45488  (0.45823)\n",
            "     | > decoder_ssim_loss: 0.88422  (0.88862)\n",
            "     | > postnet_ssim_loss: 0.74211  (0.76757)\n",
            "     | > loss: 1.74371  (1.78813)\n",
            "     | > align_error: 0.99038  (0.98411)\n",
            "     | > amp_scaler: 262144.00000  (165028.47668)\n",
            "     | > grad_norm: 1.16639  (1.26467)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.05240  (1.45056)\n",
            "     | > loader_time: 0.02640  (0.01937)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01142 \u001b[0m(-0.00257)\n",
            "     | > avg_decoder_loss:\u001b[92m 2.69511 \u001b[0m(-0.11831)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.46127 \u001b[0m(-0.01847)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.13369 \u001b[0m(-0.02116)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00344 \u001b[0m(+0.00003)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.24476 \u001b[0m(+0.00089)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46159 \u001b[0m(-0.00042)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.85849 \u001b[0m(-0.00044)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.75427 \u001b[0m(-0.01266)\n",
            "     | > avg_loss:\u001b[92m 2.01977 \u001b[0m(-0.05836)\n",
            "     | > avg_align_error:\u001b[92m 0.98923 \u001b[0m(-0.00003)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_8120.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 20/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 12:13:55) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 5/406 -- GLOBAL_STEP: 8125\u001b[0m\n",
            "     | > decoder_loss: 1.83476  (1.87433)\n",
            "     | > postnet_loss: 2.43404  (2.44895)\n",
            "     | > stopnet_loss: 0.04821  (0.05122)\n",
            "     | > ga_loss: 0.01133  (0.01363)\n",
            "     | > decoder_diff_spec_loss: 0.23878  (0.23667)\n",
            "     | > postnet_diff_spec_loss: 0.45809  (0.45679)\n",
            "     | > decoder_ssim_loss: 0.88221  (0.87768)\n",
            "     | > postnet_ssim_loss: 0.84789  (0.84340)\n",
            "     | > loss: 1.77882  (1.80382)\n",
            "     | > align_error: 0.95511  (0.95012)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.06342  (1.08721)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.57560  (0.50532)\n",
            "     | > loader_time: 0.00730  (0.00713)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 30/406 -- GLOBAL_STEP: 8150\u001b[0m\n",
            "     | > decoder_loss: 1.83802  (1.85563)\n",
            "     | > postnet_loss: 2.38476  (2.42058)\n",
            "     | > stopnet_loss: 0.03929  (0.04398)\n",
            "     | > ga_loss: 0.00590  (0.00872)\n",
            "     | > decoder_diff_spec_loss: 0.23879  (0.24233)\n",
            "     | > postnet_diff_spec_loss: 0.45849  (0.46166)\n",
            "     | > decoder_ssim_loss: 0.88178  (0.88179)\n",
            "     | > postnet_ssim_loss: 0.85317  (0.84996)\n",
            "     | > loss: 1.73257  (1.76558)\n",
            "     | > align_error: 0.97305  (0.96529)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.08261  (1.08799)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.77940  (0.64089)\n",
            "     | > loader_time: 0.00990  (0.00871)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 55/406 -- GLOBAL_STEP: 8175\u001b[0m\n",
            "     | > decoder_loss: 1.84860  (1.85497)\n",
            "     | > postnet_loss: 2.40073  (2.41059)\n",
            "     | > stopnet_loss: 0.03386  (0.04100)\n",
            "     | > ga_loss: 0.00508  (0.00726)\n",
            "     | > decoder_diff_spec_loss: 0.23982  (0.24130)\n",
            "     | > postnet_diff_spec_loss: 0.45862  (0.46079)\n",
            "     | > decoder_ssim_loss: 0.88331  (0.88183)\n",
            "     | > postnet_ssim_loss: 0.84869  (0.85010)\n",
            "     | > loss: 1.72920  (1.75219)\n",
            "     | > align_error: 0.97960  (0.97041)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.05455  (1.08334)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.00390  (0.75447)\n",
            "     | > loader_time: 0.01370  (0.00999)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 80/406 -- GLOBAL_STEP: 8200\u001b[0m\n",
            "     | > decoder_loss: 1.85992  (1.86757)\n",
            "     | > postnet_loss: 2.39327  (2.41209)\n",
            "     | > stopnet_loss: 0.03497  (0.03926)\n",
            "     | > ga_loss: 0.00432  (0.00645)\n",
            "     | > decoder_diff_spec_loss: 0.24040  (0.24061)\n",
            "     | > postnet_diff_spec_loss: 0.46259  (0.46054)\n",
            "     | > decoder_ssim_loss: 0.88497  (0.88190)\n",
            "     | > postnet_ssim_loss: 0.74140  (0.84567)\n",
            "     | > loss: 1.70223  (1.74859)\n",
            "     | > align_error: 0.98046  (0.97322)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.07315  (1.08451)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.07130  (0.83360)\n",
            "     | > loader_time: 0.01470  (0.01120)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 105/406 -- GLOBAL_STEP: 8225\u001b[0m\n",
            "     | > decoder_loss: 1.83481  (1.87481)\n",
            "     | > postnet_loss: 2.37446  (2.41479)\n",
            "     | > stopnet_loss: 0.03278  (0.03784)\n",
            "     | > ga_loss: 0.00392  (0.00590)\n",
            "     | > decoder_diff_spec_loss: 0.24030  (0.23991)\n",
            "     | > postnet_diff_spec_loss: 0.46535  (0.45985)\n",
            "     | > decoder_ssim_loss: 0.88497  (0.88214)\n",
            "     | > postnet_ssim_loss: 0.73494  (0.82076)\n",
            "     | > loss: 1.68611  (1.74038)\n",
            "     | > align_error: 0.98350  (0.97535)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.04567  (1.08210)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.12830  (0.90404)\n",
            "     | > loader_time: 0.01610  (0.01224)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 130/406 -- GLOBAL_STEP: 8250\u001b[0m\n",
            "     | > decoder_loss: 1.88849  (1.87878)\n",
            "     | > postnet_loss: 2.41673  (2.41518)\n",
            "     | > stopnet_loss: 0.03139  (0.03672)\n",
            "     | > ga_loss: 0.00358  (0.00548)\n",
            "     | > decoder_diff_spec_loss: 0.23492  (0.23944)\n",
            "     | > postnet_diff_spec_loss: 0.45699  (0.45964)\n",
            "     | > decoder_ssim_loss: 0.87803  (0.88193)\n",
            "     | > postnet_ssim_loss: 0.73729  (0.80425)\n",
            "     | > loss: 1.70238  (1.73394)\n",
            "     | > align_error: 0.98288  (0.97685)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.07034  (1.07715)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.24120  (0.96827)\n",
            "     | > loader_time: 0.01630  (0.01316)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 155/406 -- GLOBAL_STEP: 8275\u001b[0m\n",
            "     | > decoder_loss: 1.86165  (1.88220)\n",
            "     | > postnet_loss: 2.36841  (2.41459)\n",
            "     | > stopnet_loss: 0.03144  (0.03581)\n",
            "     | > ga_loss: 0.00334  (0.00517)\n",
            "     | > decoder_diff_spec_loss: 0.23614  (0.23906)\n",
            "     | > postnet_diff_spec_loss: 0.45879  (0.45940)\n",
            "     | > decoder_ssim_loss: 0.87564  (0.88169)\n",
            "     | > postnet_ssim_loss: 0.72985  (0.79248)\n",
            "     | > loss: 1.68075  (1.72902)\n",
            "     | > align_error: 0.98462  (0.97798)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.05477  (1.07341)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.33940  (1.02165)\n",
            "     | > loader_time: 0.01810  (0.01391)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 180/406 -- GLOBAL_STEP: 8300\u001b[0m\n",
            "     | > decoder_loss: 1.86094  (1.88376)\n",
            "     | > postnet_loss: 2.40351  (2.41539)\n",
            "     | > stopnet_loss: 0.02936  (0.03497)\n",
            "     | > ga_loss: 0.00322  (0.00491)\n",
            "     | > decoder_diff_spec_loss: 0.23479  (0.23854)\n",
            "     | > postnet_diff_spec_loss: 0.45775  (0.45901)\n",
            "     | > decoder_ssim_loss: 0.87875  (0.88141)\n",
            "     | > postnet_ssim_loss: 0.73054  (0.78399)\n",
            "     | > loss: 1.68701  (1.72504)\n",
            "     | > align_error: 0.98572  (0.97894)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.03394  (1.06863)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.39990  (1.07487)\n",
            "     | > loader_time: 0.01860  (0.01461)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 205/406 -- GLOBAL_STEP: 8325\u001b[0m\n",
            "     | > decoder_loss: 1.94367  (1.88429)\n",
            "     | > postnet_loss: 2.45140  (2.41614)\n",
            "     | > stopnet_loss: 0.02791  (0.03414)\n",
            "     | > ga_loss: 0.00306  (0.00469)\n",
            "     | > decoder_diff_spec_loss: 0.23282  (0.23804)\n",
            "     | > postnet_diff_spec_loss: 0.45509  (0.45861)\n",
            "     | > decoder_ssim_loss: 0.87939  (0.88116)\n",
            "     | > postnet_ssim_loss: 0.73513  (0.77745)\n",
            "     | > loss: 1.71756  (1.72153)\n",
            "     | > align_error: 0.98606  (0.97980)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.05339  (1.06378)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.48520  (1.12511)\n",
            "     | > loader_time: 0.02620  (0.01527)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 230/406 -- GLOBAL_STEP: 8350\u001b[0m\n",
            "     | > decoder_loss: 1.87867  (1.88513)\n",
            "     | > postnet_loss: 2.44718  (2.41708)\n",
            "     | > stopnet_loss: 0.02640  (0.03342)\n",
            "     | > ga_loss: 0.00281  (0.00450)\n",
            "     | > decoder_diff_spec_loss: 0.23315  (0.23760)\n",
            "     | > postnet_diff_spec_loss: 0.45505  (0.45839)\n",
            "     | > decoder_ssim_loss: 0.87995  (0.88094)\n",
            "     | > postnet_ssim_loss: 0.73185  (0.77218)\n",
            "     | > loss: 1.69691  (1.71877)\n",
            "     | > align_error: 0.98735  (0.98051)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.01812  (1.05953)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.64770  (1.17309)\n",
            "     | > loader_time: 0.02750  (0.01596)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 255/406 -- GLOBAL_STEP: 8375\u001b[0m\n",
            "     | > decoder_loss: 1.83336  (1.88462)\n",
            "     | > postnet_loss: 2.41051  (2.41808)\n",
            "     | > stopnet_loss: 0.02493  (0.03272)\n",
            "     | > ga_loss: 0.00273  (0.00434)\n",
            "     | > decoder_diff_spec_loss: 0.23179  (0.23714)\n",
            "     | > postnet_diff_spec_loss: 0.45252  (0.45813)\n",
            "     | > decoder_ssim_loss: 0.87617  (0.88072)\n",
            "     | > postnet_ssim_loss: 0.72942  (0.76777)\n",
            "     | > loss: 1.67203  (1.71602)\n",
            "     | > align_error: 0.98824  (0.98117)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.99322  (1.05467)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91760  (1.22738)\n",
            "     | > loader_time: 0.02190  (0.01653)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 280/406 -- GLOBAL_STEP: 8400\u001b[0m\n",
            "     | > decoder_loss: 1.90919  (1.88249)\n",
            "     | > postnet_loss: 2.43597  (2.41830)\n",
            "     | > stopnet_loss: 0.02603  (0.03208)\n",
            "     | > ga_loss: 0.00255  (0.00419)\n",
            "     | > decoder_diff_spec_loss: 0.23181  (0.23667)\n",
            "     | > postnet_diff_spec_loss: 0.45626  (0.45791)\n",
            "     | > decoder_ssim_loss: 0.87490  (0.88038)\n",
            "     | > postnet_ssim_loss: 0.72258  (0.76401)\n",
            "     | > loss: 1.69644  (1.71297)\n",
            "     | > align_error: 0.98729  (0.98175)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.00943  (1.04943)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.70290  (1.27306)\n",
            "     | > loader_time: 0.02970  (0.01715)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 305/406 -- GLOBAL_STEP: 8425\u001b[0m\n",
            "     | > decoder_loss: 1.86351  (1.88094)\n",
            "     | > postnet_loss: 2.42205  (2.41904)\n",
            "     | > stopnet_loss: 0.02553  (0.03147)\n",
            "     | > ga_loss: 0.00262  (0.00406)\n",
            "     | > decoder_diff_spec_loss: 0.23207  (0.23618)\n",
            "     | > postnet_diff_spec_loss: 0.45552  (0.45767)\n",
            "     | > decoder_ssim_loss: 0.87176  (0.88007)\n",
            "     | > postnet_ssim_loss: 0.72449  (0.76085)\n",
            "     | > loss: 1.68099  (1.71045)\n",
            "     | > align_error: 0.98735  (0.98227)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.98374  (1.04458)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.74960  (1.31888)\n",
            "     | > loader_time: 0.02400  (0.01774)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 330/406 -- GLOBAL_STEP: 8450\u001b[0m\n",
            "     | > decoder_loss: 1.87559  (1.87819)\n",
            "     | > postnet_loss: 2.42999  (2.41861)\n",
            "     | > stopnet_loss: 0.02366  (0.03090)\n",
            "     | > ga_loss: 0.00252  (0.00394)\n",
            "     | > decoder_diff_spec_loss: 0.22889  (0.23576)\n",
            "     | > postnet_diff_spec_loss: 0.45317  (0.45751)\n",
            "     | > decoder_ssim_loss: 0.87287  (0.87973)\n",
            "     | > postnet_ssim_loss: 0.72546  (0.75797)\n",
            "     | > loss: 1.68275  (1.70753)\n",
            "     | > align_error: 0.98789  (0.98273)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 1.00184  (1.03934)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.99510  (1.36394)\n",
            "     | > loader_time: 0.02470  (0.01826)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 355/406 -- GLOBAL_STEP: 8475\u001b[0m\n",
            "     | > decoder_loss: 1.89121  (1.87623)\n",
            "     | > postnet_loss: 2.43232  (2.41864)\n",
            "     | > stopnet_loss: 0.02245  (0.03035)\n",
            "     | > ga_loss: 0.00237  (0.00383)\n",
            "     | > decoder_diff_spec_loss: 0.22531  (0.23526)\n",
            "     | > postnet_diff_spec_loss: 0.44868  (0.45725)\n",
            "     | > decoder_ssim_loss: 0.87641  (0.87942)\n",
            "     | > postnet_ssim_loss: 0.72620  (0.75545)\n",
            "     | > loss: 1.68433  (1.70505)\n",
            "     | > align_error: 0.98843  (0.98316)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.99096  (1.03441)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.93300  (1.40746)\n",
            "     | > loader_time: 0.02580  (0.01878)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 380/406 -- GLOBAL_STEP: 8500\u001b[0m\n",
            "     | > decoder_loss: 1.82589  (1.87374)\n",
            "     | > postnet_loss: 2.42051  (2.41857)\n",
            "     | > stopnet_loss: 0.02220  (0.02981)\n",
            "     | > ga_loss: 0.00222  (0.00372)\n",
            "     | > decoder_diff_spec_loss: 0.22772  (0.23479)\n",
            "     | > postnet_diff_spec_loss: 0.45576  (0.45706)\n",
            "     | > decoder_ssim_loss: 0.87253  (0.87910)\n",
            "     | > postnet_ssim_loss: 0.71660  (0.75325)\n",
            "     | > loss: 1.66308  (1.70256)\n",
            "     | > align_error: 0.98897  (0.98357)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.95494  (1.02946)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.00650  (1.45218)\n",
            "     | > loader_time: 0.02710  (0.01931)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 405/406 -- GLOBAL_STEP: 8525\u001b[0m\n",
            "     | > decoder_loss: 1.81602  (1.87139)\n",
            "     | > postnet_loss: 2.39369  (2.41830)\n",
            "     | > stopnet_loss: 0.02272  (0.02930)\n",
            "     | > ga_loss: 0.00203  (0.00363)\n",
            "     | > decoder_diff_spec_loss: 0.23623  (0.23439)\n",
            "     | > postnet_diff_spec_loss: 0.46520  (0.45691)\n",
            "     | > decoder_ssim_loss: 0.87303  (0.87884)\n",
            "     | > postnet_ssim_loss: 0.71101  (0.75119)\n",
            "     | > loss: 1.65665  (1.70019)\n",
            "     | > align_error: 0.98968  (0.98394)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.96567  (1.02450)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.72650  (1.48954)\n",
            "     | > loader_time: 0.01550  (0.01983)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n",
            "   | > Decoder stopped with 'max_decoder_steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01267 \u001b[0m(+0.00125)\n",
            "     | > avg_decoder_loss:\u001b[92m 2.55286 \u001b[0m(-0.14224)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.43208 \u001b[0m(-0.02919)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.11081 \u001b[0m(-0.02288)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00347 \u001b[0m(+0.00003)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.24761 \u001b[0m(+0.00285)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.46083 \u001b[0m(-0.00075)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.85716 \u001b[0m(-0.00132)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.73720 \u001b[0m(-0.01708)\n",
            "     | > avg_loss:\u001b[92m 1.95008 \u001b[0m(-0.06968)\n",
            "     | > avg_align_error:\u001b[92m 0.98919 \u001b[0m(-0.00004)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_8526.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 21/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 12:34:55) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 24/406 -- GLOBAL_STEP: 8550\u001b[0m\n",
            "     | > decoder_loss: 1.72244  (1.70534)\n",
            "     | > postnet_loss: 2.39780  (2.38402)\n",
            "     | > stopnet_loss: 0.02938  (0.03420)\n",
            "     | > ga_loss: 0.00672  (0.00913)\n",
            "     | > decoder_diff_spec_loss: 0.22836  (0.22846)\n",
            "     | > postnet_diff_spec_loss: 0.45739  (0.46031)\n",
            "     | > decoder_ssim_loss: 0.86932  (0.86946)\n",
            "     | > postnet_ssim_loss: 0.84583  (0.84294)\n",
            "     | > loss: 1.69325  (1.70249)\n",
            "     | > align_error: 0.97221  (0.96309)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.87277  (0.87209)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.71810  (0.64414)\n",
            "     | > loader_time: 0.00980  (0.00835)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 49/406 -- GLOBAL_STEP: 8575\u001b[0m\n",
            "     | > decoder_loss: 1.70417  (1.69974)\n",
            "     | > postnet_loss: 2.35685  (2.37113)\n",
            "     | > stopnet_loss: 0.02650  (0.03091)\n",
            "     | > ga_loss: 0.00510  (0.00740)\n",
            "     | > decoder_diff_spec_loss: 0.22864  (0.22800)\n",
            "     | > postnet_diff_spec_loss: 0.46214  (0.45991)\n",
            "     | > decoder_ssim_loss: 0.87062  (0.86969)\n",
            "     | > postnet_ssim_loss: 0.84891  (0.84444)\n",
            "     | > loss: 1.66985  (1.68612)\n",
            "     | > align_error: 0.97678  (0.96904)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.87836  (0.87461)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.87900  (0.73420)\n",
            "     | > loader_time: 0.01170  (0.00982)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 74/406 -- GLOBAL_STEP: 8600\u001b[0m\n",
            "     | > decoder_loss: 1.77171  (1.70977)\n",
            "     | > postnet_loss: 2.40734  (2.37274)\n",
            "     | > stopnet_loss: 0.02277  (0.02903)\n",
            "     | > ga_loss: 0.00477  (0.00651)\n",
            "     | > decoder_diff_spec_loss: 0.22025  (0.22716)\n",
            "     | > postnet_diff_spec_loss: 0.44855  (0.45916)\n",
            "     | > decoder_ssim_loss: 0.86797  (0.86956)\n",
            "     | > postnet_ssim_loss: 0.84484  (0.84399)\n",
            "     | > loss: 1.68680  (1.68219)\n",
            "     | > align_error: 0.98013  (0.97227)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.90676  (0.87806)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.03480  (0.81424)\n",
            "     | > loader_time: 0.01320  (0.01088)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 99/406 -- GLOBAL_STEP: 8625\u001b[0m\n",
            "     | > decoder_loss: 1.74646  (1.71502)\n",
            "     | > postnet_loss: 2.34523  (2.37487)\n",
            "     | > stopnet_loss: 0.02265  (0.02768)\n",
            "     | > ga_loss: 0.00412  (0.00594)\n",
            "     | > decoder_diff_spec_loss: 0.22594  (0.22657)\n",
            "     | > postnet_diff_spec_loss: 0.45823  (0.45859)\n",
            "     | > decoder_ssim_loss: 0.87302  (0.86973)\n",
            "     | > postnet_ssim_loss: 0.72148  (0.81725)\n",
            "     | > loss: 1.63586  (1.67287)\n",
            "     | > align_error: 0.98215  (0.97451)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.86291  (0.87846)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.11780  (0.88551)\n",
            "     | > loader_time: 0.01490  (0.01183)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 124/406 -- GLOBAL_STEP: 8650\u001b[0m\n",
            "     | > decoder_loss: 1.73449  (1.71838)\n",
            "     | > postnet_loss: 2.36260  (2.37455)\n",
            "     | > stopnet_loss: 0.02145  (0.02667)\n",
            "     | > ga_loss: 0.00368  (0.00551)\n",
            "     | > decoder_diff_spec_loss: 0.22427  (0.22621)\n",
            "     | > postnet_diff_spec_loss: 0.45568  (0.45842)\n",
            "     | > decoder_ssim_loss: 0.86654  (0.86947)\n",
            "     | > postnet_ssim_loss: 0.71835  (0.79697)\n",
            "     | > loss: 1.63031  (1.66523)\n",
            "     | > align_error: 0.98471  (0.97616)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.86157  (0.87432)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.20720  (0.94344)\n",
            "     | > loader_time: 0.01670  (0.01276)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 149/406 -- GLOBAL_STEP: 8675\u001b[0m\n",
            "     | > decoder_loss: 1.76792  (1.72314)\n",
            "     | > postnet_loss: 2.38714  (2.37533)\n",
            "     | > stopnet_loss: 0.02166  (0.02585)\n",
            "     | > ga_loss: 0.00347  (0.00519)\n",
            "     | > decoder_diff_spec_loss: 0.22164  (0.22586)\n",
            "     | > postnet_diff_spec_loss: 0.45452  (0.45805)\n",
            "     | > decoder_ssim_loss: 0.86336  (0.86925)\n",
            "     | > postnet_ssim_loss: 0.71507  (0.78314)\n",
            "     | > loss: 1.64140  (1.66049)\n",
            "     | > align_error: 0.98337  (0.97733)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.86946  (0.87240)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.35480  (0.99762)\n",
            "     | > loader_time: 0.01760  (0.01346)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 174/406 -- GLOBAL_STEP: 8700\u001b[0m\n",
            "     | > decoder_loss: 1.72639  (1.72377)\n",
            "     | > postnet_loss: 2.34882  (2.37494)\n",
            "     | > stopnet_loss: 0.02073  (0.02515)\n",
            "     | > ga_loss: 0.00327  (0.00492)\n",
            "     | > decoder_diff_spec_loss: 0.22015  (0.22553)\n",
            "     | > postnet_diff_spec_loss: 0.45445  (0.45781)\n",
            "     | > decoder_ssim_loss: 0.86625  (0.86879)\n",
            "     | > postnet_ssim_loss: 0.70728  (0.77297)\n",
            "     | > loss: 1.61793  (1.65571)\n",
            "     | > align_error: 0.98446  (0.97834)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.83509  (0.86875)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.32130  (1.04948)\n",
            "     | > loader_time: 0.01830  (0.01417)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 199/406 -- GLOBAL_STEP: 8725\u001b[0m\n",
            "     | > decoder_loss: 1.71991  (1.72476)\n",
            "     | > postnet_loss: 2.38111  (2.37568)\n",
            "     | > stopnet_loss: 0.01926  (0.02448)\n",
            "     | > ga_loss: 0.00307  (0.00470)\n",
            "     | > decoder_diff_spec_loss: 0.22108  (0.22505)\n",
            "     | > postnet_diff_spec_loss: 0.45225  (0.45730)\n",
            "     | > decoder_ssim_loss: 0.86435  (0.86845)\n",
            "     | > postnet_ssim_loss: 0.71297  (0.76536)\n",
            "     | > loss: 1.62253  (1.65211)\n",
            "     | > align_error: 0.98642  (0.97925)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.82601  (0.86522)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.63190  (1.09755)\n",
            "     | > loader_time: 0.02020  (0.01484)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 224/406 -- GLOBAL_STEP: 8750\u001b[0m\n",
            "     | > decoder_loss: 1.69898  (1.72588)\n",
            "     | > postnet_loss: 2.38355  (2.37610)\n",
            "     | > stopnet_loss: 0.01846  (0.02391)\n",
            "     | > ga_loss: 0.00290  (0.00450)\n",
            "     | > decoder_diff_spec_loss: 0.22373  (0.22475)\n",
            "     | > postnet_diff_spec_loss: 0.45784  (0.45712)\n",
            "     | > decoder_ssim_loss: 0.86382  (0.86813)\n",
            "     | > postnet_ssim_loss: 0.70942  (0.75930)\n",
            "     | > loss: 1.61731  (1.64925)\n",
            "     | > align_error: 0.98688  (0.98001)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.81991  (0.86242)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.59000  (1.14505)\n",
            "     | > loader_time: 0.02030  (0.01548)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 249/406 -- GLOBAL_STEP: 8775\u001b[0m\n",
            "     | > decoder_loss: 1.69430  (1.72590)\n",
            "     | > postnet_loss: 2.35854  (2.37679)\n",
            "     | > stopnet_loss: 0.01829  (0.02337)\n",
            "     | > ga_loss: 0.00271  (0.00434)\n",
            "     | > decoder_diff_spec_loss: 0.22140  (0.22437)\n",
            "     | > postnet_diff_spec_loss: 0.45560  (0.45684)\n",
            "     | > decoder_ssim_loss: 0.86222  (0.86780)\n",
            "     | > postnet_ssim_loss: 0.70334  (0.75420)\n",
            "     | > loss: 1.60567  (1.64653)\n",
            "     | > align_error: 0.98748  (0.98069)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.80139  (0.85912)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.59710  (1.19596)\n",
            "     | > loader_time: 0.02130  (0.01611)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 274/406 -- GLOBAL_STEP: 8800\u001b[0m\n",
            "     | > decoder_loss: 1.73222  (1.72497)\n",
            "     | > postnet_loss: 2.38457  (2.37673)\n",
            "     | > stopnet_loss: 0.01751  (0.02286)\n",
            "     | > ga_loss: 0.00266  (0.00419)\n",
            "     | > decoder_diff_spec_loss: 0.21624  (0.22395)\n",
            "     | > postnet_diff_spec_loss: 0.45221  (0.45655)\n",
            "     | > decoder_ssim_loss: 0.86533  (0.86735)\n",
            "     | > postnet_ssim_loss: 0.70933  (0.75000)\n",
            "     | > loss: 1.62077  (1.64370)\n",
            "     | > align_error: 0.98728  (0.98130)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.82146  (0.85547)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.76070  (1.24398)\n",
            "     | > loader_time: 0.02410  (0.01667)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 299/406 -- GLOBAL_STEP: 8825\u001b[0m\n",
            "     | > decoder_loss: 1.72651  (1.72392)\n",
            "     | > postnet_loss: 2.40396  (2.37697)\n",
            "     | > stopnet_loss: 0.01674  (0.02240)\n",
            "     | > ga_loss: 0.00249  (0.00406)\n",
            "     | > decoder_diff_spec_loss: 0.21643  (0.22358)\n",
            "     | > postnet_diff_spec_loss: 0.44780  (0.45633)\n",
            "     | > decoder_ssim_loss: 0.86586  (0.86693)\n",
            "     | > postnet_ssim_loss: 0.70945  (0.74640)\n",
            "     | > loss: 1.62171  (1.64122)\n",
            "     | > align_error: 0.98829  (0.98183)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.82786  (0.85183)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.80190  (1.29254)\n",
            "     | > loader_time: 0.02360  (0.01721)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 324/406 -- GLOBAL_STEP: 8850\u001b[0m\n",
            "     | > decoder_loss: 1.67767  (1.72186)\n",
            "     | > postnet_loss: 2.34250  (2.37639)\n",
            "     | > stopnet_loss: 0.01641  (0.02197)\n",
            "     | > ga_loss: 0.00233  (0.00394)\n",
            "     | > decoder_diff_spec_loss: 0.22203  (0.22325)\n",
            "     | > postnet_diff_spec_loss: 0.45732  (0.45619)\n",
            "     | > decoder_ssim_loss: 0.86042  (0.86649)\n",
            "     | > postnet_ssim_loss: 0.70073  (0.74318)\n",
            "     | > loss: 1.59323  (1.63848)\n",
            "     | > align_error: 0.98871  (0.98232)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.78113  (0.84766)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.82600  (1.34044)\n",
            "     | > loader_time: 0.02380  (0.01777)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 349/406 -- GLOBAL_STEP: 8875\u001b[0m\n",
            "     | > decoder_loss: 1.72880  (1.72090)\n",
            "     | > postnet_loss: 2.37189  (2.37631)\n",
            "     | > stopnet_loss: 0.01634  (0.02155)\n",
            "     | > ga_loss: 0.00241  (0.00383)\n",
            "     | > decoder_diff_spec_loss: 0.21607  (0.22285)\n",
            "     | > postnet_diff_spec_loss: 0.45030  (0.45591)\n",
            "     | > decoder_ssim_loss: 0.85862  (0.86607)\n",
            "     | > postnet_ssim_loss: 0.70307  (0.74037)\n",
            "     | > loss: 1.61060  (1.63628)\n",
            "     | > align_error: 0.98788  (0.98276)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.79954  (0.84376)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.96090  (1.38489)\n",
            "     | > loader_time: 0.02540  (0.01829)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 374/406 -- GLOBAL_STEP: 8900\u001b[0m\n",
            "     | > decoder_loss: 1.64203  (1.71932)\n",
            "     | > postnet_loss: 2.34369  (2.37608)\n",
            "     | > stopnet_loss: 0.01479  (0.02116)\n",
            "     | > ga_loss: 0.00220  (0.00372)\n",
            "     | > decoder_diff_spec_loss: 0.21517  (0.22247)\n",
            "     | > postnet_diff_spec_loss: 0.45180  (0.45569)\n",
            "     | > decoder_ssim_loss: 0.85740  (0.86565)\n",
            "     | > postnet_ssim_loss: 0.70295  (0.73794)\n",
            "     | > loss: 1.57907  (1.63405)\n",
            "     | > align_error: 0.98982  (0.98318)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.76907  (0.83992)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.10300  (1.42939)\n",
            "     | > loader_time: 0.02610  (0.01890)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 399/406 -- GLOBAL_STEP: 8925\u001b[0m\n",
            "     | > decoder_loss: 1.71899  (1.71780)\n",
            "     | > postnet_loss: 2.35174  (2.37553)\n",
            "     | > stopnet_loss: 0.01488  (0.02077)\n",
            "     | > ga_loss: 0.00215  (0.00363)\n",
            "     | > decoder_diff_spec_loss: 0.21678  (0.22211)\n",
            "     | > postnet_diff_spec_loss: 0.45244  (0.45551)\n",
            "     | > decoder_ssim_loss: 0.86235  (0.86527)\n",
            "     | > postnet_ssim_loss: 0.69760  (0.73569)\n",
            "     | > loss: 1.60062  (1.63188)\n",
            "     | > align_error: 0.98943  (0.98357)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.78699  (0.83603)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.87150  (1.47367)\n",
            "     | > loader_time: 0.02770  (0.01945)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01554 \u001b[0m(+0.00287)\n",
            "     | > avg_decoder_loss:\u001b[92m 2.44091 \u001b[0m(-0.11195)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.39747 \u001b[0m(-0.03460)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.09772 \u001b[0m(-0.01309)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00348 \u001b[0m(+0.00002)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.24913 \u001b[0m(+0.00152)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.45970 \u001b[0m(-0.00113)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.85509 \u001b[0m(-0.00207)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.71700 \u001b[0m(-0.02019)\n",
            "     | > avg_loss:\u001b[92m 1.89496 \u001b[0m(-0.05513)\n",
            "     | > avg_align_error:\u001b[92m 0.98913 \u001b[0m(-0.00006)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_8932.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 22/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 12:45:26) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 18/406 -- GLOBAL_STEP: 8950\u001b[0m\n",
            "     | > decoder_loss: 1.57558  (1.60011)\n",
            "     | > postnet_loss: 2.34346  (2.34476)\n",
            "     | > stopnet_loss: 0.02542  (0.02932)\n",
            "     | > ga_loss: 0.00736  (0.00979)\n",
            "     | > decoder_diff_spec_loss: 0.21996  (0.21742)\n",
            "     | > postnet_diff_spec_loss: 0.45955  (0.45818)\n",
            "     | > decoder_ssim_loss: 0.85677  (0.85330)\n",
            "     | > postnet_ssim_loss: 0.84119  (0.83527)\n",
            "     | > loss: 1.63636  (1.65554)\n",
            "     | > align_error: 0.96821  (0.96004)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.70136  (0.70693)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.68810  (0.59657)\n",
            "     | > loader_time: 0.00900  (0.00935)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 43/406 -- GLOBAL_STEP: 8975\u001b[0m\n",
            "     | > decoder_loss: 1.54073  (1.58969)\n",
            "     | > postnet_loss: 2.29424  (2.32894)\n",
            "     | > stopnet_loss: 0.02164  (0.02552)\n",
            "     | > ga_loss: 0.00514  (0.00762)\n",
            "     | > decoder_diff_spec_loss: 0.21964  (0.21813)\n",
            "     | > postnet_diff_spec_loss: 0.46030  (0.45845)\n",
            "     | > decoder_ssim_loss: 0.84592  (0.85366)\n",
            "     | > postnet_ssim_loss: 0.83690  (0.83847)\n",
            "     | > loss: 1.59678  (1.63546)\n",
            "     | > align_error: 0.97561  (0.96772)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.68247  (0.70084)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.87200  (0.71170)\n",
            "     | > loader_time: 0.01150  (0.01013)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 68/406 -- GLOBAL_STEP: 9000\u001b[0m\n",
            "     | > decoder_loss: 1.60909  (1.59647)\n",
            "     | > postnet_loss: 2.31777  (2.32677)\n",
            "     | > stopnet_loss: 0.01899  (0.02349)\n",
            "     | > ga_loss: 0.00465  (0.00664)\n",
            "     | > decoder_diff_spec_loss: 0.21312  (0.21742)\n",
            "     | > postnet_diff_spec_loss: 0.45186  (0.45767)\n",
            "     | > decoder_ssim_loss: 0.85434  (0.85368)\n",
            "     | > postnet_ssim_loss: 0.84109  (0.83935)\n",
            "     | > loss: 1.61404  (1.62953)\n",
            "     | > align_error: 0.97945  (0.97135)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.70610  (0.70128)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.95000  (0.79462)\n",
            "     | > loader_time: 0.01330  (0.01117)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_9000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 93/406 -- GLOBAL_STEP: 9025\u001b[0m\n",
            "     | > decoder_loss: 1.63382  (1.60107)\n",
            "     | > postnet_loss: 2.39787  (2.32940)\n",
            "     | > stopnet_loss: 0.01783  (0.02216)\n",
            "     | > ga_loss: 0.00396  (0.00602)\n",
            "     | > decoder_diff_spec_loss: 0.21622  (0.21708)\n",
            "     | > postnet_diff_spec_loss: 0.45557  (0.45712)\n",
            "     | > decoder_ssim_loss: 0.85166  (0.85372)\n",
            "     | > postnet_ssim_loss: 0.70120  (0.81537)\n",
            "     | > loss: 1.60170  (1.62068)\n",
            "     | > align_error: 0.98203  (0.97375)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.72201  (0.70307)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.06200  (0.86285)\n",
            "     | > loader_time: 0.01460  (0.01221)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 118/406 -- GLOBAL_STEP: 9050\u001b[0m\n",
            "     | > decoder_loss: 1.57905  (1.60408)\n",
            "     | > postnet_loss: 2.30958  (2.32892)\n",
            "     | > stopnet_loss: 0.01683  (0.02114)\n",
            "     | > ga_loss: 0.00355  (0.00556)\n",
            "     | > decoder_diff_spec_loss: 0.21247  (0.21683)\n",
            "     | > postnet_diff_spec_loss: 0.45312  (0.45685)\n",
            "     | > decoder_ssim_loss: 0.84979  (0.85350)\n",
            "     | > postnet_ssim_loss: 0.69503  (0.79031)\n",
            "     | > loss: 1.55931  (1.61158)\n",
            "     | > align_error: 0.98378  (0.97552)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.68909  (0.70226)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.18800  (0.92406)\n",
            "     | > loader_time: 0.01600  (0.01293)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 143/406 -- GLOBAL_STEP: 9075\u001b[0m\n",
            "     | > decoder_loss: 1.61818  (1.60873)\n",
            "     | > postnet_loss: 2.32003  (2.32914)\n",
            "     | > stopnet_loss: 0.01584  (0.02035)\n",
            "     | > ga_loss: 0.00340  (0.00522)\n",
            "     | > decoder_diff_spec_loss: 0.21670  (0.21647)\n",
            "     | > postnet_diff_spec_loss: 0.45846  (0.45646)\n",
            "     | > decoder_ssim_loss: 0.84725  (0.85323)\n",
            "     | > postnet_ssim_loss: 0.68701  (0.77371)\n",
            "     | > loss: 1.56974  (1.60591)\n",
            "     | > align_error: 0.98421  (0.97681)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.68307  (0.70298)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.67860  (0.98257)\n",
            "     | > loader_time: 0.01740  (0.01364)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 168/406 -- GLOBAL_STEP: 9100\u001b[0m\n",
            "     | > decoder_loss: 1.58238  (1.60947)\n",
            "     | > postnet_loss: 2.31080  (2.32810)\n",
            "     | > stopnet_loss: 0.01546  (0.01969)\n",
            "     | > ga_loss: 0.00312  (0.00495)\n",
            "     | > decoder_diff_spec_loss: 0.21197  (0.21626)\n",
            "     | > postnet_diff_spec_loss: 0.45353  (0.45622)\n",
            "     | > decoder_ssim_loss: 0.84860  (0.85270)\n",
            "     | > postnet_ssim_loss: 0.70007  (0.76167)\n",
            "     | > loss: 1.55789  (1.60053)\n",
            "     | > align_error: 0.98436  (0.97787)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.68518  (0.70119)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.34490  (1.03439)\n",
            "     | > loader_time: 0.01800  (0.01432)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 193/406 -- GLOBAL_STEP: 9125\u001b[0m\n",
            "     | > decoder_loss: 1.61089  (1.61092)\n",
            "     | > postnet_loss: 2.34640  (2.32851)\n",
            "     | > stopnet_loss: 0.01451  (0.01909)\n",
            "     | > ga_loss: 0.00305  (0.00472)\n",
            "     | > decoder_diff_spec_loss: 0.20998  (0.21586)\n",
            "     | > postnet_diff_spec_loss: 0.45081  (0.45578)\n",
            "     | > decoder_ssim_loss: 0.84758  (0.85226)\n",
            "     | > postnet_ssim_loss: 0.69549  (0.75279)\n",
            "     | > loss: 1.57005  (1.59672)\n",
            "     | > align_error: 0.98593  (0.97881)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.68002  (0.69908)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.49760  (1.08615)\n",
            "     | > loader_time: 0.02470  (0.01501)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 218/406 -- GLOBAL_STEP: 9150\u001b[0m\n",
            "     | > decoder_loss: 1.62015  (1.61174)\n",
            "     | > postnet_loss: 2.32870  (2.32851)\n",
            "     | > stopnet_loss: 0.01403  (0.01857)\n",
            "     | > ga_loss: 0.00294  (0.00452)\n",
            "     | > decoder_diff_spec_loss: 0.21126  (0.21557)\n",
            "     | > postnet_diff_spec_loss: 0.45371  (0.45547)\n",
            "     | > decoder_ssim_loss: 0.85184  (0.85191)\n",
            "     | > postnet_ssim_loss: 0.69411  (0.74582)\n",
            "     | > loss: 1.56868  (1.59345)\n",
            "     | > align_error: 0.98620  (0.97962)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.67399  (0.69695)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.57510  (1.13222)\n",
            "     | > loader_time: 0.02520  (0.01563)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 243/406 -- GLOBAL_STEP: 9175\u001b[0m\n",
            "     | > decoder_loss: 1.70597  (1.61316)\n",
            "     | > postnet_loss: 2.38008  (2.32957)\n",
            "     | > stopnet_loss: 0.01446  (0.01810)\n",
            "     | > ga_loss: 0.00290  (0.00435)\n",
            "     | > decoder_diff_spec_loss: 0.21113  (0.21528)\n",
            "     | > postnet_diff_spec_loss: 0.44969  (0.45520)\n",
            "     | > decoder_ssim_loss: 0.84777  (0.85154)\n",
            "     | > postnet_ssim_loss: 0.69252  (0.74021)\n",
            "     | > loss: 1.60075  (1.59111)\n",
            "     | > align_error: 0.98583  (0.98032)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.70882  (0.69498)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.59820  (1.18545)\n",
            "     | > loader_time: 0.02200  (0.01624)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 268/406 -- GLOBAL_STEP: 9200\u001b[0m\n",
            "     | > decoder_loss: 1.61957  (1.61243)\n",
            "     | > postnet_loss: 2.33720  (2.32863)\n",
            "     | > stopnet_loss: 0.01326  (0.01768)\n",
            "     | > ga_loss: 0.00268  (0.00420)\n",
            "     | > decoder_diff_spec_loss: 0.20914  (0.21498)\n",
            "     | > postnet_diff_spec_loss: 0.45216  (0.45498)\n",
            "     | > decoder_ssim_loss: 0.84490  (0.85105)\n",
            "     | > postnet_ssim_loss: 0.69021  (0.73536)\n",
            "     | > loss: 1.56494  (1.58804)\n",
            "     | > align_error: 0.98743  (0.98096)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.66674  (0.69186)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.83240  (1.23662)\n",
            "     | > loader_time: 0.02350  (0.01685)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 293/406 -- GLOBAL_STEP: 9225\u001b[0m\n",
            "     | > decoder_loss: 1.65853  (1.61234)\n",
            "     | > postnet_loss: 2.36458  (2.32862)\n",
            "     | > stopnet_loss: 0.01288  (0.01729)\n",
            "     | > ga_loss: 0.00255  (0.00406)\n",
            "     | > decoder_diff_spec_loss: 0.20851  (0.21470)\n",
            "     | > postnet_diff_spec_loss: 0.44959  (0.45476)\n",
            "     | > decoder_ssim_loss: 0.84846  (0.85056)\n",
            "     | > postnet_ssim_loss: 0.69014  (0.73134)\n",
            "     | > loss: 1.58058  (1.58570)\n",
            "     | > align_error: 0.98808  (0.98152)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.66301  (0.68883)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.71940  (1.28351)\n",
            "     | > loader_time: 0.02350  (0.01742)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 318/406 -- GLOBAL_STEP: 9250\u001b[0m\n",
            "     | > decoder_loss: 1.58942  (1.61131)\n",
            "     | > postnet_loss: 2.31676  (2.32815)\n",
            "     | > stopnet_loss: 0.01216  (0.01692)\n",
            "     | > ga_loss: 0.00247  (0.00394)\n",
            "     | > decoder_diff_spec_loss: 0.21118  (0.21442)\n",
            "     | > postnet_diff_spec_loss: 0.45230  (0.45456)\n",
            "     | > decoder_ssim_loss: 0.84217  (0.85009)\n",
            "     | > postnet_ssim_loss: 0.68810  (0.72786)\n",
            "     | > loss: 1.54946  (1.58323)\n",
            "     | > align_error: 0.98836  (0.98203)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.65226  (0.68572)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91610  (1.32958)\n",
            "     | > loader_time: 0.02510  (0.01800)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 343/406 -- GLOBAL_STEP: 9275\u001b[0m\n",
            "     | > decoder_loss: 1.63885  (1.61097)\n",
            "     | > postnet_loss: 2.34863  (2.32784)\n",
            "     | > stopnet_loss: 0.01226  (0.01658)\n",
            "     | > ga_loss: 0.00252  (0.00383)\n",
            "     | > decoder_diff_spec_loss: 0.20780  (0.21415)\n",
            "     | > postnet_diff_spec_loss: 0.44968  (0.45434)\n",
            "     | > decoder_ssim_loss: 0.84356  (0.84963)\n",
            "     | > postnet_ssim_loss: 0.68685  (0.72474)\n",
            "     | > loss: 1.56871  (1.58116)\n",
            "     | > align_error: 0.98749  (0.98248)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.65346  (0.68256)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.80080  (1.37386)\n",
            "     | > loader_time: 0.02570  (0.01859)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 368/406 -- GLOBAL_STEP: 9300\u001b[0m\n",
            "     | > decoder_loss: 1.61438  (1.61027)\n",
            "     | > postnet_loss: 2.33412  (2.32727)\n",
            "     | > stopnet_loss: 0.01164  (0.01626)\n",
            "     | > ga_loss: 0.00226  (0.00373)\n",
            "     | > decoder_diff_spec_loss: 0.20875  (0.21383)\n",
            "     | > postnet_diff_spec_loss: 0.44871  (0.45408)\n",
            "     | > decoder_ssim_loss: 0.84032  (0.84920)\n",
            "     | > postnet_ssim_loss: 0.67909  (0.72205)\n",
            "     | > loss: 1.55431  (1.57908)\n",
            "     | > align_error: 0.98893  (0.98291)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.63433  (0.67970)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.14040  (1.41699)\n",
            "     | > loader_time: 0.02640  (0.01917)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 393/406 -- GLOBAL_STEP: 9325\u001b[0m\n",
            "     | > decoder_loss: 1.59164  (1.60930)\n",
            "     | > postnet_loss: 2.30754  (2.32628)\n",
            "     | > stopnet_loss: 0.01145  (0.01595)\n",
            "     | > ga_loss: 0.00212  (0.00363)\n",
            "     | > decoder_diff_spec_loss: 0.20879  (0.21354)\n",
            "     | > postnet_diff_spec_loss: 0.45067  (0.45386)\n",
            "     | > decoder_ssim_loss: 0.84349  (0.84876)\n",
            "     | > postnet_ssim_loss: 0.68500  (0.71958)\n",
            "     | > loss: 1.54385  (1.57694)\n",
            "     | > align_error: 0.98965  (0.98332)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.62274  (0.67686)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.03740  (1.46004)\n",
            "     | > loader_time: 0.02820  (0.01973)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01380 \u001b[0m(-0.00174)\n",
            "     | > avg_decoder_loss:\u001b[92m 2.32491 \u001b[0m(-0.11601)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.35464 \u001b[0m(-0.04283)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.08533 \u001b[0m(-0.01239)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00349 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.24737 \u001b[0m(-0.00175)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.45795 \u001b[0m(-0.00175)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.85222 \u001b[0m(-0.00287)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.68514 \u001b[0m(-0.03186)\n",
            "     | > avg_loss:\u001b[92m 1.83333 \u001b[0m(-0.06163)\n",
            "     | > avg_align_error:\u001b[92m 0.98907 \u001b[0m(-0.00006)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_9338.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 23/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 12:56:00) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 12/406 -- GLOBAL_STEP: 9350\u001b[0m\n",
            "     | > decoder_loss: 1.51653  (1.53283)\n",
            "     | > postnet_loss: 2.26656  (2.29722)\n",
            "     | > stopnet_loss: 0.02298  (0.02822)\n",
            "     | > ga_loss: 0.00820  (0.01075)\n",
            "     | > decoder_diff_spec_loss: 0.21887  (0.21010)\n",
            "     | > postnet_diff_spec_loss: 0.46806  (0.45586)\n",
            "     | > decoder_ssim_loss: 0.83772  (0.83435)\n",
            "     | > postnet_ssim_loss: 0.81965  (0.82313)\n",
            "     | > loss: 1.59583  (1.62034)\n",
            "     | > align_error: 0.96439  (0.95655)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.59326  (0.59623)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.62800  (0.57143)\n",
            "     | > loader_time: 0.00840  (0.00831)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 37/406 -- GLOBAL_STEP: 9375\u001b[0m\n",
            "     | > decoder_loss: 1.54216  (1.51919)\n",
            "     | > postnet_loss: 2.26708  (2.28179)\n",
            "     | > stopnet_loss: 0.01789  (0.02269)\n",
            "     | > ga_loss: 0.00578  (0.00789)\n",
            "     | > decoder_diff_spec_loss: 0.20770  (0.21133)\n",
            "     | > postnet_diff_spec_loss: 0.45313  (0.45666)\n",
            "     | > decoder_ssim_loss: 0.83598  (0.83572)\n",
            "     | > postnet_ssim_loss: 0.83419  (0.82871)\n",
            "     | > loss: 1.58183  (1.59551)\n",
            "     | > align_error: 0.97531  (0.96655)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.57290  (0.58761)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.82440  (0.68597)\n",
            "     | > loader_time: 0.01440  (0.00941)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 62/406 -- GLOBAL_STEP: 9400\u001b[0m\n",
            "     | > decoder_loss: 1.46698  (1.51957)\n",
            "     | > postnet_loss: 2.23924  (2.27473)\n",
            "     | > stopnet_loss: 0.01633  (0.02052)\n",
            "     | > ga_loss: 0.00449  (0.00678)\n",
            "     | > decoder_diff_spec_loss: 0.20973  (0.21080)\n",
            "     | > postnet_diff_spec_loss: 0.45638  (0.45607)\n",
            "     | > decoder_ssim_loss: 0.83319  (0.83525)\n",
            "     | > postnet_ssim_loss: 0.82976  (0.82987)\n",
            "     | > loss: 1.54762  (1.58599)\n",
            "     | > align_error: 0.97994  (0.97061)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.56384  (0.58578)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.98600  (0.77013)\n",
            "     | > loader_time: 0.01250  (0.01049)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 87/406 -- GLOBAL_STEP: 9425\u001b[0m\n",
            "     | > decoder_loss: 1.54528  (1.52538)\n",
            "     | > postnet_loss: 2.30272  (2.27676)\n",
            "     | > stopnet_loss: 0.01426  (0.01914)\n",
            "     | > ga_loss: 0.00391  (0.00609)\n",
            "     | > decoder_diff_spec_loss: 0.20391  (0.21035)\n",
            "     | > postnet_diff_spec_loss: 0.44901  (0.45539)\n",
            "     | > decoder_ssim_loss: 0.83177  (0.83521)\n",
            "     | > postnet_ssim_loss: 0.68157  (0.81282)\n",
            "     | > loss: 1.53737  (1.57857)\n",
            "     | > align_error: 0.98321  (0.97318)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.60074  (0.58721)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.02930  (0.85082)\n",
            "     | > loader_time: 0.01450  (0.01145)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 112/406 -- GLOBAL_STEP: 9450\u001b[0m\n",
            "     | > decoder_loss: 1.51579  (1.52707)\n",
            "     | > postnet_loss: 2.26486  (2.27661)\n",
            "     | > stopnet_loss: 0.01399  (0.01812)\n",
            "     | > ga_loss: 0.00382  (0.00561)\n",
            "     | > decoder_diff_spec_loss: 0.20744  (0.21013)\n",
            "     | > postnet_diff_spec_loss: 0.45445  (0.45510)\n",
            "     | > decoder_ssim_loss: 0.82896  (0.83497)\n",
            "     | > postnet_ssim_loss: 0.67786  (0.78263)\n",
            "     | > loss: 1.52042  (1.56782)\n",
            "     | > align_error: 0.98225  (0.97511)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.56802  (0.58612)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.13170  (0.91346)\n",
            "     | > loader_time: 0.01590  (0.01240)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 137/406 -- GLOBAL_STEP: 9475\u001b[0m\n",
            "     | > decoder_loss: 1.53860  (1.53030)\n",
            "     | > postnet_loss: 2.27564  (2.27687)\n",
            "     | > stopnet_loss: 0.01357  (0.01737)\n",
            "     | > ga_loss: 0.00355  (0.00526)\n",
            "     | > decoder_diff_spec_loss: 0.20853  (0.20970)\n",
            "     | > postnet_diff_spec_loss: 0.45288  (0.45459)\n",
            "     | > decoder_ssim_loss: 0.83291  (0.83449)\n",
            "     | > postnet_ssim_loss: 0.67545  (0.76333)\n",
            "     | > loss: 1.52730  (1.56099)\n",
            "     | > align_error: 0.98238  (0.97649)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.57824  (0.58678)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.20050  (0.96913)\n",
            "     | > loader_time: 0.01730  (0.01324)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 162/406 -- GLOBAL_STEP: 9500\u001b[0m\n",
            "     | > decoder_loss: 1.58729  (1.53149)\n",
            "     | > postnet_loss: 2.28340  (2.27517)\n",
            "     | > stopnet_loss: 0.01282  (0.01676)\n",
            "     | > ga_loss: 0.00335  (0.00497)\n",
            "     | > decoder_diff_spec_loss: 0.20087  (0.20957)\n",
            "     | > postnet_diff_spec_loss: 0.44464  (0.45442)\n",
            "     | > decoder_ssim_loss: 0.83210  (0.83386)\n",
            "     | > postnet_ssim_loss: 0.67523  (0.74940)\n",
            "     | > loss: 1.53546  (1.55510)\n",
            "     | > align_error: 0.98440  (0.97759)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.60173  (0.58558)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.28090  (1.02423)\n",
            "     | > loader_time: 0.01830  (0.01399)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 187/406 -- GLOBAL_STEP: 9525\u001b[0m\n",
            "     | > decoder_loss: 1.53935  (1.53308)\n",
            "     | > postnet_loss: 2.27165  (2.27524)\n",
            "     | > stopnet_loss: 0.01258  (0.01622)\n",
            "     | > ga_loss: 0.00311  (0.00474)\n",
            "     | > decoder_diff_spec_loss: 0.20737  (0.20921)\n",
            "     | > postnet_diff_spec_loss: 0.45281  (0.45402)\n",
            "     | > decoder_ssim_loss: 0.82966  (0.83323)\n",
            "     | > postnet_ssim_loss: 0.67112  (0.73935)\n",
            "     | > loss: 1.52114  (1.55094)\n",
            "     | > align_error: 0.98527  (0.97856)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.55770  (0.58321)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.50210  (1.07477)\n",
            "     | > loader_time: 0.01890  (0.01457)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 212/406 -- GLOBAL_STEP: 9550\u001b[0m\n",
            "     | > decoder_loss: 1.53830  (1.53455)\n",
            "     | > postnet_loss: 2.25885  (2.27508)\n",
            "     | > stopnet_loss: 0.01170  (0.01576)\n",
            "     | > ga_loss: 0.00311  (0.00454)\n",
            "     | > decoder_diff_spec_loss: 0.20355  (0.20893)\n",
            "     | > postnet_diff_spec_loss: 0.44836  (0.45363)\n",
            "     | > decoder_ssim_loss: 0.82838  (0.83272)\n",
            "     | > postnet_ssim_loss: 0.67193  (0.73156)\n",
            "     | > loss: 1.51460  (1.54757)\n",
            "     | > align_error: 0.98621  (0.97940)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.57010  (0.58087)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.61230  (1.12662)\n",
            "     | > loader_time: 0.02040  (0.01520)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 237/406 -- GLOBAL_STEP: 9575\u001b[0m\n",
            "     | > decoder_loss: 1.56691  (1.53578)\n",
            "     | > postnet_loss: 2.31660  (2.27534)\n",
            "     | > stopnet_loss: 0.01123  (0.01534)\n",
            "     | > ga_loss: 0.00284  (0.00436)\n",
            "     | > decoder_diff_spec_loss: 0.20256  (0.20867)\n",
            "     | > postnet_diff_spec_loss: 0.44600  (0.45337)\n",
            "     | > decoder_ssim_loss: 0.82676  (0.83220)\n",
            "     | > postnet_ssim_loss: 0.67819  (0.72523)\n",
            "     | > loss: 1.53469  (1.54481)\n",
            "     | > align_error: 0.98770  (0.98013)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.57488  (0.57865)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.71960  (1.17559)\n",
            "     | > loader_time: 0.02140  (0.01588)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 262/406 -- GLOBAL_STEP: 9600\u001b[0m\n",
            "     | > decoder_loss: 1.50124  (1.53600)\n",
            "     | > postnet_loss: 2.24606  (2.27486)\n",
            "     | > stopnet_loss: 0.01101  (0.01497)\n",
            "     | > ga_loss: 0.00264  (0.00421)\n",
            "     | > decoder_diff_spec_loss: 0.20396  (0.20837)\n",
            "     | > postnet_diff_spec_loss: 0.45205  (0.45309)\n",
            "     | > decoder_ssim_loss: 0.82293  (0.83157)\n",
            "     | > postnet_ssim_loss: 0.66910  (0.71997)\n",
            "     | > loss: 1.49803  (1.54199)\n",
            "     | > align_error: 0.98733  (0.98078)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.52487  (0.57580)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.74880  (1.22514)\n",
            "     | > loader_time: 0.02260  (0.01648)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 287/406 -- GLOBAL_STEP: 9625\u001b[0m\n",
            "     | > decoder_loss: 1.51131  (1.53621)\n",
            "     | > postnet_loss: 2.22824  (2.27439)\n",
            "     | > stopnet_loss: 0.01085  (0.01463)\n",
            "     | > ga_loss: 0.00261  (0.00407)\n",
            "     | > decoder_diff_spec_loss: 0.20348  (0.20813)\n",
            "     | > postnet_diff_spec_loss: 0.44771  (0.45287)\n",
            "     | > decoder_ssim_loss: 0.82413  (0.83097)\n",
            "     | > postnet_ssim_loss: 0.66651  (0.71549)\n",
            "     | > loss: 1.49425  (1.53952)\n",
            "     | > align_error: 0.98749  (0.98135)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.53872  (0.57247)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.74120  (1.27300)\n",
            "     | > loader_time: 0.02280  (0.01708)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 312/406 -- GLOBAL_STEP: 9650\u001b[0m\n",
            "     | > decoder_loss: 1.54939  (1.53608)\n",
            "     | > postnet_loss: 2.24459  (2.27398)\n",
            "     | > stopnet_loss: 0.01077  (0.01433)\n",
            "     | > ga_loss: 0.00256  (0.00395)\n",
            "     | > decoder_diff_spec_loss: 0.20563  (0.20786)\n",
            "     | > postnet_diff_spec_loss: 0.45000  (0.45262)\n",
            "     | > decoder_ssim_loss: 0.82825  (0.83043)\n",
            "     | > postnet_ssim_loss: 0.66103  (0.71174)\n",
            "     | > loss: 1.50831  (1.53726)\n",
            "     | > align_error: 0.98751  (0.98188)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.51749  (0.56918)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.95740  (1.31953)\n",
            "     | > loader_time: 0.02420  (0.01766)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 337/406 -- GLOBAL_STEP: 9675\u001b[0m\n",
            "     | > decoder_loss: 1.52734  (1.53588)\n",
            "     | > postnet_loss: 2.28685  (2.27314)\n",
            "     | > stopnet_loss: 0.01038  (0.01404)\n",
            "     | > ga_loss: 0.00242  (0.00384)\n",
            "     | > decoder_diff_spec_loss: 0.20629  (0.20765)\n",
            "     | > postnet_diff_spec_loss: 0.45029  (0.45241)\n",
            "     | > decoder_ssim_loss: 0.82481  (0.82979)\n",
            "     | > postnet_ssim_loss: 0.66873  (0.70828)\n",
            "     | > loss: 1.51353  (1.53502)\n",
            "     | > align_error: 0.98761  (0.98235)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.53907  (0.56581)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.92660  (1.36570)\n",
            "     | > loader_time: 0.02530  (0.01820)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 362/406 -- GLOBAL_STEP: 9700\u001b[0m\n",
            "     | > decoder_loss: 1.56353  (1.53586)\n",
            "     | > postnet_loss: 2.28511  (2.27212)\n",
            "     | > stopnet_loss: 0.00996  (0.01378)\n",
            "     | > ga_loss: 0.00231  (0.00374)\n",
            "     | > decoder_diff_spec_loss: 0.20466  (0.20736)\n",
            "     | > postnet_diff_spec_loss: 0.45129  (0.45214)\n",
            "     | > decoder_ssim_loss: 0.82130  (0.82924)\n",
            "     | > postnet_ssim_loss: 0.66424  (0.70535)\n",
            "     | > loss: 1.51902  (1.53297)\n",
            "     | > align_error: 0.98949  (0.98280)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.51468  (0.56268)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.07280  (1.40981)\n",
            "     | > loader_time: 0.02550  (0.01873)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 387/406 -- GLOBAL_STEP: 9725\u001b[0m\n",
            "     | > decoder_loss: 1.52722  (1.53551)\n",
            "     | > postnet_loss: 2.23844  (2.27112)\n",
            "     | > stopnet_loss: 0.00969  (0.01352)\n",
            "     | > ga_loss: 0.00213  (0.00364)\n",
            "     | > decoder_diff_spec_loss: 0.20514  (0.20713)\n",
            "     | > postnet_diff_spec_loss: 0.44941  (0.45194)\n",
            "     | > decoder_ssim_loss: 0.82374  (0.82870)\n",
            "     | > postnet_ssim_loss: 0.66779  (0.70271)\n",
            "     | > loss: 1.49826  (1.53099)\n",
            "     | > align_error: 0.98969  (0.98322)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.50966  (0.55925)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.12970  (1.45452)\n",
            "     | > loader_time: 0.02760  (0.01929)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01422 \u001b[0m(+0.00042)\n",
            "     | > avg_decoder_loss:\u001b[92m 2.19789 \u001b[0m(-0.12702)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.30372 \u001b[0m(-0.05092)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.07405 \u001b[0m(-0.01128)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00350 \u001b[0m(+0.00002)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.24539 \u001b[0m(-0.00198)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.45627 \u001b[0m(-0.00169)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.84721 \u001b[0m(-0.00501)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.66142 \u001b[0m(-0.02372)\n",
            "     | > avg_loss:\u001b[92m 1.76953 \u001b[0m(-0.06379)\n",
            "     | > avg_align_error:\u001b[92m 0.98900 \u001b[0m(-0.00007)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_9744.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 24/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 13:06:31) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 6/406 -- GLOBAL_STEP: 9750\u001b[0m\n",
            "     | > decoder_loss: 1.39624  (1.47510)\n",
            "     | > postnet_loss: 2.16021  (2.23860)\n",
            "     | > stopnet_loss: 0.02567  (0.02882)\n",
            "     | > ga_loss: 0.01012  (0.01225)\n",
            "     | > decoder_diff_spec_loss: 0.20975  (0.20324)\n",
            "     | > postnet_diff_spec_loss: 0.46025  (0.45190)\n",
            "     | > decoder_ssim_loss: 0.81465  (0.81293)\n",
            "     | > postnet_ssim_loss: 0.81751  (0.81149)\n",
            "     | > loss: 1.54095  (1.58836)\n",
            "     | > align_error: 0.96294  (0.95238)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.45841  (0.49754)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.60460  (0.56467)\n",
            "     | > loader_time: 0.00880  (0.00854)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 31/406 -- GLOBAL_STEP: 9775\u001b[0m\n",
            "     | > decoder_loss: 1.44058  (1.47049)\n",
            "     | > postnet_loss: 2.18699  (2.22875)\n",
            "     | > stopnet_loss: 0.01749  (0.02190)\n",
            "     | > ga_loss: 0.00573  (0.00818)\n",
            "     | > decoder_diff_spec_loss: 0.20697  (0.20674)\n",
            "     | > postnet_diff_spec_loss: 0.45678  (0.45493)\n",
            "     | > decoder_ssim_loss: 0.81657  (0.81475)\n",
            "     | > postnet_ssim_loss: 0.82073  (0.81864)\n",
            "     | > loss: 1.52832  (1.56136)\n",
            "     | > align_error: 0.97377  (0.96509)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.43832  (0.46694)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.77030  (0.66227)\n",
            "     | > loader_time: 0.01030  (0.00886)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 56/406 -- GLOBAL_STEP: 9800\u001b[0m\n",
            "     | > decoder_loss: 1.48378  (1.47051)\n",
            "     | > postnet_loss: 2.22184  (2.21960)\n",
            "     | > stopnet_loss: 0.01555  (0.01939)\n",
            "     | > ga_loss: 0.00483  (0.00690)\n",
            "     | > decoder_diff_spec_loss: 0.20645  (0.20596)\n",
            "     | > postnet_diff_spec_loss: 0.45663  (0.45399)\n",
            "     | > decoder_ssim_loss: 0.81558  (0.81484)\n",
            "     | > postnet_ssim_loss: 0.82121  (0.82036)\n",
            "     | > loss: 1.54108  (1.55022)\n",
            "     | > align_error: 0.97710  (0.96996)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.44716  (0.45631)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.95600  (0.75622)\n",
            "     | > loader_time: 0.01250  (0.01008)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 81/406 -- GLOBAL_STEP: 9825\u001b[0m\n",
            "     | > decoder_loss: 1.45945  (1.47315)\n",
            "     | > postnet_loss: 2.22188  (2.21890)\n",
            "     | > stopnet_loss: 0.01393  (0.01788)\n",
            "     | > ga_loss: 0.00417  (0.00618)\n",
            "     | > decoder_diff_spec_loss: 0.20361  (0.20574)\n",
            "     | > postnet_diff_spec_loss: 0.45012  (0.45360)\n",
            "     | > decoder_ssim_loss: 0.81757  (0.81490)\n",
            "     | > postnet_ssim_loss: 0.65951  (0.81290)\n",
            "     | > loss: 1.48784  (1.54355)\n",
            "     | > align_error: 0.98045  (0.97272)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.45979  (0.45401)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.06940  (0.83538)\n",
            "     | > loader_time: 0.01420  (0.01120)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 106/406 -- GLOBAL_STEP: 9850\u001b[0m\n",
            "     | > decoder_loss: 1.43745  (1.47622)\n",
            "     | > postnet_loss: 2.17071  (2.21920)\n",
            "     | > stopnet_loss: 0.01315  (0.01681)\n",
            "     | > ga_loss: 0.00380  (0.00567)\n",
            "     | > decoder_diff_spec_loss: 0.20743  (0.20541)\n",
            "     | > postnet_diff_spec_loss: 0.45524  (0.45295)\n",
            "     | > decoder_ssim_loss: 0.81668  (0.81514)\n",
            "     | > postnet_ssim_loss: 0.65125  (0.77650)\n",
            "     | > loss: 1.46683  (1.53153)\n",
            "     | > align_error: 0.98177  (0.97483)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.44931  (0.45280)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.08520  (0.90196)\n",
            "     | > loader_time: 0.01570  (0.01211)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 131/406 -- GLOBAL_STEP: 9875\u001b[0m\n",
            "     | > decoder_loss: 1.43200  (1.47789)\n",
            "     | > postnet_loss: 2.17708  (2.21847)\n",
            "     | > stopnet_loss: 0.01277  (0.01602)\n",
            "     | > ga_loss: 0.00356  (0.00530)\n",
            "     | > decoder_diff_spec_loss: 0.20612  (0.20520)\n",
            "     | > postnet_diff_spec_loss: 0.45335  (0.45267)\n",
            "     | > decoder_ssim_loss: 0.81164  (0.81482)\n",
            "     | > postnet_ssim_loss: 0.65209  (0.75383)\n",
            "     | > loss: 1.46366  (1.52322)\n",
            "     | > align_error: 0.98302  (0.97634)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.45697  (0.45219)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.19220  (0.95987)\n",
            "     | > loader_time: 0.02170  (0.01300)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 156/406 -- GLOBAL_STEP: 9900\u001b[0m\n",
            "     | > decoder_loss: 1.50575  (1.47990)\n",
            "     | > postnet_loss: 2.21268  (2.21688)\n",
            "     | > stopnet_loss: 0.01165  (0.01539)\n",
            "     | > ga_loss: 0.00339  (0.00500)\n",
            "     | > decoder_diff_spec_loss: 0.20442  (0.20508)\n",
            "     | > postnet_diff_spec_loss: 0.45150  (0.45236)\n",
            "     | > decoder_ssim_loss: 0.80967  (0.81449)\n",
            "     | > postnet_ssim_loss: 0.65662  (0.73797)\n",
            "     | > loss: 1.48876  (1.51707)\n",
            "     | > align_error: 0.98433  (0.97749)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.42449  (0.45145)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.40130  (1.01244)\n",
            "     | > loader_time: 0.01750  (0.01370)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 181/406 -- GLOBAL_STEP: 9925\u001b[0m\n",
            "     | > decoder_loss: 1.47058  (1.48191)\n",
            "     | > postnet_loss: 2.22421  (2.21658)\n",
            "     | > stopnet_loss: 0.01130  (0.01487)\n",
            "     | > ga_loss: 0.00310  (0.00476)\n",
            "     | > decoder_diff_spec_loss: 0.20297  (0.20482)\n",
            "     | > postnet_diff_spec_loss: 0.45097  (0.45194)\n",
            "     | > decoder_ssim_loss: 0.80786  (0.81412)\n",
            "     | > postnet_ssim_loss: 0.65817  (0.72666)\n",
            "     | > loss: 1.48050  (1.51267)\n",
            "     | > align_error: 0.98501  (0.97846)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.41997  (0.44987)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.40720  (1.06403)\n",
            "     | > loader_time: 0.01910  (0.01435)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 206/406 -- GLOBAL_STEP: 9950\u001b[0m\n",
            "     | > decoder_loss: 1.50726  (1.48391)\n",
            "     | > postnet_loss: 2.21511  (2.21599)\n",
            "     | > stopnet_loss: 0.01110  (0.01441)\n",
            "     | > ga_loss: 0.00305  (0.00456)\n",
            "     | > decoder_diff_spec_loss: 0.20181  (0.20455)\n",
            "     | > postnet_diff_spec_loss: 0.44791  (0.45150)\n",
            "     | > decoder_ssim_loss: 0.81773  (0.81385)\n",
            "     | > postnet_ssim_loss: 0.65201  (0.71790)\n",
            "     | > loss: 1.48683  (1.50912)\n",
            "     | > align_error: 0.98541  (0.97933)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.45811  (0.44806)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.49330  (1.11125)\n",
            "     | > loader_time: 0.01950  (0.01500)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 231/406 -- GLOBAL_STEP: 9975\u001b[0m\n",
            "     | > decoder_loss: 1.52217  (1.48554)\n",
            "     | > postnet_loss: 2.24683  (2.21575)\n",
            "     | > stopnet_loss: 0.01046  (0.01401)\n",
            "     | > ga_loss: 0.00284  (0.00438)\n",
            "     | > decoder_diff_spec_loss: 0.20319  (0.20442)\n",
            "     | > postnet_diff_spec_loss: 0.45002  (0.45125)\n",
            "     | > decoder_ssim_loss: 0.80960  (0.81357)\n",
            "     | > postnet_ssim_loss: 0.64748  (0.71083)\n",
            "     | > loss: 1.49449  (1.50624)\n",
            "     | > align_error: 0.98663  (0.98007)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.43060  (0.44666)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.61300  (1.16054)\n",
            "     | > loader_time: 0.02120  (0.01562)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 256/406 -- GLOBAL_STEP: 10000\u001b[0m\n",
            "     | > decoder_loss: 1.48529  (1.48688)\n",
            "     | > postnet_loss: 2.17882  (2.21518)\n",
            "     | > stopnet_loss: 0.00996  (0.01365)\n",
            "     | > ga_loss: 0.00266  (0.00422)\n",
            "     | > decoder_diff_spec_loss: 0.20332  (0.20421)\n",
            "     | > postnet_diff_spec_loss: 0.44932  (0.45094)\n",
            "     | > decoder_ssim_loss: 0.80680  (0.81319)\n",
            "     | > postnet_ssim_loss: 0.64564  (0.70489)\n",
            "     | > loss: 1.46556  (1.50358)\n",
            "     | > align_error: 0.98820  (0.98075)\n",
            "     | > amp_scaler: 262144.00000  (262144.00000)\n",
            "     | > grad_norm: 0.39745  (0.44458)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.75060  (1.21421)\n",
            "     | > loader_time: 0.02200  (0.01621)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_10000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 281/406 -- GLOBAL_STEP: 10025\u001b[0m\n",
            "     | > decoder_loss: 1.53831  (1.48742)\n",
            "     | > postnet_loss: 2.25077  (2.21449)\n",
            "     | > stopnet_loss: 0.00999  (0.01333)\n",
            "     | > ga_loss: 0.00260  (0.00408)\n",
            "     | > decoder_diff_spec_loss: 0.20455  (0.20403)\n",
            "     | > postnet_diff_spec_loss: 0.44940  (0.45068)\n",
            "     | > decoder_ssim_loss: 0.80944  (0.81278)\n",
            "     | > postnet_ssim_loss: 0.65132  (0.70000)\n",
            "     | > loss: 1.49892  (1.50109)\n",
            "     | > align_error: 0.98747  (0.98134)\n",
            "     | > amp_scaler: 524288.00000  (285466.41993)\n",
            "     | > grad_norm: 0.43268  (0.44214)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.75590  (1.26406)\n",
            "     | > loader_time: 0.03070  (0.01693)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 306/406 -- GLOBAL_STEP: 10050\u001b[0m\n",
            "     | > decoder_loss: 1.50015  (1.48805)\n",
            "     | > postnet_loss: 2.20662  (2.21390)\n",
            "     | > stopnet_loss: 0.00947  (0.01303)\n",
            "     | > ga_loss: 0.00254  (0.00396)\n",
            "     | > decoder_diff_spec_loss: 0.20133  (0.20383)\n",
            "     | > postnet_diff_spec_loss: 0.44700  (0.45041)\n",
            "     | > decoder_ssim_loss: 0.80717  (0.81238)\n",
            "     | > postnet_ssim_loss: 0.64520  (0.69592)\n",
            "     | > loss: 1.47405  (1.49894)\n",
            "     | > align_error: 0.98806  (0.98187)\n",
            "     | > amp_scaler: 524288.00000  (304977.98693)\n",
            "     | > grad_norm: 0.39662  (0.43993)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.90420  (1.30944)\n",
            "     | > loader_time: 0.03110  (0.01754)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 331/406 -- GLOBAL_STEP: 10075\u001b[0m\n",
            "     | > decoder_loss: 1.52128  (1.48809)\n",
            "     | > postnet_loss: 2.21791  (2.21248)\n",
            "     | > stopnet_loss: 0.00951  (0.01276)\n",
            "     | > ga_loss: 0.00247  (0.00384)\n",
            "     | > decoder_diff_spec_loss: 0.20471  (0.20372)\n",
            "     | > postnet_diff_spec_loss: 0.44926  (0.45022)\n",
            "     | > decoder_ssim_loss: 0.80896  (0.81200)\n",
            "     | > postnet_ssim_loss: 0.64618  (0.69225)\n",
            "     | > loss: 1.48394  (1.49667)\n",
            "     | > align_error: 0.98818  (0.98236)\n",
            "     | > amp_scaler: 524288.00000  (321542.18731)\n",
            "     | > grad_norm: 0.40249  (0.43712)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.06710  (1.35410)\n",
            "     | > loader_time: 0.02510  (0.01808)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 356/406 -- GLOBAL_STEP: 10100\u001b[0m\n",
            "     | > decoder_loss: 1.50856  (1.48861)\n",
            "     | > postnet_loss: 2.21165  (2.21132)\n",
            "     | > stopnet_loss: 0.00938  (0.01252)\n",
            "     | > ga_loss: 0.00238  (0.00374)\n",
            "     | > decoder_diff_spec_loss: 0.19603  (0.20347)\n",
            "     | > postnet_diff_spec_loss: 0.44150  (0.44990)\n",
            "     | > decoder_ssim_loss: 0.80434  (0.81163)\n",
            "     | > postnet_ssim_loss: 0.65508  (0.68909)\n",
            "     | > loss: 1.47559  (1.49472)\n",
            "     | > align_error: 0.98810  (0.98281)\n",
            "     | > amp_scaler: 524288.00000  (335779.95506)\n",
            "     | > grad_norm: 0.42448  (0.43482)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.01610  (1.39635)\n",
            "     | > loader_time: 0.02640  (0.01860)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 381/406 -- GLOBAL_STEP: 10125\u001b[0m\n",
            "     | > decoder_loss: 1.46417  (1.48875)\n",
            "     | > postnet_loss: 2.17736  (2.21009)\n",
            "     | > stopnet_loss: 0.00892  (0.01228)\n",
            "     | > ga_loss: 0.00218  (0.00364)\n",
            "     | > decoder_diff_spec_loss: 0.19982  (0.20331)\n",
            "     | > postnet_diff_spec_loss: 0.44715  (0.44969)\n",
            "     | > decoder_ssim_loss: 0.80247  (0.81128)\n",
            "     | > postnet_ssim_loss: 0.64718  (0.68629)\n",
            "     | > loss: 1.45435  (1.49285)\n",
            "     | > align_error: 0.98897  (0.98323)\n",
            "     | > amp_scaler: 524288.00000  (348149.24934)\n",
            "     | > grad_norm: 0.37465  (0.43233)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.07860  (1.44042)\n",
            "     | > loader_time: 0.02840  (0.01917)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01267 \u001b[0m(-0.00155)\n",
            "     | > avg_decoder_loss:\u001b[92m 2.08112 \u001b[0m(-0.11677)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.25229 \u001b[0m(-0.05143)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.06387 \u001b[0m(-0.01018)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00350 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.24363 \u001b[0m(-0.00176)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.45421 \u001b[0m(-0.00205)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.83958 \u001b[0m(-0.00763)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.63666 \u001b[0m(-0.02476)\n",
            "     | > avg_loss:\u001b[92m 1.70826 \u001b[0m(-0.06127)\n",
            "     | > avg_align_error:\u001b[91m 0.98900 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_10150.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 25/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 13:17:08) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 0/406 -- GLOBAL_STEP: 10150\u001b[0m\n",
            "     | > decoder_loss: 1.53963  (1.53963)\n",
            "     | > postnet_loss: 2.27405  (2.27405)\n",
            "     | > stopnet_loss: 0.03862  (0.03862)\n",
            "     | > ga_loss: 0.01810  (0.01810)\n",
            "     | > decoder_diff_spec_loss: 0.19933  (0.19933)\n",
            "     | > postnet_diff_spec_loss: 0.44683  (0.44683)\n",
            "     | > decoder_ssim_loss: 0.76173  (0.76173)\n",
            "     | > postnet_ssim_loss: 0.76478  (0.76478)\n",
            "     | > loss: 1.62573  (1.62573)\n",
            "     | > align_error: 0.93301  (0.93301)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.61971  (0.61971)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.89790  (0.89795)\n",
            "     | > loader_time: 1.20010  (1.20010)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 25/406 -- GLOBAL_STEP: 10175\u001b[0m\n",
            "     | > decoder_loss: 1.47171  (1.44629)\n",
            "     | > postnet_loss: 2.19900  (2.17047)\n",
            "     | > stopnet_loss: 0.01703  (0.02164)\n",
            "     | > ga_loss: 0.00656  (0.00862)\n",
            "     | > decoder_diff_spec_loss: 0.19748  (0.20379)\n",
            "     | > postnet_diff_spec_loss: 0.44329  (0.45201)\n",
            "     | > decoder_ssim_loss: 0.80719  (0.80095)\n",
            "     | > postnet_ssim_loss: 0.81822  (0.80797)\n",
            "     | > loss: 1.53402  (1.53513)\n",
            "     | > align_error: 0.97038  (0.96357)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.36527  (0.38162)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.67770  (0.66535)\n",
            "     | > loader_time: 0.01000  (0.01047)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 50/406 -- GLOBAL_STEP: 10200\u001b[0m\n",
            "     | > decoder_loss: 1.48178  (1.44298)\n",
            "     | > postnet_loss: 2.16952  (2.15703)\n",
            "     | > stopnet_loss: 0.01494  (0.01885)\n",
            "     | > ga_loss: 0.00536  (0.00709)\n",
            "     | > decoder_diff_spec_loss: 0.19344  (0.20366)\n",
            "     | > postnet_diff_spec_loss: 0.43895  (0.45159)\n",
            "     | > decoder_ssim_loss: 0.80016  (0.80154)\n",
            "     | > postnet_ssim_loss: 0.81673  (0.80967)\n",
            "     | > loss: 1.51687  (1.52091)\n",
            "     | > align_error: 0.97589  (0.96928)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.34455  (0.36689)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.84480  (0.75213)\n",
            "     | > loader_time: 0.01160  (0.01076)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 75/406 -- GLOBAL_STEP: 10225\u001b[0m\n",
            "     | > decoder_loss: 1.49326  (1.44579)\n",
            "     | > postnet_loss: 2.18716  (2.15629)\n",
            "     | > stopnet_loss: 0.01329  (0.01723)\n",
            "     | > ga_loss: 0.00435  (0.00628)\n",
            "     | > decoder_diff_spec_loss: 0.20034  (0.20339)\n",
            "     | > postnet_diff_spec_loss: 0.44823  (0.45102)\n",
            "     | > decoder_ssim_loss: 0.80225  (0.80193)\n",
            "     | > postnet_ssim_loss: 0.81190  (0.81031)\n",
            "     | > loss: 1.52082  (1.51579)\n",
            "     | > align_error: 0.97737  (0.97242)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.35353  (0.36043)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.07470  (0.82941)\n",
            "     | > loader_time: 0.01340  (0.01161)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 100/406 -- GLOBAL_STEP: 10250\u001b[0m\n",
            "     | > decoder_loss: 1.44417  (1.44681)\n",
            "     | > postnet_loss: 2.15008  (2.15585)\n",
            "     | > stopnet_loss: 0.01232  (0.01609)\n",
            "     | > ga_loss: 0.00395  (0.00574)\n",
            "     | > decoder_diff_spec_loss: 0.20267  (0.20319)\n",
            "     | > postnet_diff_spec_loss: 0.45318  (0.45046)\n",
            "     | > decoder_ssim_loss: 0.80215  (0.80236)\n",
            "     | > postnet_ssim_loss: 0.63765  (0.77128)\n",
            "     | > loss: 1.45452  (1.50229)\n",
            "     | > align_error: 0.98241  (0.97466)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.33580  (0.35886)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.14420  (0.89254)\n",
            "     | > loader_time: 0.01530  (0.01245)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 125/406 -- GLOBAL_STEP: 10275\u001b[0m\n",
            "     | > decoder_loss: 1.52587  (1.44863)\n",
            "     | > postnet_loss: 2.20752  (2.15465)\n",
            "     | > stopnet_loss: 0.01203  (0.01527)\n",
            "     | > ga_loss: 0.00366  (0.00534)\n",
            "     | > decoder_diff_spec_loss: 0.19956  (0.20307)\n",
            "     | > postnet_diff_spec_loss: 0.44673  (0.45017)\n",
            "     | > decoder_ssim_loss: 0.80374  (0.80247)\n",
            "     | > postnet_ssim_loss: 0.64903  (0.74480)\n",
            "     | > loss: 1.48844  (1.49293)\n",
            "     | > align_error: 0.98297  (0.97626)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.35631  (0.35756)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.19140  (0.95136)\n",
            "     | > loader_time: 0.01660  (0.01330)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 150/406 -- GLOBAL_STEP: 10300\u001b[0m\n",
            "     | > decoder_loss: 1.43628  (1.45050)\n",
            "     | > postnet_loss: 2.13784  (2.15333)\n",
            "     | > stopnet_loss: 0.01105  (0.01463)\n",
            "     | > ga_loss: 0.00339  (0.00504)\n",
            "     | > decoder_diff_spec_loss: 0.20738  (0.20300)\n",
            "     | > postnet_diff_spec_loss: 0.45370  (0.44981)\n",
            "     | > decoder_ssim_loss: 0.80245  (0.80256)\n",
            "     | > postnet_ssim_loss: 0.62981  (0.72683)\n",
            "     | > loss: 1.44488  (1.48635)\n",
            "     | > align_error: 0.98522  (0.97745)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.34265  (0.35787)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.29120  (1.01165)\n",
            "     | > loader_time: 0.01870  (0.01402)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 175/406 -- GLOBAL_STEP: 10325\u001b[0m\n",
            "     | > decoder_loss: 1.44745  (1.45220)\n",
            "     | > postnet_loss: 2.14232  (2.15188)\n",
            "     | > stopnet_loss: 0.01018  (0.01409)\n",
            "     | > ga_loss: 0.00317  (0.00479)\n",
            "     | > decoder_diff_spec_loss: 0.19912  (0.20286)\n",
            "     | > postnet_diff_spec_loss: 0.44453  (0.44945)\n",
            "     | > decoder_ssim_loss: 0.80249  (0.80236)\n",
            "     | > postnet_ssim_loss: 0.64054  (0.71390)\n",
            "     | > loss: 1.44516  (1.48122)\n",
            "     | > align_error: 0.98682  (0.97846)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.33968  (0.35596)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.37850  (1.06522)\n",
            "     | > loader_time: 0.01870  (0.01464)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 200/406 -- GLOBAL_STEP: 10350\u001b[0m\n",
            "     | > decoder_loss: 1.47486  (1.45419)\n",
            "     | > postnet_loss: 2.12623  (2.15109)\n",
            "     | > stopnet_loss: 0.01011  (0.01364)\n",
            "     | > ga_loss: 0.00309  (0.00458)\n",
            "     | > decoder_diff_spec_loss: 0.20304  (0.20260)\n",
            "     | > postnet_diff_spec_loss: 0.44658  (0.44894)\n",
            "     | > decoder_ssim_loss: 0.80393  (0.80225)\n",
            "     | > postnet_ssim_loss: 0.63637  (0.70428)\n",
            "     | > loss: 1.44829  (1.47739)\n",
            "     | > align_error: 0.98515  (0.97936)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.34181  (0.35457)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.42240  (1.11325)\n",
            "     | > loader_time: 0.01920  (0.01523)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 225/406 -- GLOBAL_STEP: 10375\u001b[0m\n",
            "     | > decoder_loss: 1.44554  (1.45546)\n",
            "     | > postnet_loss: 2.10250  (2.15003)\n",
            "     | > stopnet_loss: 0.00959  (0.01323)\n",
            "     | > ga_loss: 0.00281  (0.00440)\n",
            "     | > decoder_diff_spec_loss: 0.19899  (0.20251)\n",
            "     | > postnet_diff_spec_loss: 0.44298  (0.44870)\n",
            "     | > decoder_ssim_loss: 0.79915  (0.80221)\n",
            "     | > postnet_ssim_loss: 0.63404  (0.69654)\n",
            "     | > loss: 1.42944  (1.47411)\n",
            "     | > align_error: 0.98548  (0.98012)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.35002  (0.35358)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.60010  (1.16115)\n",
            "     | > loader_time: 0.02150  (0.01589)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 250/406 -- GLOBAL_STEP: 10400\u001b[0m\n",
            "     | > decoder_loss: 1.52236  (1.45731)\n",
            "     | > postnet_loss: 2.17991  (2.14975)\n",
            "     | > stopnet_loss: 0.00959  (0.01287)\n",
            "     | > ga_loss: 0.00283  (0.00424)\n",
            "     | > decoder_diff_spec_loss: 0.19621  (0.20235)\n",
            "     | > postnet_diff_spec_loss: 0.43977  (0.44838)\n",
            "     | > decoder_ssim_loss: 0.80205  (0.80210)\n",
            "     | > postnet_ssim_loss: 0.64027  (0.69021)\n",
            "     | > loss: 1.46889  (1.47161)\n",
            "     | > align_error: 0.98625  (0.98082)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.36349  (0.35241)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.93420  (1.21081)\n",
            "     | > loader_time: 0.02790  (0.01655)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 275/406 -- GLOBAL_STEP: 10425\u001b[0m\n",
            "     | > decoder_loss: 1.47033  (1.45802)\n",
            "     | > postnet_loss: 2.14089  (2.14828)\n",
            "     | > stopnet_loss: 0.00908  (0.01255)\n",
            "     | > ga_loss: 0.00260  (0.00410)\n",
            "     | > decoder_diff_spec_loss: 0.20063  (0.20218)\n",
            "     | > postnet_diff_spec_loss: 0.44581  (0.44808)\n",
            "     | > decoder_ssim_loss: 0.80389  (0.80191)\n",
            "     | > postnet_ssim_loss: 0.63080  (0.68490)\n",
            "     | > loss: 1.44518  (1.46890)\n",
            "     | > align_error: 0.98799  (0.98144)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.33238  (0.35055)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.93010  (1.25829)\n",
            "     | > loader_time: 0.02250  (0.01713)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 300/406 -- GLOBAL_STEP: 10450\u001b[0m\n",
            "     | > decoder_loss: 1.44421  (1.45857)\n",
            "     | > postnet_loss: 2.10397  (2.14722)\n",
            "     | > stopnet_loss: 0.00893  (0.01226)\n",
            "     | > ga_loss: 0.00252  (0.00397)\n",
            "     | > decoder_diff_spec_loss: 0.20004  (0.20206)\n",
            "     | > postnet_diff_spec_loss: 0.44393  (0.44783)\n",
            "     | > decoder_ssim_loss: 0.79754  (0.80174)\n",
            "     | > postnet_ssim_loss: 0.62847  (0.68049)\n",
            "     | > loss: 1.42609  (1.46660)\n",
            "     | > align_error: 0.98782  (0.98198)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.31810  (0.34911)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.99600  (1.30899)\n",
            "     | > loader_time: 0.02380  (0.01769)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 325/406 -- GLOBAL_STEP: 10475\u001b[0m\n",
            "     | > decoder_loss: 1.46344  (1.45876)\n",
            "     | > postnet_loss: 2.12207  (2.14567)\n",
            "     | > stopnet_loss: 0.00874  (0.01199)\n",
            "     | > ga_loss: 0.00240  (0.00386)\n",
            "     | > decoder_diff_spec_loss: 0.19980  (0.20199)\n",
            "     | > postnet_diff_spec_loss: 0.44295  (0.44764)\n",
            "     | > decoder_ssim_loss: 0.79734  (0.80158)\n",
            "     | > postnet_ssim_loss: 0.62651  (0.67656)\n",
            "     | > loss: 1.43375  (1.46433)\n",
            "     | > align_error: 0.98849  (0.98247)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.31462  (0.34737)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.99770  (1.35264)\n",
            "     | > loader_time: 0.03270  (0.01826)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 350/406 -- GLOBAL_STEP: 10500\u001b[0m\n",
            "     | > decoder_loss: 1.45658  (1.45974)\n",
            "     | > postnet_loss: 2.12240  (2.14439)\n",
            "     | > stopnet_loss: 0.00825  (0.01174)\n",
            "     | > ga_loss: 0.00228  (0.00375)\n",
            "     | > decoder_diff_spec_loss: 0.20081  (0.20183)\n",
            "     | > postnet_diff_spec_loss: 0.44468  (0.44734)\n",
            "     | > decoder_ssim_loss: 0.80355  (0.80147)\n",
            "     | > postnet_ssim_loss: 0.63156  (0.67315)\n",
            "     | > loss: 1.43452  (1.46249)\n",
            "     | > align_error: 0.98962  (0.98293)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.33142  (0.34594)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.04620  (1.39832)\n",
            "     | > loader_time: 0.02570  (0.01879)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 375/406 -- GLOBAL_STEP: 10525\u001b[0m\n",
            "     | > decoder_loss: 1.47678  (1.46006)\n",
            "     | > postnet_loss: 2.10091  (2.14296)\n",
            "     | > stopnet_loss: 0.00805  (0.01151)\n",
            "     | > ga_loss: 0.00238  (0.00365)\n",
            "     | > decoder_diff_spec_loss: 0.19719  (0.20167)\n",
            "     | > postnet_diff_spec_loss: 0.44157  (0.44707)\n",
            "     | > decoder_ssim_loss: 0.79971  (0.80132)\n",
            "     | > postnet_ssim_loss: 0.62785  (0.67021)\n",
            "     | > loss: 1.43093  (1.46061)\n",
            "     | > align_error: 0.98905  (0.98336)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.33164  (0.34465)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.24660  (1.44016)\n",
            "     | > loader_time: 0.02710  (0.01933)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 400/406 -- GLOBAL_STEP: 10550\u001b[0m\n",
            "     | > decoder_loss: 1.47518  (1.46059)\n",
            "     | > postnet_loss: 2.12015  (2.14137)\n",
            "     | > stopnet_loss: 0.00770  (0.01130)\n",
            "     | > ga_loss: 0.00214  (0.00356)\n",
            "     | > decoder_diff_spec_loss: 0.19871  (0.20157)\n",
            "     | > postnet_diff_spec_loss: 0.44155  (0.44685)\n",
            "     | > decoder_ssim_loss: 0.80211  (0.80127)\n",
            "     | > postnet_ssim_loss: 0.62824  (0.66754)\n",
            "     | > loss: 1.43488  (1.45890)\n",
            "     | > align_error: 0.99018  (0.98376)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.34567  (0.34339)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.86470  (1.48115)\n",
            "     | > loader_time: 0.02760  (0.01985)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01363 \u001b[0m(+0.00097)\n",
            "     | > avg_decoder_loss:\u001b[92m 1.97947 \u001b[0m(-0.10165)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.19678 \u001b[0m(-0.05551)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.05517 \u001b[0m(-0.00870)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00351 \u001b[0m(+0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.24103 \u001b[0m(-0.00260)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.45216 \u001b[0m(-0.00205)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.83228 \u001b[0m(-0.00730)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.61804 \u001b[0m(-0.01862)\n",
            "     | > avg_loss:\u001b[92m 1.65264 \u001b[0m(-0.05562)\n",
            "     | > avg_align_error:\u001b[92m 0.98896 \u001b[0m(-0.00004)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_10556.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 26/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 13:27:41) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 19/406 -- GLOBAL_STEP: 10575\u001b[0m\n",
            "     | > decoder_loss: 1.40896  (1.42778)\n",
            "     | > postnet_loss: 2.07393  (2.10319)\n",
            "     | > stopnet_loss: 0.01903  (0.02226)\n",
            "     | > ga_loss: 0.00664  (0.00927)\n",
            "     | > decoder_diff_spec_loss: 0.20806  (0.20258)\n",
            "     | > postnet_diff_spec_loss: 0.45521  (0.44928)\n",
            "     | > decoder_ssim_loss: 0.79213  (0.79364)\n",
            "     | > postnet_ssim_loss: 0.79431  (0.79577)\n",
            "     | > loss: 1.48538  (1.51168)\n",
            "     | > align_error: 0.97050  (0.96124)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30966  (0.34822)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.70600  (0.62356)\n",
            "     | > loader_time: 0.00920  (0.00965)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 44/406 -- GLOBAL_STEP: 10600\u001b[0m\n",
            "     | > decoder_loss: 1.41793  (1.42161)\n",
            "     | > postnet_loss: 2.09106  (2.09057)\n",
            "     | > stopnet_loss: 0.01454  (0.01868)\n",
            "     | > ga_loss: 0.00513  (0.00733)\n",
            "     | > decoder_diff_spec_loss: 0.20481  (0.20293)\n",
            "     | > postnet_diff_spec_loss: 0.44817  (0.44902)\n",
            "     | > decoder_ssim_loss: 0.79809  (0.79475)\n",
            "     | > postnet_ssim_loss: 0.79687  (0.79829)\n",
            "     | > loss: 1.47941  (1.49461)\n",
            "     | > align_error: 0.97820  (0.96865)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30043  (0.32374)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.92380  (0.70748)\n",
            "     | > loader_time: 0.01130  (0.01008)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 69/406 -- GLOBAL_STEP: 10625\u001b[0m\n",
            "     | > decoder_loss: 1.44928  (1.42500)\n",
            "     | > postnet_loss: 2.10676  (2.08703)\n",
            "     | > stopnet_loss: 0.01304  (0.01689)\n",
            "     | > ga_loss: 0.00451  (0.00643)\n",
            "     | > decoder_diff_spec_loss: 0.20781  (0.20251)\n",
            "     | > postnet_diff_spec_loss: 0.44940  (0.44823)\n",
            "     | > decoder_ssim_loss: 0.79935  (0.79576)\n",
            "     | > postnet_ssim_loss: 0.79968  (0.79916)\n",
            "     | > loss: 1.48866  (1.48848)\n",
            "     | > align_error: 0.97816  (0.97211)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30808  (0.31284)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.01070  (0.79390)\n",
            "     | > loader_time: 0.01380  (0.01094)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 94/406 -- GLOBAL_STEP: 10650\u001b[0m\n",
            "     | > decoder_loss: 1.44227  (1.42620)\n",
            "     | > postnet_loss: 2.07503  (2.08715)\n",
            "     | > stopnet_loss: 0.01205  (0.01566)\n",
            "     | > ga_loss: 0.00408  (0.00585)\n",
            "     | > decoder_diff_spec_loss: 0.20055  (0.20236)\n",
            "     | > postnet_diff_spec_loss: 0.44242  (0.44758)\n",
            "     | > decoder_ssim_loss: 0.80137  (0.79652)\n",
            "     | > postnet_ssim_loss: 0.62531  (0.76745)\n",
            "     | > loss: 1.42920  (1.47673)\n",
            "     | > align_error: 0.98167  (0.97446)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30063  (0.31225)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.25570  (0.86455)\n",
            "     | > loader_time: 0.01540  (0.01188)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 119/406 -- GLOBAL_STEP: 10675\u001b[0m\n",
            "     | > decoder_loss: 1.43370  (1.42778)\n",
            "     | > postnet_loss: 2.09667  (2.08557)\n",
            "     | > stopnet_loss: 0.01098  (0.01478)\n",
            "     | > ga_loss: 0.00374  (0.00543)\n",
            "     | > decoder_diff_spec_loss: 0.20153  (0.20233)\n",
            "     | > postnet_diff_spec_loss: 0.44378  (0.44729)\n",
            "     | > decoder_ssim_loss: 0.80157  (0.79687)\n",
            "     | > postnet_ssim_loss: 0.62658  (0.73700)\n",
            "     | > loss: 1.43062  (1.46612)\n",
            "     | > align_error: 0.98347  (0.97619)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30919  (0.31023)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.13830  (0.92739)\n",
            "     | > loader_time: 0.01580  (0.01265)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 144/406 -- GLOBAL_STEP: 10700\u001b[0m\n",
            "     | > decoder_loss: 1.42577  (1.42964)\n",
            "     | > postnet_loss: 2.07221  (2.08383)\n",
            "     | > stopnet_loss: 0.01061  (0.01410)\n",
            "     | > ga_loss: 0.00348  (0.00510)\n",
            "     | > decoder_diff_spec_loss: 0.20636  (0.20220)\n",
            "     | > postnet_diff_spec_loss: 0.44523  (0.44688)\n",
            "     | > decoder_ssim_loss: 0.80002  (0.79717)\n",
            "     | > postnet_ssim_loss: 0.61300  (0.71676)\n",
            "     | > loss: 1.41866  (1.45874)\n",
            "     | > align_error: 0.98392  (0.97745)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30988  (0.31050)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.39100  (0.98616)\n",
            "     | > loader_time: 0.01730  (0.01340)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 169/406 -- GLOBAL_STEP: 10725\u001b[0m\n",
            "     | > decoder_loss: 1.47253  (1.43065)\n",
            "     | > postnet_loss: 2.10386  (2.08178)\n",
            "     | > stopnet_loss: 0.01008  (0.01355)\n",
            "     | > ga_loss: 0.00330  (0.00484)\n",
            "     | > decoder_diff_spec_loss: 0.20390  (0.20218)\n",
            "     | > postnet_diff_spec_loss: 0.44705  (0.44661)\n",
            "     | > decoder_ssim_loss: 0.79837  (0.79713)\n",
            "     | > postnet_ssim_loss: 0.63053  (0.70249)\n",
            "     | > loss: 1.44065  (1.45298)\n",
            "     | > align_error: 0.98520  (0.97849)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28956  (0.30931)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.37350  (1.03983)\n",
            "     | > loader_time: 0.01870  (0.01404)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 194/406 -- GLOBAL_STEP: 10750\u001b[0m\n",
            "     | > decoder_loss: 1.45778  (1.43264)\n",
            "     | > postnet_loss: 2.07426  (2.08065)\n",
            "     | > stopnet_loss: 0.00945  (0.01308)\n",
            "     | > ga_loss: 0.00315  (0.00463)\n",
            "     | > decoder_diff_spec_loss: 0.19965  (0.20196)\n",
            "     | > postnet_diff_spec_loss: 0.44218  (0.44612)\n",
            "     | > decoder_ssim_loss: 0.80047  (0.79714)\n",
            "     | > postnet_ssim_loss: 0.61816  (0.69170)\n",
            "     | > loss: 1.42333  (1.44877)\n",
            "     | > align_error: 0.98751  (0.97942)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28805  (0.30869)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.45620  (1.09098)\n",
            "     | > loader_time: 0.01910  (0.01471)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 219/406 -- GLOBAL_STEP: 10775\u001b[0m\n",
            "     | > decoder_loss: 1.44723  (1.43371)\n",
            "     | > postnet_loss: 2.07195  (2.07918)\n",
            "     | > stopnet_loss: 0.00926  (0.01268)\n",
            "     | > ga_loss: 0.00287  (0.00444)\n",
            "     | > decoder_diff_spec_loss: 0.20226  (0.20187)\n",
            "     | > postnet_diff_spec_loss: 0.44647  (0.44581)\n",
            "     | > decoder_ssim_loss: 0.79837  (0.79728)\n",
            "     | > postnet_ssim_loss: 0.61570  (0.68332)\n",
            "     | > loss: 1.41911  (1.44517)\n",
            "     | > align_error: 0.98747  (0.98021)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.29374  (0.30814)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.60480  (1.13932)\n",
            "     | > loader_time: 0.02110  (0.01536)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 244/406 -- GLOBAL_STEP: 10800\u001b[0m\n",
            "     | > decoder_loss: 1.43109  (1.43529)\n",
            "     | > postnet_loss: 2.04827  (2.07863)\n",
            "     | > stopnet_loss: 0.00894  (0.01231)\n",
            "     | > ga_loss: 0.00281  (0.00428)\n",
            "     | > decoder_diff_spec_loss: 0.20354  (0.20176)\n",
            "     | > postnet_diff_spec_loss: 0.44755  (0.44551)\n",
            "     | > decoder_ssim_loss: 0.79598  (0.79728)\n",
            "     | > postnet_ssim_loss: 0.60567  (0.67654)\n",
            "     | > loss: 1.40602  (1.44246)\n",
            "     | > align_error: 0.98708  (0.98090)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28711  (0.30820)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.70640  (1.19009)\n",
            "     | > loader_time: 0.02160  (0.01602)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 269/406 -- GLOBAL_STEP: 10825\u001b[0m\n",
            "     | > decoder_loss: 1.47149  (1.43582)\n",
            "     | > postnet_loss: 2.07320  (2.07665)\n",
            "     | > stopnet_loss: 0.00868  (0.01199)\n",
            "     | > ga_loss: 0.00258  (0.00413)\n",
            "     | > decoder_diff_spec_loss: 0.19978  (0.20164)\n",
            "     | > postnet_diff_spec_loss: 0.44082  (0.44521)\n",
            "     | > decoder_ssim_loss: 0.79946  (0.79723)\n",
            "     | > postnet_ssim_loss: 0.61711  (0.67085)\n",
            "     | > loss: 1.42203  (1.43949)\n",
            "     | > align_error: 0.98814  (0.98154)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.29932  (0.30704)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.79340  (1.23933)\n",
            "     | > loader_time: 0.02210  (0.01665)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 294/406 -- GLOBAL_STEP: 10850\u001b[0m\n",
            "     | > decoder_loss: 1.45406  (1.43663)\n",
            "     | > postnet_loss: 2.08028  (2.07544)\n",
            "     | > stopnet_loss: 0.00862  (0.01170)\n",
            "     | > ga_loss: 0.00255  (0.00400)\n",
            "     | > decoder_diff_spec_loss: 0.19672  (0.20154)\n",
            "     | > postnet_diff_spec_loss: 0.43903  (0.44495)\n",
            "     | > decoder_ssim_loss: 0.79806  (0.79715)\n",
            "     | > postnet_ssim_loss: 0.62226  (0.66611)\n",
            "     | > loss: 1.41899  (1.43716)\n",
            "     | > align_error: 0.98867  (0.98209)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.29991  (0.30625)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.72760  (1.28479)\n",
            "     | > loader_time: 0.02370  (0.01721)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 319/406 -- GLOBAL_STEP: 10875\u001b[0m\n",
            "     | > decoder_loss: 1.42976  (1.43675)\n",
            "     | > postnet_loss: 2.04268  (2.07375)\n",
            "     | > stopnet_loss: 0.00796  (0.01143)\n",
            "     | > ga_loss: 0.00244  (0.00388)\n",
            "     | > decoder_diff_spec_loss: 0.19926  (0.20146)\n",
            "     | > postnet_diff_spec_loss: 0.43932  (0.44471)\n",
            "     | > decoder_ssim_loss: 0.79720  (0.79710)\n",
            "     | > postnet_ssim_loss: 0.61497  (0.66202)\n",
            "     | > loss: 1.40096  (1.43479)\n",
            "     | > align_error: 0.98869  (0.98260)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30534  (0.30553)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.92100  (1.33031)\n",
            "     | > loader_time: 0.02420  (0.01777)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 344/406 -- GLOBAL_STEP: 10900\u001b[0m\n",
            "     | > decoder_loss: 1.44345  (1.43750)\n",
            "     | > postnet_loss: 2.02439  (2.07218)\n",
            "     | > stopnet_loss: 0.00791  (0.01119)\n",
            "     | > ga_loss: 0.00236  (0.00378)\n",
            "     | > decoder_diff_spec_loss: 0.19694  (0.20138)\n",
            "     | > postnet_diff_spec_loss: 0.43846  (0.44445)\n",
            "     | > decoder_ssim_loss: 0.79346  (0.79705)\n",
            "     | > postnet_ssim_loss: 0.60588  (0.65836)\n",
            "     | > loss: 1.39533  (1.43279)\n",
            "     | > align_error: 0.98954  (0.98305)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28225  (0.30485)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.94400  (1.37507)\n",
            "     | > loader_time: 0.02500  (0.01835)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 369/406 -- GLOBAL_STEP: 10925\u001b[0m\n",
            "     | > decoder_loss: 1.40976  (1.43776)\n",
            "     | > postnet_loss: 2.01281  (2.07044)\n",
            "     | > stopnet_loss: 0.00726  (0.01095)\n",
            "     | > ga_loss: 0.00220  (0.00368)\n",
            "     | > decoder_diff_spec_loss: 0.19863  (0.20125)\n",
            "     | > postnet_diff_spec_loss: 0.44113  (0.44416)\n",
            "     | > decoder_ssim_loss: 0.79329  (0.79701)\n",
            "     | > postnet_ssim_loss: 0.61017  (0.65528)\n",
            "     | > loss: 1.38469  (1.43081)\n",
            "     | > align_error: 0.99143  (0.98348)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28004  (0.30444)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.14770  (1.42100)\n",
            "     | > loader_time: 0.02700  (0.01893)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 394/406 -- GLOBAL_STEP: 10950\u001b[0m\n",
            "     | > decoder_loss: 1.44658  (1.43807)\n",
            "     | > postnet_loss: 2.03306  (2.06844)\n",
            "     | > stopnet_loss: 0.00752  (0.01074)\n",
            "     | > ga_loss: 0.00212  (0.00358)\n",
            "     | > decoder_diff_spec_loss: 0.20178  (0.20115)\n",
            "     | > postnet_diff_spec_loss: 0.44267  (0.44392)\n",
            "     | > decoder_ssim_loss: 0.79794  (0.79698)\n",
            "     | > postnet_ssim_loss: 0.60468  (0.65246)\n",
            "     | > loss: 1.39979  (1.42890)\n",
            "     | > align_error: 0.98967  (0.98388)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.29395  (0.30375)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.10830  (1.46683)\n",
            "     | > loader_time: 0.02770  (0.01950)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01442 \u001b[0m(+0.00078)\n",
            "     | > avg_decoder_loss:\u001b[92m 1.86201 \u001b[0m(-0.11746)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.12988 \u001b[0m(-0.06690)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.04475 \u001b[0m(-0.01042)\n",
            "     | > avg_ga_loss:\u001b[91m 0.00352 \u001b[0m(+0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.23913 \u001b[0m(-0.00190)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.44961 \u001b[0m(-0.00255)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.82424 \u001b[0m(-0.00804)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.60125 \u001b[0m(-0.01679)\n",
            "     | > avg_loss:\u001b[92m 1.58887 \u001b[0m(-0.06377)\n",
            "     | > avg_align_error:\u001b[92m 0.98895 \u001b[0m(-0.00001)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_10962.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 27/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 13:38:11) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 13/406 -- GLOBAL_STEP: 10975\u001b[0m\n",
            "     | > decoder_loss: 1.39683  (1.41175)\n",
            "     | > postnet_loss: 2.02850  (2.03422)\n",
            "     | > stopnet_loss: 0.01954  (0.02387)\n",
            "     | > ga_loss: 0.00762  (0.01022)\n",
            "     | > decoder_diff_spec_loss: 0.20012  (0.20148)\n",
            "     | > postnet_diff_spec_loss: 0.44205  (0.44499)\n",
            "     | > decoder_ssim_loss: 0.79108  (0.78916)\n",
            "     | > postnet_ssim_loss: 0.78899  (0.78276)\n",
            "     | > loss: 1.46955  (1.49105)\n",
            "     | > align_error: 0.96628  (0.95809)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30189  (0.34463)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.61910  (0.56238)\n",
            "     | > loader_time: 0.00840  (0.00807)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 38/406 -- GLOBAL_STEP: 11000\u001b[0m\n",
            "     | > decoder_loss: 1.38669  (1.40486)\n",
            "     | > postnet_loss: 1.99847  (2.01991)\n",
            "     | > stopnet_loss: 0.01481  (0.01898)\n",
            "     | > ga_loss: 0.00564  (0.00765)\n",
            "     | > decoder_diff_spec_loss: 0.20220  (0.20285)\n",
            "     | > postnet_diff_spec_loss: 0.44650  (0.44596)\n",
            "     | > decoder_ssim_loss: 0.79202  (0.79155)\n",
            "     | > postnet_ssim_loss: 0.78987  (0.78756)\n",
            "     | > loss: 1.44696  (1.47043)\n",
            "     | > align_error: 0.97449  (0.96764)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28563  (0.31164)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.85770  (0.68928)\n",
            "     | > loader_time: 0.01090  (0.00925)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_11000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 63/406 -- GLOBAL_STEP: 11025\u001b[0m\n",
            "     | > decoder_loss: 1.42852  (1.40470)\n",
            "     | > postnet_loss: 1.99679  (2.01284)\n",
            "     | > stopnet_loss: 0.01287  (0.01692)\n",
            "     | > ga_loss: 0.00465  (0.00662)\n",
            "     | > decoder_diff_spec_loss: 0.19829  (0.20258)\n",
            "     | > postnet_diff_spec_loss: 0.43841  (0.44518)\n",
            "     | > decoder_ssim_loss: 0.79509  (0.79258)\n",
            "     | > postnet_ssim_loss: 0.78806  (0.78834)\n",
            "     | > loss: 1.44738  (1.46156)\n",
            "     | > align_error: 0.97847  (0.97162)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.29370  (0.29930)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.99700  (0.77410)\n",
            "     | > loader_time: 0.01270  (0.01039)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 88/406 -- GLOBAL_STEP: 11050\u001b[0m\n",
            "     | > decoder_loss: 1.38216  (1.40577)\n",
            "     | > postnet_loss: 2.00006  (2.01267)\n",
            "     | > stopnet_loss: 0.01158  (0.01561)\n",
            "     | > ga_loss: 0.00420  (0.00598)\n",
            "     | > decoder_diff_spec_loss: 0.20348  (0.20252)\n",
            "     | > postnet_diff_spec_loss: 0.44306  (0.44457)\n",
            "     | > decoder_ssim_loss: 0.79532  (0.79340)\n",
            "     | > postnet_ssim_loss: 0.60383  (0.76593)\n",
            "     | > loss: 1.38957  (1.45170)\n",
            "     | > align_error: 0.98195  (0.97415)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30331  (0.29642)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.12530  (0.85207)\n",
            "     | > loader_time: 0.01480  (0.01151)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 113/406 -- GLOBAL_STEP: 11075\u001b[0m\n",
            "     | > decoder_loss: 1.42078  (1.40713)\n",
            "     | > postnet_loss: 2.02423  (2.01134)\n",
            "     | > stopnet_loss: 0.01077  (0.01465)\n",
            "     | > ga_loss: 0.00385  (0.00552)\n",
            "     | > decoder_diff_spec_loss: 0.19874  (0.20250)\n",
            "     | > postnet_diff_spec_loss: 0.43906  (0.44418)\n",
            "     | > decoder_ssim_loss: 0.79205  (0.79394)\n",
            "     | > postnet_ssim_loss: 0.60604  (0.73046)\n",
            "     | > loss: 1.40022  (1.43966)\n",
            "     | > align_error: 0.98234  (0.97603)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.29561  (0.29476)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.18380  (0.91729)\n",
            "     | > loader_time: 0.01700  (0.01235)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 138/406 -- GLOBAL_STEP: 11100\u001b[0m\n",
            "     | > decoder_loss: 1.42857  (1.40859)\n",
            "     | > postnet_loss: 1.99727  (2.00952)\n",
            "     | > stopnet_loss: 0.01024  (0.01391)\n",
            "     | > ga_loss: 0.00363  (0.00519)\n",
            "     | > decoder_diff_spec_loss: 0.20196  (0.20232)\n",
            "     | > postnet_diff_spec_loss: 0.44027  (0.44364)\n",
            "     | > decoder_ssim_loss: 0.79824  (0.79425)\n",
            "     | > postnet_ssim_loss: 0.60162  (0.70785)\n",
            "     | > loss: 1.39539  (1.43139)\n",
            "     | > align_error: 0.98332  (0.97737)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30614  (0.29476)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.30150  (0.97453)\n",
            "     | > loader_time: 0.01700  (0.01316)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 163/406 -- GLOBAL_STEP: 11125\u001b[0m\n",
            "     | > decoder_loss: 1.43899  (1.40889)\n",
            "     | > postnet_loss: 2.03348  (2.00674)\n",
            "     | > stopnet_loss: 0.01005  (0.01333)\n",
            "     | > ga_loss: 0.00328  (0.00491)\n",
            "     | > decoder_diff_spec_loss: 0.19909  (0.20235)\n",
            "     | > postnet_diff_spec_loss: 0.43751  (0.44340)\n",
            "     | > decoder_ssim_loss: 0.79601  (0.79428)\n",
            "     | > postnet_ssim_loss: 0.60686  (0.69162)\n",
            "     | > loss: 1.40446  (1.42471)\n",
            "     | > align_error: 0.98364  (0.97843)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30540  (0.29372)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.31960  (1.02968)\n",
            "     | > loader_time: 0.01800  (0.01399)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 188/406 -- GLOBAL_STEP: 11150\u001b[0m\n",
            "     | > decoder_loss: 1.49465  (1.41072)\n",
            "     | > postnet_loss: 2.04327  (2.00544)\n",
            "     | > stopnet_loss: 0.00954  (0.01282)\n",
            "     | > ga_loss: 0.00328  (0.00469)\n",
            "     | > decoder_diff_spec_loss: 0.19616  (0.20217)\n",
            "     | > postnet_diff_spec_loss: 0.43264  (0.44295)\n",
            "     | > decoder_ssim_loss: 0.79988  (0.79435)\n",
            "     | > postnet_ssim_loss: 0.60216  (0.67991)\n",
            "     | > loss: 1.41814  (1.42014)\n",
            "     | > align_error: 0.98465  (0.97939)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.31281  (0.29269)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.50030  (1.07877)\n",
            "     | > loader_time: 0.01850  (0.01459)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 213/406 -- GLOBAL_STEP: 11175\u001b[0m\n",
            "     | > decoder_loss: 1.40829  (1.41166)\n",
            "     | > postnet_loss: 2.00134  (2.00356)\n",
            "     | > stopnet_loss: 0.00904  (0.01240)\n",
            "     | > ga_loss: 0.00296  (0.00449)\n",
            "     | > decoder_diff_spec_loss: 0.20269  (0.20210)\n",
            "     | > postnet_diff_spec_loss: 0.43855  (0.44255)\n",
            "     | > decoder_ssim_loss: 0.79082  (0.79448)\n",
            "     | > postnet_ssim_loss: 0.60121  (0.67077)\n",
            "     | > loss: 1.38455  (1.41614)\n",
            "     | > align_error: 0.98602  (0.98019)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30207  (0.29216)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.47260  (1.12769)\n",
            "     | > loader_time: 0.02040  (0.01523)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 238/406 -- GLOBAL_STEP: 11200\u001b[0m\n",
            "     | > decoder_loss: 1.42499  (1.41306)\n",
            "     | > postnet_loss: 2.00932  (2.00246)\n",
            "     | > stopnet_loss: 0.00878  (0.01203)\n",
            "     | > ga_loss: 0.00284  (0.00432)\n",
            "     | > decoder_diff_spec_loss: 0.19934  (0.20200)\n",
            "     | > postnet_diff_spec_loss: 0.43693  (0.44225)\n",
            "     | > decoder_ssim_loss: 0.79388  (0.79455)\n",
            "     | > postnet_ssim_loss: 0.59792  (0.66344)\n",
            "     | > loss: 1.38858  (1.41308)\n",
            "     | > align_error: 0.98640  (0.98090)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.31830  (0.29208)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.69480  (1.17681)\n",
            "     | > loader_time: 0.02730  (0.01587)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 263/406 -- GLOBAL_STEP: 11225\u001b[0m\n",
            "     | > decoder_loss: 1.44287  (1.41363)\n",
            "     | > postnet_loss: 1.99631  (2.00063)\n",
            "     | > stopnet_loss: 0.00864  (0.01168)\n",
            "     | > ga_loss: 0.00271  (0.00417)\n",
            "     | > decoder_diff_spec_loss: 0.20378  (0.20189)\n",
            "     | > postnet_diff_spec_loss: 0.44067  (0.44196)\n",
            "     | > decoder_ssim_loss: 0.79635  (0.79453)\n",
            "     | > postnet_ssim_loss: 0.59252  (0.65744)\n",
            "     | > loss: 1.39033  (1.41007)\n",
            "     | > align_error: 0.98796  (0.98154)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28003  (0.29125)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.84500  (1.22613)\n",
            "     | > loader_time: 0.02270  (0.01650)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 288/406 -- GLOBAL_STEP: 11250\u001b[0m\n",
            "     | > decoder_loss: 1.40534  (1.41402)\n",
            "     | > postnet_loss: 1.97370  (1.99889)\n",
            "     | > stopnet_loss: 0.00810  (0.01138)\n",
            "     | > ga_loss: 0.00259  (0.00404)\n",
            "     | > decoder_diff_spec_loss: 0.19880  (0.20181)\n",
            "     | > postnet_diff_spec_loss: 0.43908  (0.44168)\n",
            "     | > decoder_ssim_loss: 0.79066  (0.79448)\n",
            "     | > postnet_ssim_loss: 0.59674  (0.65235)\n",
            "     | > loss: 1.37212  (1.40739)\n",
            "     | > align_error: 0.98963  (0.98209)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27028  (0.29048)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.67470  (1.27264)\n",
            "     | > loader_time: 0.02290  (0.01709)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 313/406 -- GLOBAL_STEP: 11275\u001b[0m\n",
            "     | > decoder_loss: 1.40596  (1.41430)\n",
            "     | > postnet_loss: 1.95788  (1.99730)\n",
            "     | > stopnet_loss: 0.00798  (0.01111)\n",
            "     | > ga_loss: 0.00248  (0.00392)\n",
            "     | > decoder_diff_spec_loss: 0.20166  (0.20171)\n",
            "     | > postnet_diff_spec_loss: 0.43833  (0.44141)\n",
            "     | > decoder_ssim_loss: 0.78797  (0.79444)\n",
            "     | > postnet_ssim_loss: 0.59403  (0.64810)\n",
            "     | > loss: 1.36686  (1.40502)\n",
            "     | > align_error: 0.98791  (0.98260)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27440  (0.28987)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.78500  (1.31992)\n",
            "     | > loader_time: 0.02480  (0.01763)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 338/406 -- GLOBAL_STEP: 11300\u001b[0m\n",
            "     | > decoder_loss: 1.41463  (1.41452)\n",
            "     | > postnet_loss: 1.95843  (1.99537)\n",
            "     | > stopnet_loss: 0.00762  (0.01086)\n",
            "     | > ga_loss: 0.00239  (0.00381)\n",
            "     | > decoder_diff_spec_loss: 0.19934  (0.20165)\n",
            "     | > postnet_diff_spec_loss: 0.43640  (0.44115)\n",
            "     | > decoder_ssim_loss: 0.79520  (0.79437)\n",
            "     | > postnet_ssim_loss: 0.59823  (0.64428)\n",
            "     | > loss: 1.37012  (1.40273)\n",
            "     | > align_error: 0.99012  (0.98306)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26927  (0.28923)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.98360  (1.36255)\n",
            "     | > loader_time: 0.02530  (0.01821)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 363/406 -- GLOBAL_STEP: 11325\u001b[0m\n",
            "     | > decoder_loss: 1.42407  (1.41481)\n",
            "     | > postnet_loss: 1.97519  (1.99329)\n",
            "     | > stopnet_loss: 0.00741  (0.01063)\n",
            "     | > ga_loss: 0.00223  (0.00371)\n",
            "     | > decoder_diff_spec_loss: 0.20307  (0.20153)\n",
            "     | > postnet_diff_spec_loss: 0.43761  (0.44085)\n",
            "     | > decoder_ssim_loss: 0.79329  (0.79434)\n",
            "     | > postnet_ssim_loss: 0.59695  (0.64100)\n",
            "     | > loss: 1.37610  (1.40061)\n",
            "     | > align_error: 0.98926  (0.98349)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.29984  (0.28907)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.17060  (1.40712)\n",
            "     | > loader_time: 0.02610  (0.01875)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 388/406 -- GLOBAL_STEP: 11350\u001b[0m\n",
            "     | > decoder_loss: 1.41997  (1.41487)\n",
            "     | > postnet_loss: 1.94233  (1.99115)\n",
            "     | > stopnet_loss: 0.00716  (0.01041)\n",
            "     | > ga_loss: 0.00219  (0.00361)\n",
            "     | > decoder_diff_spec_loss: 0.20311  (0.20145)\n",
            "     | > postnet_diff_spec_loss: 0.43887  (0.44061)\n",
            "     | > decoder_ssim_loss: 0.79053  (0.79431)\n",
            "     | > postnet_ssim_loss: 0.59101  (0.63809)\n",
            "     | > loss: 1.36455  (1.39858)\n",
            "     | > align_error: 0.98945  (0.98389)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28385  (0.28853)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.04000  (1.45067)\n",
            "     | > loader_time: 0.02770  (0.01933)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.01530 \u001b[0m(+0.00089)\n",
            "     | > avg_decoder_loss:\u001b[92m 1.80604 \u001b[0m(-0.05597)\n",
            "     | > avg_postnet_loss:\u001b[92m 2.06600 \u001b[0m(-0.06389)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.04152 \u001b[0m(-0.00324)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00350 \u001b[0m(-0.00001)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[92m 0.23646 \u001b[0m(-0.00267)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.44706 \u001b[0m(-0.00255)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.81822 \u001b[0m(-0.00602)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.58412 \u001b[0m(-0.01713)\n",
            "     | > avg_loss:\u001b[92m 1.54851 \u001b[0m(-0.04036)\n",
            "     | > avg_align_error:\u001b[92m 0.98894 \u001b[0m(-0.00001)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_11368.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 28/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 13:48:44) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 7/406 -- GLOBAL_STEP: 11375\u001b[0m\n",
            "     | > decoder_loss: 1.39288  (1.39249)\n",
            "     | > postnet_loss: 1.96537  (1.95619)\n",
            "     | > stopnet_loss: 0.02312  (0.02609)\n",
            "     | > ga_loss: 0.00931  (0.01172)\n",
            "     | > decoder_diff_spec_loss: 0.20061  (0.20009)\n",
            "     | > postnet_diff_spec_loss: 0.43613  (0.43959)\n",
            "     | > decoder_ssim_loss: 0.78706  (0.78518)\n",
            "     | > postnet_ssim_loss: 0.78015  (0.77160)\n",
            "     | > loss: 1.46022  (1.47099)\n",
            "     | > align_error: 0.95801  (0.95331)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.35726  (0.36777)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.48790  (0.51258)\n",
            "     | > loader_time: 0.00650  (0.00706)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 32/406 -- GLOBAL_STEP: 11400\u001b[0m\n",
            "     | > decoder_loss: 1.39003  (1.38755)\n",
            "     | > postnet_loss: 1.91459  (1.94552)\n",
            "     | > stopnet_loss: 0.01545  (0.01963)\n",
            "     | > ga_loss: 0.00595  (0.00805)\n",
            "     | > decoder_diff_spec_loss: 0.20058  (0.20360)\n",
            "     | > postnet_diff_spec_loss: 0.43898  (0.44265)\n",
            "     | > decoder_ssim_loss: 0.79010  (0.78844)\n",
            "     | > postnet_ssim_loss: 0.77840  (0.77589)\n",
            "     | > loss: 1.42339  (1.44577)\n",
            "     | > align_error: 0.97419  (0.96589)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27443  (0.31306)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.75240  (0.64618)\n",
            "     | > loader_time: 0.01000  (0.00870)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 57/406 -- GLOBAL_STEP: 11425\u001b[0m\n",
            "     | > decoder_loss: 1.34751  (1.38444)\n",
            "     | > postnet_loss: 1.89630  (1.93732)\n",
            "     | > stopnet_loss: 0.01279  (0.01716)\n",
            "     | > ga_loss: 0.00486  (0.00682)\n",
            "     | > decoder_diff_spec_loss: 0.20533  (0.20321)\n",
            "     | > postnet_diff_spec_loss: 0.44471  (0.44187)\n",
            "     | > decoder_ssim_loss: 0.78662  (0.78946)\n",
            "     | > postnet_ssim_loss: 0.77832  (0.77726)\n",
            "     | > loss: 1.40178  (1.43466)\n",
            "     | > align_error: 0.98028  (0.97077)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26539  (0.29730)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.89610  (0.74256)\n",
            "     | > loader_time: 0.01290  (0.00990)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 82/406 -- GLOBAL_STEP: 11450\u001b[0m\n",
            "     | > decoder_loss: 1.42865  (1.38472)\n",
            "     | > postnet_loss: 1.95300  (1.93561)\n",
            "     | > stopnet_loss: 0.01135  (0.01568)\n",
            "     | > ga_loss: 0.00426  (0.00612)\n",
            "     | > decoder_diff_spec_loss: 0.20116  (0.20322)\n",
            "     | > postnet_diff_spec_loss: 0.43541  (0.44129)\n",
            "     | > decoder_ssim_loss: 0.79359  (0.79035)\n",
            "     | > postnet_ssim_loss: 0.59067  (0.76613)\n",
            "     | > loss: 1.38330  (1.42662)\n",
            "     | > align_error: 0.98325  (0.97348)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.29766  (0.29149)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.05890  (0.82005)\n",
            "     | > loader_time: 0.01440  (0.01117)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 107/406 -- GLOBAL_STEP: 11475\u001b[0m\n",
            "     | > decoder_loss: 1.33472  (1.38468)\n",
            "     | > postnet_loss: 1.88651  (1.93338)\n",
            "     | > stopnet_loss: 0.01085  (0.01465)\n",
            "     | > ga_loss: 0.00373  (0.00563)\n",
            "     | > decoder_diff_spec_loss: 0.20343  (0.20314)\n",
            "     | > postnet_diff_spec_loss: 0.44261  (0.44070)\n",
            "     | > decoder_ssim_loss: 0.79354  (0.79129)\n",
            "     | > postnet_ssim_loss: 0.58745  (0.72538)\n",
            "     | > loss: 1.34156  (1.41246)\n",
            "     | > align_error: 0.98144  (0.97552)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28202  (0.28936)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.09580  (0.88980)\n",
            "     | > loader_time: 0.01550  (0.01212)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 132/406 -- GLOBAL_STEP: 11500\u001b[0m\n",
            "     | > decoder_loss: 1.38448  (1.38465)\n",
            "     | > postnet_loss: 1.91808  (1.93139)\n",
            "     | > stopnet_loss: 0.01010  (0.01386)\n",
            "     | > ga_loss: 0.00370  (0.00527)\n",
            "     | > decoder_diff_spec_loss: 0.19788  (0.20303)\n",
            "     | > postnet_diff_spec_loss: 0.43271  (0.44027)\n",
            "     | > decoder_ssim_loss: 0.79706  (0.79155)\n",
            "     | > postnet_ssim_loss: 0.59695  (0.69981)\n",
            "     | > loss: 1.36037  (1.40289)\n",
            "     | > align_error: 0.98221  (0.97698)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.30573  (0.28806)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.23530  (0.95575)\n",
            "     | > loader_time: 0.01670  (0.01303)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 157/406 -- GLOBAL_STEP: 11525\u001b[0m\n",
            "     | > decoder_loss: 1.36600  (1.38479)\n",
            "     | > postnet_loss: 1.91436  (1.92828)\n",
            "     | > stopnet_loss: 0.00932  (0.01323)\n",
            "     | > ga_loss: 0.00339  (0.00498)\n",
            "     | > decoder_diff_spec_loss: 0.19903  (0.20305)\n",
            "     | > postnet_diff_spec_loss: 0.43403  (0.43994)\n",
            "     | > decoder_ssim_loss: 0.79296  (0.79168)\n",
            "     | > postnet_ssim_loss: 0.59308  (0.68198)\n",
            "     | > loss: 1.35114  (1.39558)\n",
            "     | > align_error: 0.98414  (0.97810)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28849  (0.28723)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.32450  (1.01095)\n",
            "     | > loader_time: 0.01770  (0.01372)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 182/406 -- GLOBAL_STEP: 11550\u001b[0m\n",
            "     | > decoder_loss: 1.39271  (1.38596)\n",
            "     | > postnet_loss: 1.89360  (1.92658)\n",
            "     | > stopnet_loss: 0.00931  (0.01272)\n",
            "     | > ga_loss: 0.00321  (0.00474)\n",
            "     | > decoder_diff_spec_loss: 0.19989  (0.20292)\n",
            "     | > postnet_diff_spec_loss: 0.43299  (0.43951)\n",
            "     | > decoder_ssim_loss: 0.78700  (0.79169)\n",
            "     | > postnet_ssim_loss: 0.58108  (0.66925)\n",
            "     | > loss: 1.34717  (1.39042)\n",
            "     | > align_error: 0.98513  (0.97905)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27333  (0.28588)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.46440  (1.06343)\n",
            "     | > loader_time: 0.01940  (0.01441)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 207/406 -- GLOBAL_STEP: 11575\u001b[0m\n",
            "     | > decoder_loss: 1.37796  (1.38691)\n",
            "     | > postnet_loss: 1.90091  (1.92462)\n",
            "     | > stopnet_loss: 0.00892  (0.01227)\n",
            "     | > ga_loss: 0.00301  (0.00454)\n",
            "     | > decoder_diff_spec_loss: 0.20376  (0.20277)\n",
            "     | > postnet_diff_spec_loss: 0.43554  (0.43906)\n",
            "     | > decoder_ssim_loss: 0.78902  (0.79186)\n",
            "     | > postnet_ssim_loss: 0.58776  (0.65954)\n",
            "     | > loss: 1.34769  (1.38617)\n",
            "     | > align_error: 0.98601  (0.97990)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26767  (0.28523)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.59440  (1.11038)\n",
            "     | > loader_time: 0.01960  (0.01507)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 232/406 -- GLOBAL_STEP: 11600\u001b[0m\n",
            "     | > decoder_loss: 1.36956  (1.38762)\n",
            "     | > postnet_loss: 1.90355  (1.92311)\n",
            "     | > stopnet_loss: 0.00816  (0.01188)\n",
            "     | > ga_loss: 0.00278  (0.00437)\n",
            "     | > decoder_diff_spec_loss: 0.20362  (0.20272)\n",
            "     | > postnet_diff_spec_loss: 0.43687  (0.43878)\n",
            "     | > decoder_ssim_loss: 0.79138  (0.79196)\n",
            "     | > postnet_ssim_loss: 0.57976  (0.65170)\n",
            "     | > loss: 1.34325  (1.38269)\n",
            "     | > align_error: 0.98845  (0.98062)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27559  (0.28468)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.55630  (1.16016)\n",
            "     | > loader_time: 0.02090  (0.01568)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 257/406 -- GLOBAL_STEP: 11625\u001b[0m\n",
            "     | > decoder_loss: 1.35791  (1.38843)\n",
            "     | > postnet_loss: 1.88589  (1.92129)\n",
            "     | > stopnet_loss: 0.00800  (0.01153)\n",
            "     | > ga_loss: 0.00263  (0.00421)\n",
            "     | > decoder_diff_spec_loss: 0.20281  (0.20262)\n",
            "     | > postnet_diff_spec_loss: 0.43678  (0.43845)\n",
            "     | > decoder_ssim_loss: 0.78963  (0.79196)\n",
            "     | > postnet_ssim_loss: 0.58046  (0.64525)\n",
            "     | > loss: 1.33454  (1.37960)\n",
            "     | > align_error: 0.98742  (0.98127)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27264  (0.28406)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.79840  (1.20997)\n",
            "     | > loader_time: 0.02290  (0.01627)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 282/406 -- GLOBAL_STEP: 11650\u001b[0m\n",
            "     | > decoder_loss: 1.39530  (1.38860)\n",
            "     | > postnet_loss: 1.90758  (1.91955)\n",
            "     | > stopnet_loss: 0.00811  (0.01123)\n",
            "     | > ga_loss: 0.00261  (0.00407)\n",
            "     | > decoder_diff_spec_loss: 0.20044  (0.20255)\n",
            "     | > postnet_diff_spec_loss: 0.43459  (0.43816)\n",
            "     | > decoder_ssim_loss: 0.79694  (0.79196)\n",
            "     | > postnet_ssim_loss: 0.59158  (0.63994)\n",
            "     | > loss: 1.35275  (1.37679)\n",
            "     | > align_error: 0.98760  (0.98184)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28171  (0.28330)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.85260  (1.25774)\n",
            "     | > loader_time: 0.02340  (0.01696)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 307/406 -- GLOBAL_STEP: 11675\u001b[0m\n",
            "     | > decoder_loss: 1.38286  (1.38872)\n",
            "     | > postnet_loss: 1.87451  (1.91775)\n",
            "     | > stopnet_loss: 0.00772  (0.01094)\n",
            "     | > ga_loss: 0.00256  (0.00395)\n",
            "     | > decoder_diff_spec_loss: 0.20015  (0.20245)\n",
            "     | > postnet_diff_spec_loss: 0.43305  (0.43785)\n",
            "     | > decoder_ssim_loss: 0.79218  (0.79192)\n",
            "     | > postnet_ssim_loss: 0.58274  (0.63551)\n",
            "     | > loss: 1.33692  (1.37425)\n",
            "     | > align_error: 0.98837  (0.98236)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27194  (0.28266)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.78170  (1.30321)\n",
            "     | > loader_time: 0.02400  (0.01751)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 332/406 -- GLOBAL_STEP: 11700\u001b[0m\n",
            "     | > decoder_loss: 1.37092  (1.38839)\n",
            "     | > postnet_loss: 1.87675  (1.91533)\n",
            "     | > stopnet_loss: 0.00757  (0.01069)\n",
            "     | > ga_loss: 0.00239  (0.00384)\n",
            "     | > decoder_diff_spec_loss: 0.20374  (0.20245)\n",
            "     | > postnet_diff_spec_loss: 0.43701  (0.43763)\n",
            "     | > decoder_ssim_loss: 0.79020  (0.79187)\n",
            "     | > postnet_ssim_loss: 0.57859  (0.63149)\n",
            "     | > loss: 1.33382  (1.37167)\n",
            "     | > align_error: 0.98925  (0.98282)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26259  (0.28184)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.91760  (1.34748)\n",
            "     | > loader_time: 0.02520  (0.01811)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 357/406 -- GLOBAL_STEP: 11725\u001b[0m\n",
            "     | > decoder_loss: 1.37956  (1.38851)\n",
            "     | > postnet_loss: 1.86545  (1.91306)\n",
            "     | > stopnet_loss: 0.00728  (0.01045)\n",
            "     | > ga_loss: 0.00225  (0.00374)\n",
            "     | > decoder_diff_spec_loss: 0.20412  (0.20231)\n",
            "     | > postnet_diff_spec_loss: 0.43611  (0.43728)\n",
            "     | > decoder_ssim_loss: 0.79208  (0.79184)\n",
            "     | > postnet_ssim_loss: 0.58065  (0.62807)\n",
            "     | > loss: 1.33303  (1.36939)\n",
            "     | > align_error: 0.98904  (0.98325)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26694  (0.28156)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.24460  (1.39260)\n",
            "     | > loader_time: 0.02590  (0.01866)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 382/406 -- GLOBAL_STEP: 11750\u001b[0m\n",
            "     | > decoder_loss: 1.42175  (1.38828)\n",
            "     | > postnet_loss: 1.88246  (1.91091)\n",
            "     | > stopnet_loss: 0.00678  (0.01023)\n",
            "     | > ga_loss: 0.00219  (0.00364)\n",
            "     | > decoder_diff_spec_loss: 0.20429  (0.20224)\n",
            "     | > postnet_diff_spec_loss: 0.43422  (0.43704)\n",
            "     | > decoder_ssim_loss: 0.78953  (0.79179)\n",
            "     | > postnet_ssim_loss: 0.57082  (0.62507)\n",
            "     | > loss: 1.34350  (1.36725)\n",
            "     | > align_error: 0.99026  (0.98365)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27426  (0.28103)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 2.14260  (1.43610)\n",
            "     | > loader_time: 0.02690  (0.01920)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 131\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 174\n",
            " | > Min text length: 20\n",
            " | > Avg text length: 100.76335877862596\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 34739.0\n",
            " | > Avg audio length: 144033.41221374046\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.01410 \u001b[0m(-0.00121)\n",
            "     | > avg_decoder_loss:\u001b[92m 1.77443 \u001b[0m(-0.03161)\n",
            "     | > avg_postnet_loss:\u001b[92m 1.99150 \u001b[0m(-0.07450)\n",
            "     | > avg_stopnet_loss:\u001b[92m 0.04115 \u001b[0m(-0.00036)\n",
            "     | > avg_ga_loss:\u001b[92m 0.00350 \u001b[0m(-0.00000)\n",
            "     | > avg_decoder_diff_spec_loss:\u001b[91m 0.23732 \u001b[0m(+0.00087)\n",
            "     | > avg_postnet_diff_spec_loss:\u001b[92m 0.44424 \u001b[0m(-0.00283)\n",
            "     | > avg_decoder_ssim_loss:\u001b[92m 0.81485 \u001b[0m(-0.00338)\n",
            "     | > avg_postnet_ssim_loss:\u001b[92m 0.56815 \u001b[0m(-0.01597)\n",
            "     | > avg_loss:\u001b[92m 1.51629 \u001b[0m(-0.03222)\n",
            "     | > avg_align_error:\u001b[91m 0.98900 \u001b[0m(+0.00006)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-May-18-2023_05+07AM-0000000/best_model_11774.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 29/30\u001b[0m\n",
            " --> tts_train_dir/run-May-18-2023_05+07AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-05-18 13:59:11) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 3 not found characters:\n",
            "\t| > ͡\n",
            "\t| > “\n",
            "\t| > ”\n",
            "| > Number of instances : 12969\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 188\n",
            " | > Min text length: 13\n",
            " | > Avg text length: 100.90014650319993\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 24499.0\n",
            " | > Avg audio length: 144984.29755570978\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> STEP: 1/406 -- GLOBAL_STEP: 11775\u001b[0m\n",
            "     | > decoder_loss: 1.40777  (1.40777)\n",
            "     | > postnet_loss: 1.91316  (1.91316)\n",
            "     | > stopnet_loss: 0.03420  (0.03420)\n",
            "     | > ga_loss: 0.01490  (0.01490)\n",
            "     | > decoder_diff_spec_loss: 0.20689  (0.20689)\n",
            "     | > postnet_diff_spec_loss: 0.44050  (0.44050)\n",
            "     | > decoder_ssim_loss: 0.77325  (0.77325)\n",
            "     | > postnet_ssim_loss: 0.73852  (0.73852)\n",
            "     | > loss: 1.47871  (1.47871)\n",
            "     | > align_error: 0.94379  (0.94379)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.39950  (0.39950)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.73280  (0.73283)\n",
            "     | > loader_time: 0.00650  (0.00647)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 26/406 -- GLOBAL_STEP: 11800\u001b[0m\n",
            "     | > decoder_loss: 1.36118  (1.36507)\n",
            "     | > postnet_loss: 1.85448  (1.87202)\n",
            "     | > stopnet_loss: 0.01589  (0.02081)\n",
            "     | > ga_loss: 0.00635  (0.00857)\n",
            "     | > decoder_diff_spec_loss: 0.20994  (0.20471)\n",
            "     | > postnet_diff_spec_loss: 0.44372  (0.43892)\n",
            "     | > decoder_ssim_loss: 0.78656  (0.78542)\n",
            "     | > postnet_ssim_loss: 0.76389  (0.76484)\n",
            "     | > loss: 1.40258  (1.42140)\n",
            "     | > align_error: 0.97170  (0.96338)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27734  (0.32092)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.70460  (0.61404)\n",
            "     | > loader_time: 0.00960  (0.00822)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 51/406 -- GLOBAL_STEP: 11825\u001b[0m\n",
            "     | > decoder_loss: 1.39098  (1.35888)\n",
            "     | > postnet_loss: 1.90429  (1.86110)\n",
            "     | > stopnet_loss: 0.01321  (0.01775)\n",
            "     | > ga_loss: 0.00516  (0.00709)\n",
            "     | > decoder_diff_spec_loss: 0.19708  (0.20431)\n",
            "     | > postnet_diff_spec_loss: 0.43274  (0.43811)\n",
            "     | > decoder_ssim_loss: 0.79029  (0.78666)\n",
            "     | > postnet_ssim_loss: 0.77704  (0.76659)\n",
            "     | > loss: 1.41209  (1.40709)\n",
            "     | > align_error: 0.97883  (0.96917)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.28630  (0.29956)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 0.94710  (0.72303)\n",
            "     | > loader_time: 0.01200  (0.00952)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 76/406 -- GLOBAL_STEP: 11850\u001b[0m\n",
            "     | > decoder_loss: 1.35954  (1.35768)\n",
            "     | > postnet_loss: 1.84787  (1.85700)\n",
            "     | > stopnet_loss: 0.01205  (0.01602)\n",
            "     | > ga_loss: 0.00437  (0.00629)\n",
            "     | > decoder_diff_spec_loss: 0.21234  (0.20450)\n",
            "     | > postnet_diff_spec_loss: 0.44269  (0.43763)\n",
            "     | > decoder_ssim_loss: 0.79373  (0.78757)\n",
            "     | > postnet_ssim_loss: 0.75880  (0.76650)\n",
            "     | > loss: 1.38763  (1.40021)\n",
            "     | > align_error: 0.97942  (0.97230)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27258  (0.29006)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.04850  (0.80236)\n",
            "     | > loader_time: 0.01320  (0.01090)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 101/406 -- GLOBAL_STEP: 11875\u001b[0m\n",
            "     | > decoder_loss: 1.37541  (1.35700)\n",
            "     | > postnet_loss: 1.86790  (1.85501)\n",
            "     | > stopnet_loss: 0.01119  (0.01486)\n",
            "     | > ga_loss: 0.00412  (0.00576)\n",
            "     | > decoder_diff_spec_loss: 0.19960  (0.20432)\n",
            "     | > postnet_diff_spec_loss: 0.43155  (0.43691)\n",
            "     | > decoder_ssim_loss: 0.79310  (0.78838)\n",
            "     | > postnet_ssim_loss: 0.58345  (0.72188)\n",
            "     | > loss: 1.34456  (1.38455)\n",
            "     | > align_error: 0.98126  (0.97457)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.27560  (0.28719)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.12690  (0.87359)\n",
            "     | > loader_time: 0.01530  (0.01192)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 126/406 -- GLOBAL_STEP: 11900\u001b[0m\n",
            "     | > decoder_loss: 1.33148  (1.35630)\n",
            "     | > postnet_loss: 1.81510  (1.85181)\n",
            "     | > stopnet_loss: 0.01045  (0.01400)\n",
            "     | > ga_loss: 0.00358  (0.00536)\n",
            "     | > decoder_diff_spec_loss: 0.20456  (0.20432)\n",
            "     | > postnet_diff_spec_loss: 0.43585  (0.43661)\n",
            "     | > decoder_ssim_loss: 0.78993  (0.78880)\n",
            "     | > postnet_ssim_loss: 0.57598  (0.69288)\n",
            "     | > loss: 1.31657  (1.37350)\n",
            "     | > align_error: 0.98428  (0.97621)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26165  (0.28470)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.24700  (0.93999)\n",
            "     | > loader_time: 0.01690  (0.01276)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 151/406 -- GLOBAL_STEP: 11925\u001b[0m\n",
            "     | > decoder_loss: 1.35117  (1.35623)\n",
            "     | > postnet_loss: 1.83165  (1.84895)\n",
            "     | > stopnet_loss: 0.00976  (0.01334)\n",
            "     | > ga_loss: 0.00343  (0.00506)\n",
            "     | > decoder_diff_spec_loss: 0.20573  (0.20433)\n",
            "     | > postnet_diff_spec_loss: 0.43820  (0.43625)\n",
            "     | > decoder_ssim_loss: 0.78730  (0.78914)\n",
            "     | > postnet_ssim_loss: 0.56974  (0.67345)\n",
            "     | > loss: 1.32283  (1.36573)\n",
            "     | > align_error: 0.98387  (0.97736)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26295  (0.28395)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.35560  (0.99636)\n",
            "     | > loader_time: 0.01750  (0.01358)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 176/406 -- GLOBAL_STEP: 11950\u001b[0m\n",
            "     | > decoder_loss: 1.36609  (1.35659)\n",
            "     | > postnet_loss: 1.81784  (1.84641)\n",
            "     | > stopnet_loss: 0.00906  (0.01279)\n",
            "     | > ga_loss: 0.00326  (0.00481)\n",
            "     | > decoder_diff_spec_loss: 0.20565  (0.20426)\n",
            "     | > postnet_diff_spec_loss: 0.43356  (0.43587)\n",
            "     | > decoder_ssim_loss: 0.78696  (0.78916)\n",
            "     | > postnet_ssim_loss: 0.56679  (0.65945)\n",
            "     | > loss: 1.31957  (1.35978)\n",
            "     | > align_error: 0.98534  (0.97834)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26565  (0.28191)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.40800  (1.04723)\n",
            "     | > loader_time: 0.01860  (0.01433)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 201/406 -- GLOBAL_STEP: 11975\u001b[0m\n",
            "     | > decoder_loss: 1.34367  (1.35729)\n",
            "     | > postnet_loss: 1.83120  (1.84428)\n",
            "     | > stopnet_loss: 0.00882  (0.01232)\n",
            "     | > ga_loss: 0.00304  (0.00460)\n",
            "     | > decoder_diff_spec_loss: 0.21028  (0.20410)\n",
            "     | > postnet_diff_spec_loss: 0.43899  (0.43537)\n",
            "     | > decoder_ssim_loss: 0.79008  (0.78929)\n",
            "     | > postnet_ssim_loss: 0.56665  (0.64901)\n",
            "     | > loss: 1.31925  (1.35516)\n",
            "     | > align_error: 0.98566  (0.97923)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26648  (0.28094)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.45360  (1.09619)\n",
            "     | > loader_time: 0.01970  (0.01493)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 226/406 -- GLOBAL_STEP: 12000\u001b[0m\n",
            "     | > decoder_loss: 1.36612  (1.35743)\n",
            "     | > postnet_loss: 1.82351  (1.84193)\n",
            "     | > stopnet_loss: 0.00834  (0.01191)\n",
            "     | > ga_loss: 0.00291  (0.00442)\n",
            "     | > decoder_diff_spec_loss: 0.20412  (0.20406)\n",
            "     | > postnet_diff_spec_loss: 0.43196  (0.43507)\n",
            "     | > decoder_ssim_loss: 0.79209  (0.78944)\n",
            "     | > postnet_ssim_loss: 0.57627  (0.64069)\n",
            "     | > loss: 1.32141  (1.35116)\n",
            "     | > align_error: 0.98640  (0.97997)\n",
            "     | > amp_scaler: 524288.00000  (524288.00000)\n",
            "     | > grad_norm: 0.26939  (0.28018)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.54760  (1.14436)\n",
            "     | > loader_time: 0.02080  (0.01555)\n",
            "\n",
            "\n",
            " > CHECKPOINT : tts_train_dir/run-May-18-2023_05+07AM-0000000/checkpoint_12000.pth\n",
            "\n",
            "\u001b[1m   --> STEP: 251/406 -- GLOBAL_STEP: 12025\u001b[0m\n",
            "     | > decoder_loss: 1.34683  (1.35793)\n",
            "     | > postnet_loss: 1.79581  (1.84026)\n",
            "     | > stopnet_loss: 0.00797  (0.01155)\n",
            "     | > ga_loss: 0.00278  (0.00426)\n",
            "     | > decoder_diff_spec_loss: 0.20707  (0.20398)\n",
            "     | > postnet_diff_spec_loss: 0.43468  (0.43475)\n",
            "     | > decoder_ssim_loss: 0.78703  (0.78944)\n",
            "     | > postnet_ssim_loss: 0.56507  (0.63391)\n",
            "     | > loss: 1.30597  (1.34792)\n",
            "     | > align_error: 0.98658  (0.98065)\n",
            "     | > amp_scaler: 1048576.00000  (576507.92032)\n",
            "     | > grad_norm: 0.26171  (0.27947)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.76170  (1.19537)\n",
            "     | > loader_time: 0.02190  (0.01629)\n",
            "\n",
            "\n",
            "\u001b[1m   --> STEP: 276/406 -- GLOBAL_STEP: 12050\u001b[0m\n",
            "     | > decoder_loss: 1.36436  (1.35774)\n",
            "     | > postnet_loss: 1.83336  (1.83790)\n",
            "     | > stopnet_loss: 0.00780  (0.01122)\n",
            "     | > ga_loss: 0.00263  (0.00412)\n",
            "     | > decoder_diff_spec_loss: 0.20385  (0.20389)\n",
            "     | > postnet_diff_spec_loss: 0.43283  (0.43441)\n",
            "     | > decoder_ssim_loss: 0.79019  (0.78942)\n",
            "     | > postnet_ssim_loss: 0.57447  (0.62828)\n",
            "     | > loss: 1.32070  (1.34473)\n",
            "     | > align_error: 0.98787  (0.98126)\n",
            "     | > amp_scaler: 1048576.00000  (619267.71014)\n",
            "     | > grad_norm: 0.26556  (0.27831)\n",
            "     | > current_lr: 0.00000 \n",
            "     | > step_time: 1.82020  (1.24478)\n",
            "     | > loader_time: 0.02280  (0.01685)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n",
        "!tensorboard --logdir=tts_train_dir"
      ],
      "metadata": {
        "id": "zO5SHGMdiEJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775b8ce6-54b9-4a17-d0a4-f304f8fbbb0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.40.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
            "2023-05-18 14:07:01.232174: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-18 14:07:01.288303: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-18 14:07:02.182618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.12.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "output_path = \"tts_train_dir\"\n",
        "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
        "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"
      ],
      "metadata": {
        "id": "tkT-9AGYiMF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tts --text \"Text for TTS\" \\\n",
        "      --model_path $test_ckpt \\\n",
        "      --config_path $test_config \\\n",
        "      --out_path out.wav"
      ],
      "metadata": {
        "id": "gIvjA16NiPJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"out.wav\")"
      ],
      "metadata": {
        "id": "BA8OhCk4iSBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cuYMUd3uifj0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}